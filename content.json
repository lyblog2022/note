[{"title":"RabbitMQ初步学习","date":"2022-06-26T02:17:45.000Z","path":"2022/06/26/study/rabbitMq/rabbitMQ1/","text":"RabbitMQ学习及简单原理简介 1、AMQP1.1 AMQP​ AMQP(Advanced Message Queuing Protocol，高级消息队列协议)是进程之间传递异步消息的网络协议。 1.2 AMQP工作过程​ 发布者(Publisher)发布消息(Message)，经过交换机(Exchange)，交换机根据路由规则将收到消息分发给交换机绑定的队列(Queue)，最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。 1.3 队列​ 队列是数据结构中概念。数据存储在一个队列中，数据是有顺序的，先进的先出，后进后出。其中一侧负责进数据，另一侧负责出数据。 ​ MQ（消息队列）很多功能都是基于此队列结构实现的 ​ 2、RabbitMQ2.1 RabbitMQ介绍​ RabbitMQ是由Erlang语言编写的基于AMQP的消息中间件。而消息中间件作为分布式系统重要组件之一，可以解决应用耦合，异步消息，流量削峰等问题。 2.1.1 解决应用耦合​ 不使用MQ时 ​ ​ 使用MQ解决耦合 ​ 2.2 RabbitMQ适用场景 排队算法 : 使用消息队列特性 秒杀活动 : 使用消息队列特性 消息分发 : 使用消息异步特性 异步处理 : 使用消息异步特性 数据同步 : 使用消息异步特性 处理耗时任务 : 使用消息异步特性 流量销峰 3、RabbitMQ原理​ Message：消息。消息是不具名的，它由消息头消息体组成。消息体是不透明的，而消息头则由一系列可选属性组成，这些属性包括：routing-key(路由键)、priority(相对于其他消息的优先权)、delivery-mode(指出消息可能持久性存储)等。 Publisher：消息的生产者。也是一个向交换器发布消息的客户端应用程序。 Consumer：消息的消费者。表示一个从消息队列中取得消息的客户端应用程序。 Exchange：交换器。用来接收生产者发送的消息并将这些消息路由给服务器中的队列。三种常用的交换器类型1. direct(发布与订阅 完全匹配)2. fanout(广播)3. topic(主题，规则匹配) Binding：绑定。用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue：消息队列。用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者链接到这个队列将其取走。 Routing-key：路由键。RabbitMQ决定消息该投递到哪个队列的规则。（也可以理解为队列的名称，路由键是key，队列是value）队列通过路由键绑定到交换器。消息发送到MQ服务器时，消息将拥有一个路由键，即便是空的，RabbitMQ也会将其和绑定使用的路由键进行匹配。如果相匹配，消息将会投递到该队列。如果不匹配，消息将会进入黑洞 Connection：链接。指rabbit服务器和服务建立的TCP链接。 Channel：信道。 Channel中文叫做信道，是TCP里面的虚拟链接。例如：电缆相当于TCP，信道是一个独立光纤束，一条TCP连接上创建多条信道是没有问题的。 TCP一旦打开，就会创建AMQP信道 无论是发布消息、接收消息、订阅队列，这些动作都是通过信道完成的。 Virtual Host：虚拟主机。表示一批交换器，消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个vhost本质上就是一个mini版的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在链接时指定，RabbitMQ默认的vhost是**&#x2F;** Borker：表示消息队列服务器实体。 交换器和队列的关系：交换器是通过路由键和队列绑定在一起的，如果消息拥有的路由键跟队列和交换器的路由键匹配，那么消息就会被路由到该绑定的队列中。也就是说，消息到队列的过程中，消息首先会经过交换器，接下来交换器在通过路由键匹配分发消息到具体的队列中。 路由键可以理解为匹配的规则。 RabbitMQ为什么需要信道？为什么不是TCP直接通信？ TCP的创建和销毁开销特别大。创建需要3次握手，销毁需要4次分手 如果不用信道，那应用程序就会以TCP链接Rabbit，高峰时每秒成千上万条链接会造成资源巨大的浪费，而且操作系统每秒处理TCP链接数也是有限制的，必定造成性能瓶颈 信道的原理是一条线程一条通道，多条线程多条通道同用一条TCP链接。一条TCP链接可以容纳无限的信道，即使每秒成千上万的请求也不会成为性能的瓶颈。 4、交换器（交换机）​ 交换器负责接收客户端传递过来的消息，并转发到对应的队列中。在RabbitMQ中支持四种交换器 Direct Exchange：直连交换器（默认） Fanout Exchange：扇形交换器 Topic Exchange：主题交换器 Header Exchange：首部交换器。 ​ 在RabbitMq的Web管理界面中Exchanges选项卡就可以看见这四个交换器。 4.1 direct交换器​ direct交换器是RabbitMQ默认交换器。默认会进行公平调度。所有接受者依次从消息队列中获取值。Publisher给哪个队列发消息，就一定是给哪个队列发送消息。对交换器绑定的其他队列没有任何影响。 ​ 代码实现 4.1.1 添加依赖1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 4.1.2 编写配置文件​ 新建application.yml. ​ host:默认值localhost ​ username默认值：guest ​ password默认值：guest 12345spring: rabbitmq: host: 192.168.213.133 username: ly password: qwq 4.1.3 配置类​ 队列的创建只有没有这个队列的时候需要编写。以后没有这个queue()方法也可以。 1234567891011121314151617181920212223package com.rabbitmq.config;import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * RabbitwqConfig * * @author liuyong * @version 1.0 * @description com.rabbitmq.config * @date 2022/6/26 11:08 */@Configurationpublic class RabbitwqConfig &#123; @Bean protected Queue queue() &#123; Queue queue = new Queue(&quot;myQueue&quot;); return queue; &#125;&#125; 4.1.4 编写测试类12345678910111213141516171819202122package com.rabbitmq;import org.junit.jupiter.api.Test;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;@SpringBootTest()class RabbitmqApplicationTests &#123; @Autowired private AmqpTemplate amqpTemplate; /** * provider */ @Test void contextLoads() &#123; amqpTemplate.convertAndSend(&quot;myQueue&quot;,&quot;send text312312&quot;); System.out.println(&quot;success&quot;); &#125;&#125; 4.1.5 创建consumerpom文件，yml文件，config文件与provider相同 4.1.6 编写监听器​ 注意： ​ 类上要有@Componet，项目启动时此类生效。 ​ @RabbitListener 监听指定队列。 1234567891011121314151617181920212223242526package com.rabbitmq.receive;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;/** * ReceiveDemo * * @author liuyong * @version 1.0 * @description com.rabbitmq.receive * @date 2022/6/26 11:49 */@Componentpublic class ReceiveDemo &#123; @RabbitListener(queues = &quot;myQueue&quot;) protected void demo(String msg) &#123; System.out.println(&quot;获取到的消息：&quot; + msg); &#125; @RabbitListener(queues = &quot;myQueue&quot;) protected void demo2(String msg) &#123; System.out.println(&quot;获取到的消息22222222：&quot; + msg); &#125;&#125; 4.2 fanout交换器​ 扇形交换器，实际上做的事情就是广播，fanout会把消息发送给所有的绑定在当前交换器上的队列。且每个队列消息中第一个Consumer能收到消息。 ​ 代码示例 pom文件、yml文件与direct示例相同 4.2.1 修改配置类在config配置文件内添加以下代码 12345678910111213141516171819202122@Bean public Queue createQueue1() &#123; return new Queue(&quot;myfanout1&quot;); &#125; @Bean public Queue createQueue2() &#123; return new Queue(&quot;myfanout2&quot;); &#125; @Bean public FanoutExchange getFanout() &#123; return new FanoutExchange(&quot;amq.fanout&quot;); &#125; @Bean public Binding binding(Queue createQueue1,FanoutExchange getFanout)&#123; return BindingBuilder.bind(createQueue1).to(getFanout); &#125; @Bean public Binding binding2(Queue createQueue2,FanoutExchange getFanout)&#123; return BindingBuilder.bind(createQueue2).to(getFanout); &#125; 4.2.2 编写发送方法12345@Test void contextLoads2() &#123; amqpTemplate.convertAndSend(&quot;amq.fanout&quot;,&quot;core&quot;,&quot;hhhh&quot;); System.out.println(&quot;success&quot;); &#125; 4.2.3 consumer在receiveDemo下添加以下代码 12345678@RabbitListener(queues = &quot;myfanout1&quot;) public void demo3(String msg) &#123; System.out.println(&quot;myfanout1:&quot;+msg); &#125; @RabbitListener(queues = &quot;myfanout2&quot;) public void demo4(String msg) &#123; System.out.println(&quot;myfanout2:&quot;+msg); &#125; 4.3 topic交换器​ 允许在路由键（RoutingKey）中出现匹配规则。 ​ 路由键的写法和包写法相同。com.xxxx.xxx格式。 ​ 在绑定时可以带有下面特殊符号，中间可以出现: ​ * : 代表一个单词（两个.之间内容） ​ # : 0个或多个字符 ​ 接收方依然是公平调度，同一个队列中内容轮换获取值。 ​ 示例代码 pom，yml文件与以上相同 4.3.1 修改配置类在config文件中添加以下代码 1234567891011121314151617181920@Bean public Queue topicQueue1()&#123; return new Queue(&quot;topic1&quot;); &#125; @Bean public Queue topicQueue2()&#123; return new Queue(&quot;topic2&quot;); &#125; @Bean public TopicExchange getTopic() &#123; return new TopicExchange(&quot;amq.topic&quot;); &#125; @Bean public Binding topicBinding1(Queue topicQueue1,TopicExchange getTopic)&#123; return BindingBuilder.bind(topicQueue1).to(getTopic).with(&quot;com.*&quot;); &#125; @Bean public Binding topicBinding2(Queue topicQueue2,TopicExchange getTopic)&#123; return BindingBuilder.bind(topicQueue2).to(getTopic).with(&quot;com.#&quot;); &#125; 4.3.2 发送消息​ 第二个参数为路由键，匹配配置类中绑定时的路由规则。 12345@Test void contextLoads3() &#123; amqpTemplate.convertAndSend(&quot;amq.topic&quot;,&quot;com.q.w&quot;,&quot;msg&quot;); System.out.println(&quot;success&quot;); &#125; 4.3.3 Consumer​ 在receiveDemo下添加以下代码 12345678@RabbitListener(queues = &quot;topic1&quot;) public void demo5(String msg) &#123; System.out.println(&quot;topic1:&quot;+msg); &#125; @RabbitListener(queues = &quot;topic2&quot;) public void demo6(String msg) &#123; System.out.println(&quot;topic2:&quot;+msg); &#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://lyblog2022.github.io/tags/RabbitMQ/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"RabbitMQ安装","date":"2022-06-25T05:16:19.000Z","path":"2022/06/25/software/rabbitMq/","text":"CentOS8安装RabbitMQ 1、Erlang安装​ RabbitMQ是使用Erlang语言编写的，所以需要先配置Erlang 1.1 修改主机名​ RabbitMQ是通过主机名进行访问的，必须指定能访问的主机名。 1vim /etc/sysconfig/network 12NETWORKING=yesHOSTNAME=ly 1vim /etc/hosts ​ 新添加了一行，前面为服务器ip，空格后面添加计算机主机名 1.2 安装依赖1yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel unixODBC unixODBC-devel 1.3 上传并解压​ 上传otp_src_22.0.tar.gz到&#x2F;usr&#x2F;local&#x2F;tmp目录中，进入目录并解压 ​ 解压时注意，此压缩包不具有gzip属性，解压参数没有z，只有xf 12cd /usr/local/tmptar xf otp_src_22.0.tar.gz 1.4 配置参数​ 先新建&#x2F;usr&#x2F;local&#x2F;erlang文件夹，作为安装文件夹 1mkdir -p /usr/local/erlang ​ 进入文件夹 1cd otp_src_22.0 ​ 配置参数 1./configure --prefix=/usr/local/erlang --with-ssl --enable-threads --enable-smp-support --enable-kernel-poll --enable-hipe --without-javac 1.5 编译并安装​ 编译 1make ​ 安装 1make install 1.6 修改环境变量​ 修改&#x2F;etc&#x2F;profile文件 1vim /etc/profile ​ 在文件中添加下面代码 1export PATH=$PATH:/usr/local/erlang/bin ​ 运行文件，让修改内容生效 1source /etc/profile 1.7 查看配置是否成功1erl -version 2、安装RabbitMQ2.1 上传并解压​ 上传rabbitmq-server-generic-unix-3.7.18.tar.xz到&#x2F;usr&#x2F;loca&#x2F;tmp中 12cd /usr/local/tmptar xf rabbitmq-server-generic-unix-3.7.18.tar.xz 2.2 复制到local下​ 复制解压文件到&#x2F;usr&#x2F;local下，命名为rabbitmq 1cp -r rabbitmq_server-3.7.18 /usr/local/rabbitmq 2.3 配置环境变量1vim /etc/profile ​ 在文件中添加 1export PATH=$PATH:/usr/local/rabbitmq/sbin ​ 解析文件 1source /etc/profile 2.4 开启web管理插件​ 进入rabbitmq&#x2F;sbin目录 1cd /usr/local/rabbitmq/sbin ​ 查看插件列表 1./rabbitmq-plugins list ​ 生效管理插件 1./rabbitmq-plugins enable rabbitmq_management 2.5 后台运行​ 启动rabbitmq。 1./rabbitmq-server -detached ​ 停止命令，如果无法停止，使用kill -9 进程号进行关闭 1./rabbitmqctl stop_app 2.6 查看web管理界面​ 默认可以在安装rabbitmq的电脑上通过用户名：guest密码guest进行访问web管理界面 ​ 端口号：15672（放行端口，或关闭防火墙） ​ 在虚拟机浏览器中输入：http://localhost:15672/#/ 3、RabbitMq账户管理3.1 创建账户​ 语法：.&#x2F;rabbitmqctl add_user username password 12cd /usr/local/rabbitmq/sbin./rabbitmqctl add_user ly qwq 3.2 给用户授予管理员角色​ 其中ly为新建用户的用户名 1./rabbitmqctl set_user_tags ly administrator 3.3 给用户授权​ “&#x2F;” 表示虚拟机 ​ ly 表示用户名 ​ “.“ “.“ “.*” 表示完整权限 1./rabbitmqctl set_permissions -p &quot;/&quot; ly &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 3.4 登录​ 使用新建账户和密码在windows中访问rabbitmq并登录 ​ 在浏览器地址栏输入：http://192.168.213.133:15672/#/ ​ 用户名：ly ​ 密码：qwq","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://lyblog2022.github.io/tags/RabbitMQ/"}]},{"title":"springboot整合redis","date":"2022-06-25T04:54:39.000Z","path":"2022/06/25/study/redis/redis4/","text":"SpringBoot整合SpringDataRedis操作redis ​ Spring Data是Spring公司的顶级项目，里面包含了N多个二级子项目，这些子项目都是相对独立的项目。每个子项目是对不同API的封装。 ​ 所有Spring Boot整合Spring Data xxxx的启动器都叫做spring-boot-starter-data-xxxx ​ Spring Data 好处很方便操作对象类型。 ​ 把Redis不同值得类型放到一个opsForXXX方法中。 opsForValue : String值 opsForList : 列表List opsForHash: 哈希表Hash opsForZSet: 有序集合Sorted Set opsForSet : 集合 1、SpringBoot整合Redis1.1 创建mysql数据库12345678910111213141516171819202122232425262728293031/* Navicat Premium Data Transfer Source Server : localhost Source Server Type : MySQL Source Server Version : 80029 Source Host : localhost:3306 Source Schema : study Target Server Type : MySQL Target Server Version : 80029 File Encoding : 65001 Date: 25/06/2022 16:23:52*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for product-- ----------------------------DROP TABLE IF EXISTS `product`;CREATE TABLE `product` ( `id` int NOT NULL, `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `price` decimal(10, 2) NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;SET FOREIGN_KEY_CHECKS = 1; 1.2 创建 redis配置文件1234567891011121314151617181920212223242526272829package com.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * RedisConfig * * @author liuyong * @version 1.0 * @description com.config * @date 2022/6/25 16:12 */@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String ,Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String , Object&gt; redisTemplate = new RedisTemplate&lt;String , Object&gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class)); redisTemplate.setConnectionFactory(factory); return redisTemplate; &#125;&#125; 1.3 创建pojo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.pojo;import java.io.Serializable;/** * Product * * @author liuyong * @version 1.0 * @description com.pojo * @date 2022/6/25 15:59 */public class Product implements Serializable &#123; private Integer id; private String name; private Double price; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getPrice() &#123; return price; &#125; public void setPrice(Double price) &#123; this.price = price; &#125; @Override public String toString() &#123; return &quot;Product&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, price=&quot; + price + &#x27;&#125;&#x27;; &#125;&#125; 1.4 创建mapper及配置文件12345678package com.mapper;import com.pojo.Product;public interface ProductMapper &#123; public Product findProductById(Integer id);&#125; 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.mapper.ProductMapper&quot;&gt; &lt;select id=&quot;findProductById&quot; resultType=&quot;com.pojo.Product&quot;&gt; select id, name, price from product where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 1.5 创建service接口及实现类1234567package com.service;import com.pojo.Product;public interface ProductService &#123; public Product findProductById(Integer id) ;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.service.impl;import com.mapper.ProductMapper;import com.pojo.Product;import com.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.stereotype.Service;/** * ProductServiceImpl * * @author liuyong * @version 1.0 * @description com.service.impl * @date 2022/6/25 16:01 */@Servicepublic class ProductServiceImpl implements ProductService&#123; @Autowired private ProductMapper productMapper; @Autowired private RedisTemplate&lt;String,Object&gt; redisTemplate; @Override public Product findProductById(Integer id) &#123; String key = &quot;product:&quot; +id; //先从redis中获取数据 if(redisTemplate.hasKey(key)) &#123; System.out.println(&quot;执行缓存&quot;); redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer&lt;Product&gt;(Product.class)); Product product = (Product) redisTemplate.opsForValue().get(key); return product; &#125; System.out.println(&quot;执行mysql&quot;); Product product = productMapper.findProductById(id); redisTemplate.opsForValue().set(key, product); return product; &#125;&#125; 1.6 创建控制类123456789101112131415161718192021222324252627282930package com.controller;import com.pojo.Product;import com.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;/** * ProductController * * @author liuyong * @version 1.0 * @description com.controller * @date 2022/6/25 16:03 */@Controllerpublic class ProductController &#123; @Autowired private ProductService productService; @GetMapping(&quot;/show&quot;) public String select(Integer id , Model model) &#123; Product product = productService.findProductById(id); model.addAttribute(&quot;product&quot; , product); return &quot;show&quot;; &#125;&#125; 1.7 创建启动器12345678910111213141516171819202122package com;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * ProductApplication * * @author liuyong * @version 1.0 * @description com * @date 2022/6/25 15:58 */@SpringBootApplication@MapperScan(&quot;com.mapper&quot;)public class ProductApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProductApplication.class , args); &#125;&#125; 1.8 创建配置文件123456789101112spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/study?characterEncoding=utf-8&amp;serverTimezone=UTC username: root password: liuyong redis: cluster: nodes: 192.168.213.133:7001,192.168.213.133:7002,192.168.213.133:7003,192.168.213.133:7004,192.168.213.133:7005,192.168.213.133:7006mybatis: type-aliases-package: com.pojo mapper-locations: classpath:com/mapper/*.xml 1.9 创建视图123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;span th:text=&quot;$&#123;product.id&#125;&quot;&gt;&lt;/span&gt; &lt;span th:text=&quot;$&#123;product.name&#125;&quot;&gt;&lt;/span&gt; &lt;span th:text=&quot;$&#123;product.price&#125;&quot;&gt;&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; 1.10 运行​ 第一次运行 ​ 第二次运行","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"springboot","slug":"springboot","permalink":"https://lyblog2022.github.io/tags/springboot/"},{"name":"centos8","slug":"centos8","permalink":"https://lyblog2022.github.io/tags/centos8/"}]},{"title":"redis哨兵及集群","date":"2022-06-23T12:15:01.000Z","path":"2022/06/23/study/redis/redis3/","text":"redis哨兵及集群配置及学习 1、哨兵（Sentinel）​ 在redis主从默认是只有主具备写的能力，而从只能读。如果主宕机，整个节点不具备写能力。但是如果这是让一个从变成主，整个节点就可以继续工作。即使之前的主恢复过来也当做这个节点的从即可。 ​ Redis的哨兵就是帮助监控整个节点的，当节点主宕机等情况下，帮助重新选取主。 ​ Redis中哨兵支持单哨兵和多哨兵。单哨兵是只要这个哨兵发现master宕机了，就直接选取另一个master。而多哨兵是根据我们设定，达到一定数量哨兵认为master宕机后才会进行重新选取主。 1.1 没有哨兵下主从效果​ 只要杀掉主，整个节点无法在写数据，从身份不会变化，主的信息还是以前的信息。 1.2 搭建多哨兵​ 前提：安装了单机的redis 1.2.1 新建目录1mkdir /usr/local/sentinel 1.2.2 复制redis1cp -r /usr/local/redis/bin/* /usr/local/sentinel 1.2.3 复制配置文件​ 从redis解压目录中复制sentinel配置文件 12cd /usr/local/tmp/redis-5.0.5/cp sentinel.conf /usr/local/sentinel/ 1.2.4 修改配置文件12cd /usr/local/sentinelvim sentinel.conf 1234port 26379daemonize yeslogfile “/usr/local/sentinel/26379.log”sentinel monitor mymaster 192.168.93.10 6379 2 ​ 复制sentinel.conf，命名为sentinel-26380.conf 12cp sentinel.conf sentinel-26380.confvim sentinel-26380.conf 1234port 26380daemonize yeslogfile “/usr/local/sentinel/26380.log”sentinel monitor mymaster 192.168.93.10 6379 2 ​ 复制sentinel.conf，命名为sentinel-26381.conf 12cp sentinel.conf sentinel-26381.confvim sentinel-26381.conf 1234port 26381daemonize yeslogfile “/usr/local/sentinel/26381.log”sentinel monitor mymaster 192.168.93.10 6379 2 1.2.5 启动主从​ 如果已经启动状态，忽略下面命令。如果启动部分，全部kill后重新启动。 ​ 使用kill杀死全部redis 12ps aux|grep rediskill -9 进程号 ​ 启动redis主从 12cd /usr/local/replica./startup.sh 1.2.6 启动三个哨兵1234cd /usr/local/sentinel./redis-sentinel sentinel.conf./redis-sentinel sentinel-26380.conf./redis-sentinel sentinel-26381.conf 1.2.7 查看日志1cat 26379.log 1.2.8 测试宕机​ 查看redis进程号 1ps aux|grep redis ​ 杀死主进程号 1kill -9 进程号 ​ 查看日志，短暂延迟后会发现，出现新的主。 1cat 26379.log 2、集群（Cluster）​ 前提：已经安装好redis单机版。 ​ 当集群中超过或等于1&#x2F;2节点不可用时，整个集群不可用。为了搭建稳定集群，都采用奇数节点。 2.1 复制redis配置文件​ 从&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin下把redis.conf复制到当前目录中，命名为redis-7001.conf 1cp /usr/local/redis/bin/redis.conf /usr/local/redis/bin/redis-7001.conf 2.2 修改redis-7001.conf12cd /usr/local/redis/binvim redis-7001.conf ​ 需要修改如下 12345678port 7001cluster-enabled yescluster-config-file nodes-7001.confcluster-node-timeout 15000# appendonly yes 如果开启aof默认，需要修改为yes。如果使用rdb，此处不需要修改daemonize yesprotected-mode nopidfile /var/run/redis_7001.pid 2.3 复制配置文件，并修改内容​ 把redis-7001.conf 复制5份，分别叫做redis-7002.conf、redis-7003.conf、redis-7004.conf、redis-7005.conf、redis-7006.conf 12345cp redis-7001.conf redis-7002.confcp redis-7001.conf redis-7003.confcp redis-7001.conf redis-7004.confcp redis-7001.conf redis-7005.confcp redis-7001.conf redis-7006.conf ​ 新复制的5个配置文件都需要需改三处。 ​ 例如nodes-7002.conf中需要把所有7001都换成7002。 ​ 可以使用 :%s&#x2F;7001&#x2F;7002&#x2F;g 进行全局修改。 2.4 启动6个redis​ 可以使用redis-server结合6个配置文件进行启动6个实例。 ​ 执行之前一定要先删除dump.rdb 12rm -f dump.rdbvim startup.sh 123456./redis-server redis-7001.conf./redis-server redis-7002.conf./redis-server redis-7003.conf./redis-server redis-7004.conf./redis-server redis-7005.conf./redis-server redis-7006.conf 12chmod a+x startup.sh./startup.sh 2.5 查看启动状态2.6 建立集群​ 在redis3的时候需要借助ruby脚本实现集群。在redis5中可以使用自带的redis-cli实现集群功能，比redis3的时候更加方便了。 ​ 建议配置静态ip，ip改变集群失效 1./redis-cli --cluster create 192.168.213.133:7001 192.168.213.133:7002 192.168.213.133:7003 192.168.213.133:7004 192.168.213.133:7005 192.168.213.133:7006 --cluster-replicas 1 2.7 测试​ 集群测试时，千万不要忘记最后一个-c参数。 1234./redis-cli -p 7001 -c127.0.0.1:7001&gt; set age 18OK127.0.0.1:7001&gt; 2.8 编写关闭脚本1vim stop.sh 123456./redis-cli -p 7001 shutdown./redis-cli -p 7002 shutdown./redis-cli -p 7003 shutdown./redis-cli -p 7004 shutdown./redis-cli -p 7005 shutdown./redis-cli -p 7006 shutdown 12chmod a+x stop.sh./stop.sh 3、Jedis​ Redis给Java语言提供了客户端API，称之为Jedis。 ​ Jedis API和Redis 命令几乎是一样的。 ​ 例如：Redis对String值新增时set命令，Jedis中也是set方法。 ​ Jedis API特别简单，基本上都是创建对象调用方法即可。 依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;!--版本号可根据实际情况填写2.9.0--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.1 单机版1234567891011121314151617181920package com.jedis;import redis.clients.jedis.Jedis;/** * Main * * @author liuyong * @version 1.0 * @description com.jedis * @date 2022/6/23 21:44 */public class Main &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;192.168.213.133&quot;,7001); jedis.set(&quot;text&quot;,&quot;hello jedis&quot;); String result = jedis.get(&quot;text&quot;); System.out.println(result); &#125;&#125; 3.2 带有连接池123456789101112131415161718192021222324252627package com.jedis;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;/** * PoolDemo * * @author liuyong * @version 1.0 * @description com.jedis * @date 2022/6/23 21:54 */public class PoolDemo &#123; public static void main(String[] args) &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(20); jedisPoolConfig.setMaxIdle(5); jedisPoolConfig.setMinIdle(3); JedisPool jedisPool = new JedisPool(jedisPoolConfig,&quot;192.168.213.133&quot;,7001); Jedis jedis = jedisPool.getResource(); jedis.set(&quot;jedisdemo&quot;,&quot;pool1&quot;); String value = jedis.get(&quot;jedisdemo&quot;); System.out.println(value); &#125;&#125; 3.3 集群12345678910111213141516171819202122232425262728293031package com.jedis;import redis.clients.jedis.HostAndPort;import redis.clients.jedis.JedisCluster;import java.util.HashSet;import java.util.Set;/** * ClusterDemo * * @author liuyong * @version 1.0 * @description com.jedis * @date 2022/6/23 21:59 */public class ClusterDemo &#123; public static void main(String[] args) &#123; Set&lt;HostAndPort&gt; set = new HashSet&lt;&gt;(); set.add(new HostAndPort(&quot;192.168.213.133&quot;,7001)); set.add(new HostAndPort(&quot;192.168.213.133&quot;,7002)); set.add(new HostAndPort(&quot;192.168.213.133&quot;,7003)); set.add(new HostAndPort(&quot;192.168.93.10&quot;,7004)); set.add(new HostAndPort(&quot;192.168.93.10&quot;,7005)); set.add(new HostAndPort(&quot;192.168.93.10&quot;,7006)); JedisCluster jedisCluster = new JedisCluster(set); jedisCluster.set(&quot;name&quot;,&quot;bjmsb&quot;); String value = jedisCluster.get(&quot;name&quot;); System.out.println(value); &#125;&#125; 报错： 1234567891011121314java.lang.NumberFormatException: For input string: &quot;7002@17002&quot;at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)at java.lang.Integer.parseInt(Integer.java:580)at java.lang.Integer.valueOf(Integer.java:766)at redis.clients.util.ClusterNodeInformationParser.getHostAndPortFromNodeLine(ClusterNodeInformationParser.java:38)at redis.clients.util.ClusterNodeInformationParser.parse(ClusterNodeInformationParser.java:14)at redis.clients.jedis.JedisClusterInfoCache.discoverClusterNodesAndSlots(JedisClusterInfoCache.java:43)at redis.clients.jedis.JedisClusterConnectionHandler.initializeSlotsCache(JedisClusterConnectionHandler.java:52)at redis.clients.jedis.JedisClusterConnectionHandler.&lt;init&gt;(JedisClusterConnectionHandler.java:37)at redis.clients.jedis.JedisSlotBasedConnectionHandler.&lt;init&gt;(JedisSlotBasedConnectionHandler.java:16)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:48)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:35)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:27)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:31) 解决方案： 将redis依赖调高","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"centos8","slug":"centos8","permalink":"https://lyblog2022.github.io/tags/centos8/"}]},{"title":"redis持久化及主从复制","date":"2022-06-23T04:46:55.000Z","path":"2022/06/23/study/redis/redis2/","text":"Redis持久化策略及主从复制 1、Redis持久化策略​ Redis不仅仅是一个内存型数据库，还具备持久化能力。 1.1 RDB​ rdb模式是默认模式，可以在指定的时间间隔内生成数据快照（snapshot），默认保存到dump.rdb文件中。当redis重启后会自动加载dump.rdb文件中内容到内存中。 ​ 用户可以使用SAVE（同步）或BGSAVE（异步）手动保存数据。 ​ 可以设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令，可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行BGSAVE命令。 ​ 例如： ​ save 900 1 save 300 10 save 60 10000 ​ 那么只要满足以下三个条件中的任意一个，BGSAVE命令就会被执行 服务器在900秒之内，对数据库进行了至少1次修改 服务器在300秒之内，对数据库进行了至少10次修改 服务器在60秒之内，对数据库进行了至少10000次修改 1.1.1 优点 rdb文件是一个紧凑文件，直接使用rdb文件就可以还原数据。 数据保存会由一个子进程进行保存，不影响父进程。 恢复数据的效率要高于aof 1.1.2 缺点 每次保存点之间导致redis不可意料的关闭，可能会丢失数据。 由于每次保存数据都需要fork()子进程，在数据量比较大时可能会比较耗费性能。 1.2 AOF​ AOF默认是关闭的，需要在配置文件中开启AOF。Redis支持AOF和RDB同时生效，如果同时存在，AOF优先级高于RDB（Redis重新启动时会使用AOF进行数据恢复） ​ 监听执行的命令，如果发现执行了修改数据的操作，同时直接同步到数据库文件中。 1.2.1 优点​ 相对RDB数据更加安全。 1.2.2 缺点 相同数据集AOF要大于RDB。 相对RDB可能会慢一些。 1.2.3 开启办法​ 修改redis.conf文件 1234# 默认noappendonly yes# aof文件名appendfilename &quot;appendonly.aof&quot; 2、主从复制​ Redis支持集群功能。为了保证单一节点可用性，redis支持主从复制功能。每个节点有N个复制品（replica），其中一个复制品是主（master），另外N-1个复制品是从（Slave），也就是说Redis支持一主多从。 ​ 一个主可有多个从，而一个从又可以看成主，它还可以有多个从。 2.1 主从优点 增加单一节点的健壮性，从而提升整个集群的稳定性。（Redis中当超过1&#x2F;2节点不可用时，整个集群不可用） 从节点可以对主节点数据备份，提升容灾能力。 读写分离。在redis主从中，主节点一般用作写（具备读的能力），从节点只能读，利用这个特性实现读写分离，写用主，读用从。 2.2 一主多从搭建​ 在已经搭建的单机版redis基础上进行操作。 ​ 并且关闭redis单机版 1./redis-cli shutdown 2.2.1 新建目录1mkdir /usr/local/replica 2.2.2 复制目录把之前安装的redis单机版中bin目录复制三份，分别叫做：master、slave1、slave2 123cp -r /usr/local/redis/bin /usr/local/replica/mastercp -r /usr/local/redis/bin /usr/local/replica/slave1cp -r /usr/local/redis/bin /usr/local/replica/slave2 2.2.3 修改从的配置文件​ 修改2个从的redis.conf，指定主节点ip和端口。并修改自身端口号防止和其他redis冲突。 1vim /usr/local/replica/slave1/redis.conf ​ 指定主节点ip和端口 1replicaof 192.168.93.10 6379 ​ 修改自己端口 1port 6380 1vim /usr/local/replica/slave2/redis.conf ​ 指定主节点ip和端口 1replicaof 192.168.93.10 6379 ​ 修改自己端口 1port 6381 2.2.4 启动三个redis实例​ 注意：一定要关闭单机的redis，否则端口冲突。 12cd /usr/local/replicavim startup.sh ​ 在文件中添加下面内容 123456cd /usr/local/replica/master/./redis-server redis.conf cd /usr/local/replica/slave1./redis-server redis.conf cd /usr/local/replica/slave2./redis-server redis.conf ​ 赋予权限 1chmod a+x startup.sh ​ 开启 1./startup.sh 2.2.5 查看启动状态1ps aux|grep redis 2.2.6 测试12cd /usr/local/replica/master/./redis-cli 在客户端命令行模式下，添加一条数据 1127.0.0.1:6379&gt; set demo1 &quot;ly&quot; 进去slave查看数据是否同步。 12cd /usr/local/replica/slave1./redis-cli -p 6380","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"centos8","slug":"centos8","permalink":"https://lyblog2022.github.io/tags/centos8/"}]},{"title":"redis初步使用","date":"2022-06-22T05:13:45.000Z","path":"2022/06/22/study/redis/redis1/","text":"Redis初步学习及使用 1、Redis简介1.1 NoSQL简介​ 目前市场主流数据存储都是使用关系型数据库。每次操作关系型数据库时都是I&#x2F;O操作，I&#x2F;O操作是主要影响程序执行性能原因之一，连接数据库关闭数据库都是消耗性能的过程。尽量减少对数据库的操作，能够明显的提升程序运行效率。 ​ 针对上面的问题，市场上就出现了各种NoSQL(Not Only SQL,不仅仅可以使用关系型数据库)数据库，它们的宣传口号：不是什么样的场景都必须使用关系型数据库，一些特定的场景使用NoSQL数据库更好。 ​ 常见NoSQL数据库： memcached ：键值对，内存型数据库，所有数据都在内存中。 Redis：和Memcached类似，还具备持久化能力。 HBase：以列作为存储。 MongoDB：以Document做存储。 1.2 Redis简介 Redis是以Key-Value形式进行存储的NoSQL数据库。 Redis是使用C语言进行编写的。 平时操作的数据都在内存中，效率特高，读的效率110000&#x2F;s，写81000&#x2F;s，所以多把Redis当做缓存工具使用。 Redis以solt（槽）作为数据存储单元，每个槽中可以存储N多个键值对。Redis中固定具有16384。理论上可以实现一个槽是一个Redis。每个向Redis存储数据的key都会进行crc16算法得出一个值后对16384取余就是这个key存放的solt位置。 同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 2、常用的五大类型​ Redis不仅仅支持简单的k&#x2F;v类型的数据，同时还提供list，set，zset，hash等数据结构的存储，它还支持数据的备份，即master-slave模式的数据备份，同样Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 ​ Redis支持的五大数据类型包括String（字符串 用法： 键 值），Hash（哈希 类似Java中的 map 用法： 键 键值对），List（列表 用法：键 集合 不可以重复），Set（集合 用法：键 集合 可以重复），Zset（sorted set 有序集合 用法： 键 值 值） 2.1 String（字符串） string 是 redis 最基本的类型 可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据 是 Redis 最基本的数据类型 最大能存储 512MB。 应用场景 String是最常用的一种数据类型，普通的key&#x2F;value存储都可以归为此类，value其实不仅是String， 也可以是数字：比如想知道什么时候封锁一个IP地址(访问超过几次)。 2.2 Hash（哈希） Redis hash 是一个键值(key&#x3D;&gt;value)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 使用场景： 存储、读取、修改用户属性 如我们要存储一个用户信息对象数据，包含以下信息： 用户ID，为查找的key，存储的value用户对象包含姓名name，年龄age，生日birthday 等信息， 如果用普通的key&#x2F;value结构来存储，主要有以下2种存储方式： 第一种方式将用户ID作为查找key,把其他信息封装成一个对象以序列化的方式存储， 如：set u001 “李三,18,20010101” 这种方式的缺点是，增加了序列化&#x2F;反序列化的开销，并且在需要修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护，引入CAS等复杂问题。 第二种方法是这个用户信息对象有多少成员就存成多少个key-value对儿，用用户ID+对应属性的名称作为唯一标识来取得对应属性的值， ​ 如：mset user:001:name “李三 “user:001:age18 user:001:birthday “20010101” 虽然省去了序列化开销和并发问题，但是用户ID为重复存储，如果存在大量这样的数据，内存浪费还是非常可观的。 Redis提供的Hash很好的解决了这个问题。 2.3 List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序 可以添加一个元素到列表的头部（左边）或者尾部（右边）。 应用场景： Redis list的应用场景非常多，也是Redis最重要的数据结构之一。 Lists的另一个应用就是消息队列，可以利用Lists的PUSH操作，将任务存在Lists中，然后工作线程再用POP操作将任务取出进行执行。 2.4 Set（集合） Redis的Set是string类型的无序集合 使用场景 共同好友、二度好友 利用唯一性，可以统计访问网站的所有独立 IP 与list区别：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 比如在微博应用中，每个人的好友存在一个集合（set）中，这样求两个人的共同好友的操作，可能就只需要用求交集命令即可。 Redis还为集合提供了求交集、并集、差集等操作，可以非常方便的实 set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。 2.5 zset(sorted set：有序集合) 与set区别及联系：Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 使用场景 带有权重的元素，比如一个游戏的用户得分排行榜 比较复杂的数据结构，一般用到的场景不算太多 3、常用命令Redis命令手册 Redis命令参考","tags":[{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"redis单机版安装","date":"2022-06-22T03:16:38.000Z","path":"2022/06/22/software/redis/","text":"CentOS8安装Redis单机版 1、安装C语言依赖环境​ redis使用C语言编写，所以需要安装C语言库 1yum install -y gcc-c++ automake autoconf libtool make tcl 2、上传并解压​ 把redis-5.0.5.tar.gz上传到/usr/local/tmp中 ​ 解压文件 12cd /usr/local/tmptar zxf redis-5.0.5.tar.gz 3、编译并安装​ 进入解压文件夹 1cd /usr/local/tmp/redis-5.0.5/ ​ 编译 1make ​ 安装 1make install PREFIX=/usr/local/redis 4、开启守护进程复制/usr/local/tmp/redis-5.0.5/中redis.conf配置文件 1cp redis.conf /usr/local/redis/bin/ 修改配置文件 12cd /usr/local/redis/bin/vim redis.conf 把daemonize的值由no修改为yes 5、修改外部访问在redis5中需要修改配置文件redis.conf允许外部访问。需要修改两处。 注释掉bind 127.0.0.1 protected-mode yes 改成 no 6、启动并测试6.1 启动redis1./redis-server redis.conf 6.2 启动客户端工具1./redis-cli 6.3 关闭redis1./redis-cli shutdown","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"}]},{"title":"nginx初步学习","date":"2022-06-21T13:44:31.000Z","path":"2022/06/21/study/nginx/nginx1/","text":"nginx简介及常用命令 1、nginx简介​ Nginx是一个高性能的Web服务器和反向代理的软件 ​ Web服务器：就是运行我们web服务的容器，提供web功能，还有tomcat也提供类似的功能。 ​ 代理是软件架构和网络设计中，非常重要的一个概念。有两种代理：正向代理和反向代理。 1.1 正向代理​ 用户端设置代理服务器。 ​ 所有的请求都由代理服务器发出，无法判断代理了多少用户端，叫正向代理 1.2 反向代理​ 和正向代理相反：在服务端设置代理，所有请求，由服务端接受，然后再由代理服务器发到后方的服务器。 ​ 这么一来，所有请求，都由一个服务器接收，无法判断代理了多少服务端。这就是反向代 理。 ​ 利用反向代理，就可以将请求分发到系统内部的多个节点上，从而减少每个节点的并发数。 ​ 而这些节点在外界看来，就是一个系统，表现出唯一的ip，也就是代理服务器的IP。 1.3 发展历程​ 最初是由一个俄罗斯人（Igor Sysoev：伊戈尔 塞索耶夫）开发的。 ​ Nginx的第一个版本发布于 2004年，因其系统资源消耗低、运行稳定，且具有高性能的并发处理能力等特性，Nginx在互联网 企业中得到广泛应用。 ​ Nginx是互联网上最受欢迎的开源Web服务器之一，Netcraft公司2019年7月 的统计数据表明，Nginx为全球最繁忙网站中的25.42%提供了服务或代理。得益于近几年云计算和 微服务的快速发展，Nginx因在其中发挥了自身优势而得到广泛应用，且有望在未来占有更多的市场 份额。 ​ 2019年3月，著名硬件负载均衡厂商F5宣布收购Nginx，Nginx成为F5的一部分。 2、nginx启动及验证2.1 找到命令目录12[root@192 sbin]# pwd/usr/local/nginx/sbin 2.2 启动123456[root@192 sbin]# ./nginxngx_http_fastdfs_set pid=13620[root@192 sbin]# ps -ef | grep nginxroot 13621 1 0 10:01 ? 00:00:00 nginx: master process ./nginxroot 13622 13621 0 10:01 ? 00:00:00 nginx: worker processroot 13628 3146 0 10:01 pts/0 00:00:00 grep --color=auto nginx 2.3 启动验证 本机访问：Welcome to nginx! 2.4 关闭1234[root@192 sbin]# ./nginx -s quitngx_http_fastdfs_set pid=13727[root@192 sbin]# ps -ef | grep nginxroot 13729 3146 0 10:07 pts/0 00:00:00 grep --color=auto nginx 3、nginx常用命令3.1 查看版本号12[root@192 sbin]# ./nginx -vnginx version: nginx/1.16.1 3.2 关闭nginx12345[root@192 sbin]# ./nginx -s quit[root@192 sbin]# ./nginx -s stopngx_http_fastdfs_set pid=13727[root@192 sbin]# ps -ef | grep nginxroot 13729 3146 0 10:07 pts/0 00:00:00 grep --color=auto nginx 3.3 启动Nginx命令123456[root@192 sbin]# ./nginxngx_http_fastdfs_set pid=13620[root@192 sbin]# ps -ef | grep nginxroot 13621 1 0 10:01 ? 00:00:00 nginx: master process ./nginxroot 13622 13621 0 10:01 ? 00:00:00 nginx: worker processroot 13628 3146 0 10:01 pts/0 00:00:00 grep --color=auto nginx 3.4 重新加载配置文件12[root@192 sbin]# ./nginx -s reloadngx_http_fastdfs_set pid=13917 4、配置文件找到nginx配置文件：&#x2F;etc&#x2F;nginx 指令种类： 简单指令： 块指令： 全局块：就是最开始的简单指令。从配置文件开始到events 1234user nginx;worker_processes auto;error_log /var/log/nginx/error.log notice;pid /var/run/nginx.pid; events块：配置服务器和用户网络连接相关的参数。 http块： 1234567891011121314151617181920212223http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # server块可以是 多个 server &#123; listen 80; # server_name 127.0.0.1; server_name www.cpf.com; # location 块可以是 多 个 location / &#123; proxy_pass http://127.0.0.1:8080; &#125; &#125;&#125;","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"高并发场景下的 httpClient 优化使用","date":"2022-06-21T01:59:25.000Z","path":"2022/06/21/summary/High-concurrency/高并发场景下的httpClient优化使用/","text":"高并发场景下的 httpClient 优化使用，参考自：仰望星空的尘埃 1、HttpClient优化思路 池化 长链接 httpclient和httpget复用 合理的配置参数（最大并发请求数、各种超时时间、重试次数） 异步 源码 2、分析​ 原始的使用比较简单，即每次请求时初始化一个httpclient，生成一个httppost对象，执行，然后从返回结果中取出entity，保存成一个字符串，最后显示关闭response和client 2.1 httpclient反复创建开销​ httpclient是一个线程安全的类，没有必要由每个线程在每次使用时创建，全局保留一个即可 2.2 反复创建tcp连接的开销​ tcp的三次握手四次挥手两大过程，对于高频词的请求来说，消耗过大，如果每次请求需要花费5ms用于协商过程，那么对于qps为100的单系统，1秒钟就要花费500ms用于握手和挥手，so改成keep alive的方式实现连接复用 2.3 重复缓存entity的开销​ 一般情况下，使用了以下的代码 1String resultString = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); ​ 这里相当于额外复制了一份content到一个字符串内，而原本的httpResponse仍然保留了一份content，需要被consume掉，在高并发且content非常大的情况下，会消耗大量内存，并且需要显示的关闭链接 3、实现按照上面的分析，主要完成三件事： 单例的client 缓存的保持链接 更好的处理返回结果 提到连接缓存，很容易想到数据库连接池。httpclient4提供了一个PoolngHttpClientConnectionManager作为连接池。通过以下步骤进行优化 3.1 定义一个keep alive strategy​ 是否使用keep-alive要根据业务情况来定，其并不是灵丹妙药，而且keep-alive和time_wait/close_wait之间也有不少故事 ​ 在本业务场景下，相当于有少数固定的客户端，长时间高频次的访问服务器，启用keep-alive非常合适 ​ 【注意】 http的keep-alive与tcp的KEEPALIVE不是一个东西 定义一个strategy 1234567891011121314151617ConnectionKeepAliveStrategy strategy = new ConnectionKeepAliveStrategy() &#123; @Override public long getKeepAliveDuration(HttpResponse response, HttpContext context) &#123; HeaderElementIterator iterator = new BasicHeaderElementIterator(response.headerIterator(HTTP.CONN_KEEP_ALIVE)); while (iterator.hasNext()) &#123; HeaderElement element = iterator.nextElement(); String param = element.getName(); String value = element.getValue(); if (value != null &amp;&amp; param.equalsIgnoreCase(&quot;timeout&quot;)) &#123; return Long.parseLong(value) * 1000; &#125; &#125; //默认时长为60s return 60 * 1000; &#125;&#125;; 3.2 配置一个PoolingHttpClientConnectionManager1234PoolingHttpClientConnectionManager connectionManager = new PoolingHttpClientConnectionManager();connectionManager.setMaxTotal(500);//默认每个路由最高50并发，也可以针对每个路由设置并发数。connectionManager.setDefaultMaxPerRoute(50); 3.3 生成httpclient1234HttpClientBuilder httpClient = HttpClients.custom();httpClient.setConnectionManager(connectionManager);httpClient.setKeepAliveStrategy(strategy);httpClient.setDefaultRequestConfig(RequestConfig.custom().setStaleConnectionCheckEnabled(true).build()); 【注意】：使用setStaleConnectionCheckEnabled方法来逐出已被关闭的链接不被推荐。更好的方式是手动启用一个线程，定时运行closeExpiredConnections 和closeIdleConnections方法，如下所示。 12345678910111213141516171819202122232425262728293031public static class IdleConnectionMonitorThread extends Thread &#123; private final HttpClientConnectionManager manager; private volatile boolean shutdown; public IdleConnectionMonitorThread(HttpClientConnectionManager manager) &#123; super(); this.manager = manager; &#125; @Override public void run() &#123; try &#123; while(!shutdown)&#123; synchronized (this)&#123; wait(5000); manager.closeExpiredConnections(); manager.closeIdleConnections(30, TimeUnit.SECONDS); &#125; &#125; &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; public void shutdown() &#123; shutdown = true; synchronized (this)&#123; notifyAll(); &#125; &#125;&#125; 3.4 使用httpclient执行method时降低开销这里要注意的是，不要关闭connection。 一种可行的获取内容的方式类似于，把entity里的东西复制一份： 12res = EntityUtils.toString(response.getEntity(),&quot;UTF-8&quot;);EntityUtils.consume(response1.getEntity()); 但是，更推荐的方式是定义一个ResponseHandler，其相关源码如下： 1234567891011121314151617181920212223242526272829303132333435public &lt;T&gt; T execute(final HttpHost target, final HttpRequest request, final ResponseHandler&lt;? extends T&gt; responseHandler, final HttpContext context) throws IOException, ClientProtocolException &#123; Args.notNull(responseHandler, &quot;Response handler&quot;); final HttpResponse response = execute(target, request, context); final T result; try &#123; result = responseHandler.handleResponse(response); &#125; catch (final Exception t) &#123; final HttpEntity entity = response.getEntity(); try &#123; EntityUtils.consume(entity); &#125; catch (final Exception t2) &#123; // Log this exception. The original exception is more // important and will be thrown to the caller. this.log.warn(&quot;Error consuming content after an exception.&quot;, t2); &#125; if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; if (t instanceof IOException) &#123; throw (IOException) t; &#125; throw new UndeclaredThrowableException(t); &#125; // Handling the response was successful. Ensure that the content has // been fully consumed. final HttpEntity entity = response.getEntity(); // EntityUtils.consume(entity); return result; &#125; ​ 可以看到，如果我们使用resultHandler执行execute方法，会最终自动调用consume方法，而这个consume方法如下所示： 1234567891011public static void consume(final HttpEntity entity) throws IOException &#123; if (entity == null) &#123; return; &#125; if (entity.isStreaming()) &#123; final InputStream instream = entity.getContent(); if (instream != null) &#123; instream.close(); &#125; &#125; &#125; ​ 可以看到最终它关闭了输入流。 4、其他​ 通过以上步骤，基本就完成了一个支持高并发的httpclient的写法，下面是一些额外的配置和提醒： 4.1 httpclient的一些超时配置​ CONNECTION_TIMEOUT是连接超时时间，SO_TIMEOUT是socket超时时间，这两者是不同的。连接超时时间是发起请求前的等待时间；socket超时时间是等待数据的超时时间。 1234567891011121314151617181920HttpParams params = new BasicHttpParams();//设置连接超时时间//设置请求超时2秒钟 根据业务调整Integer CONNECTION_TIMEOUT = 2 * 1000; //设置等待数据超时时间2秒钟 根据业务调整Integer SO_TIMEOUT = 2 * 1000; //定义了当从ClientConnectionManager中检索ManagedClientConnection实例时使用的毫秒级的超时时间//这个参数期望得到一个java.lang.Long类型的值。如果这个参数没有被设置，默认等于CONNECTION_TIMEOUT，因此一定要设置。//在httpclient4.2.3中我记得它被改成了一个对象导致直接用long会报错，后来又改回来了Long CONN_MANAGER_TIMEOUT = 500L; params.setIntParameter(CoreConnectionPNames.CONNECTION_TIMEOUT, CONNECTION_TIMEOUT);params.setIntParameter(CoreConnectionPNames.SO_TIMEOUT, SO_TIMEOUT);params.setLongParameter(ClientPNames.CONN_MANAGER_TIMEOUT, CONN_MANAGER_TIMEOUT);//在提交请求之前 测试连接是否可用params.setBooleanParameter(CoreConnectionPNames.STALE_CONNECTION_CHECK, true); //另外设置http client的重试次数，默认是3次；当前是禁用掉（如果项目量不到，这个默认即可）httpClient.setHttpRequestRetryHandler(new DefaultHttpRequestRetryHandler(0, false)); 4.2 如果配置了nginx的话，nginx也要设置面向两端的keep-alive​ 现在的业务里，没有nginx的情况反而比较稀少。nginx默认和client端打开长连接而和server端使用短链接。注意client端的keepalive_timeout和keepalive_requests参数，以及upstream端的keepalive参数设置 ​ 依赖： 123456&lt;!-- httpclient --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.6&lt;/version&gt;&lt;/dependency&gt; 123456789101112//Basic认证private static final CredentialsProvider credsProvider = new BasicCredentialsProvider();//httpClientprivate static final CloseableHttpClient httpclient;//httpGet方法private static final HttpGet httpget;//private static final RequestConfig reqestConfig;//响应处理器private static final ResponseHandler&lt;String&gt; responseHandler;//jackson解析工具private static final ObjectMapper mapper = new ObjectMapper(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static &#123; System.setProperty(&quot;http.maxConnections&quot;,&quot;50&quot;); System.setProperty(&quot;http.keepAlive&quot;, &quot;true&quot;); //设置basic校验 credsProvider.setCredentials( new AuthScope(AuthScope.ANY_HOST, AuthScope.ANY_PORT, AuthScope.ANY_REALM), new UsernamePasswordCredentials(&quot;&quot;, &quot;&quot;)); //创建http客户端 httpclient = HttpClients.custom() .useSystemProperties() .setRetryHandler(new DefaultHttpRequestRetryHandler(3,true)) .setDefaultCredentialsProvider(credsProvider) .build(); //初始化httpGet httpget = new HttpGet(); //初始化HTTP请求配置 reqestConfig = RequestConfig.custom() .setContentCompressionEnabled(true) .setSocketTimeout(100) .setAuthenticationEnabled(true) .setConnectionRequestTimeout(100) .setConnectTimeout(100).build(); httpget.setConfig(reqestConfig); //初始化response解析器 responseHandler = new BasicResponseHandler();&#125;/* * 功能：返回响应 * @author zhangdaquan * @date 2019/1/3 上午11:19 * @param [url] * @return org.apache.http.client.methods.CloseableHttpResponse * @exception */public static String getResponse(String url) throws IOException &#123; HttpGet get = new HttpGet(url); String response = httpclient.execute(get,responseHandler); return response;&#125; /* * 功能：发送http请求，并用net.sf.json工具解析 * @author zhangdaquan * @date 2018/8/15 下午2:21 * @param [url] * @return org.json.JSONObject * @exception */public static JSONObject getUrl(String url) throws Exception&#123; try &#123; httpget.setURI(URI.create(url)); String response = httpclient.execute(httpget,responseHandler); JSONObject json = JSONObject.fromObject(response); return json; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125; 1234567891011121314151617181920212223242526272829303132333435363738/* * 功能：发送http请求，并用jackson工具解析 * @author zhangdaquan * @date 2018/12/24 下午2:58 * @param [url] * @return com.fasterxml.jackson.databind.JsonNode * @exception */public static JsonNode getUrl2(String url)&#123; try &#123; httpget.setURI(URI.create(url)); String response = httpclient.execute(httpget,responseHandler); JsonNode node = mapper.readTree(response); return node; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125;/* * 功能：发送http请求，并用fastjson工具解析 * @author zhangdaquan * @date 2018/12/24 下午2:58 * @param [url] * @return com.fasterxml.jackson.databind.JsonNode * @exception */public static com.alibaba.fastjson.JSONObject getUrl3(String url)&#123; try &#123; httpget.setURI(URI.create(url)); String response = httpclient.execute(httpget,responseHandler); com.alibaba.fastjson.JSONObject jsonObject = com.alibaba.fastjson.JSONObject.parseObject(response); return jsonObject; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125;","tags":[{"name":"httpClient","slug":"httpClient","permalink":"https://lyblog2022.github.io/tags/httpClient/"},{"name":"那些代码那些总结","slug":"那些代码那些总结","permalink":"https://lyblog2022.github.io/tags/%E9%82%A3%E4%BA%9B%E4%BB%A3%E7%A0%81%E9%82%A3%E4%BA%9B%E6%80%BB%E7%BB%93/"},{"name":"接口调用","slug":"接口调用","permalink":"https://lyblog2022.github.io/tags/%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"},{"name":"高并发","slug":"高并发","permalink":"https://lyblog2022.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"}]},{"title":"nginx安装","date":"2022-06-20T08:31:29.000Z","path":"2022/06/20/software/nginx/","text":"centos8安装nginx 1、上传并安装fastdfs-nginx-module​ 上传 &#x2F;fastdfs-nginx-model_v1.16.tar.gz 到 &#x2F;usr&#x2F;local&#x2F;tmp 中 ​ 进入 tmp 目录 1cd /usr/local/tmp ​ 解压 1tar zxf fastdfs-nginx-module_v1.16.tar.gz 2、修改配置文件​ 进入解压目录中src目录 1cd fastdfs-nginx-module/src ​ 编辑config文件 1vim config ​ 修改配置文件中第四行，把路径中local去掉。参数是用于配置安装nginx中的FastDFS组件的时候，在什么位置查找FastDFS核心代码。 1CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot; 3、安装nginx的依赖1yum install -y gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel 4、上传Nginx 并解压​ 上传nginx-1.16.1.tar.gz 到&#x2F;usr&#x2F;local&#x2F;tmp中 12cd /usr/local/tmptar zxf nginx-1.16.1.tar.gz 5、修改Nginx配置5.1 进入到Nginx文件夹1cd nginx-1.16.1 5.2 创建临时目录​ 修改配置文件中好多位置都使用了&#x2F;var&#x2F;temp&#x2F;nginx目录，但是默认不会自动创建这个目录，需要手动创建。 1mkdir -p /var/temp/nginx 5.3 修改配置文件参数内容为： 12345678910111213./configure \\--prefix=/usr/local/nginx \\--pid-path=/var/run/nginx/nginx.pid \\--lock-path=/var/lock/nginx.lock \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path=/var/temp/nginx/client \\--http-proxy-temp-path=/var/temp/nginx/proxy \\--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\--http-scgi-temp-path=/var/temp/nginx/scgi \\--add-module=/usr/local/tmp/fastdfs-nginx-module/src ​ –add-module 必须定义，此配置信息是用于指定安装Nginx时需要加载的模块，如果未指定，Nginx安装过程不会加载fastdfs-nginx-module模块，后续功能无法实现。 【报错：执行文件无权限】 先执行以下命令： 1chmod +x configure ​ 再继续执行后续代码 6、编译并安装12makemake install 7、配置fastdfs-nginx-module模块配置文件​ 复制配置文件fastdfs-nginx-module&#x2F;src&#x2F;mod_fastdfs.conf 到 &#x2F;etc&#x2F;fdfs目录中 1cp /usr/local/tmp/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ 8、修改 mod_fastdfs.conf8.1 进入到 &#x2F;etc&#x2F;fdfs1cd /etc/fdfs 8.2 编辑配置文件1vim mod_fastdfs.conf 8.3 文件内容修改​ 需要修改文件中四处内容， 这四处内容的含义： ​ connect_timeout&#x3D;2 #连接超时时间，单位秒 ​ tracker_server&#x3D;tracker:22122 #tracker 服务结点 ​ url_have_group_name&#x3D;false #URL是否包含group名称 ​ store_path0&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs #storage服务结点的存储位置，与配置storage结点一致 ​ 修改为以下内容 1234connect_timeout=10tracker_server=192.168.93.10:22122url_have_group_name=truestore_path0=/usr/local/fastdfs/storage/store 9、提供FastDFS需要的HTTP配置文件​ 复制FastDFS安装包中的两个配置文件(http.conf 和 mine.types) 到 &#x2F;etc&#x2F;fdfs目录中 12cp /usr/local/tmp/FastDFS/conf/http.conf /etc/fdfs/cp /usr/local/tmp/FastDFS/conf/mime.types /etc/fdfs/ 10、创建网络访问存储服务的软连接​ 在上传文件到FastDFS后，FastDFS会返回group1&#x2F;M00&#x2F;00&#x2F;00&#x2F;xxxxxxxxx.xxx其中group1是卷名，在mod_fastdfs.conf配置文件中已配置了url_have_group_name， 以保证URL解析正确。其中的M00是FastDFS保存数据时使用的虚拟目录， 需要将这个虚拟目录定位到真实数据目录上。 1ln -s /usr/local/fastdfs/storage/store/data/ /usr/local/fastdfs/storage/store/data/M00 11、修改nginx配置文件11.1 进入到安装后 nginx目录1cd /usr/local/nginx/conf 11.2 编辑配置文件1vim nginx.conf 11.2.1 修改1​ user root； #Nginx需要访问linux文件系统，必须有文件系统的权限。User root代表nginx文件系统的权限是root用户权限。如果不开启权限，可能有404反问错误。 123user root;worker_processes 1; 11.2.2 修改21234567server&#123; listen 8888; #storage 配置中， 有http.server_port=8888的配置信息，必须一致。配置文件是 /etc/fdfs/storaged.conf server_name localhost; location ~/group([0-9])/M00&#123; ngx_fastdfs_module; &#125;&#125; 12、启动nginx进入到nginx安装目录的sbin文件夹 1cd /usr/local/nginx/sbin/ 启动nginx 1./nginx 关闭nginx 1./nginx -s quit","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"}]},{"title":"FastDFS实现图片上传及下载","date":"2022-06-20T05:21:29.000Z","path":"2022/06/20/study/FastDFS/FastDFS-file1/","text":"FastDFS简介及简单实现图片上传及下载 1、分布式文件系统概述1.1 分类1.1.1 通用分布式文件系统​ 和传统的本地文件系统（如ext3、NTFS等）相对应。典型代表：lustre、MooseFS 优点：标准文件系统操作方式，对开发者门槛较低 缺点： 系统复杂性较高，需要支持若干标准的文件操作，如：目录结构、文件读写权限、文件锁等。复杂性更高 系统整体性能有所降低，因为要支持POSIX标准（表示可移植操作系统接口（Portable Operating System Interface of UNIX），POSIX标准定义了操作系统应该为应用程序提供的接口标准） 1.1.2 专用分布式文件系统​ 基于google File System的思想，文件上传后不能修改。需要使用专有API对文件进行访问，也可称作分布式文件存储服务。典型代表：MogileFS、FastDFS、TFS。 优点： 系统复杂性较低，不需要支持若干标准的文件操作，如：目录结构、文件读写权限、文件锁等，系统比较简洁。 系统整体性能较高，因为无需支持POSIX标准，可以省去支持POSIX引入的环节，系统更加高效。 缺点：采用专有API，对开发者门槛较高（直接封装成工具类） 1.2 Google FS 体系结构 两个角色： 名字服务器（索引服务器） 存储服务器 架构特点 不支持文件修改功能。 文件分块存储，需要索引服务器 一个文件可以存储多份，一个文件存储到哪些存储服务器，通常采用动态分配的方式。 2、FastDFS2.1 简介​ FastDFS是一个轻量级的开源分布式文件系统。2008年4月份开始启动。类似google FS的一个轻量级分布式文件系统，纯C实现，支持Linux、FreeBSD、AIX等UNIX系统。 ​ 主要解决了大容量的文件存储和高并发访问的问题，文件存取时实现了负载均衡。实现了软件方式的磁盘阵列（Redundant Arrays of Independent Drives，RAID），可以使用廉价的IDE（Integrated Drive Electronics）硬盘进行存储。并且支持存储服务器在线扩容。支持相同内容的文件只保存一份，节约磁盘空间。 ​ FastDFS只能通过Client API访问，不支持POSIX访问方式。 ​ FastDFS特别适合大中型网站使用，用来存储资源文件（如：图片、文档、音频、视频等等） 2.2 架构 2.2.1 角色 Client：客户端。使用java语言编写的项目属于客户端。 Tracker Server：跟踪服务器，主要做调度工作，在访问上起负载均衡的作用。在内存中记录集群中group和storage server的状态信息，是连接Client和Storage server的枢纽。 Storage Server：存储服务器，文件和文件属性（meta data）都保存到存储服务器上 2.2.2 架构解读​ 只有两个角色，tracker server和storage server，不需要存储文件索引信息。 ​ 所有服务器都是对等的，不存在Master-Slave关系。 ​ 存储服务器采用分组方式，同组内存储服务器上的文件完全相同（RAID 1）。 ​ 不同组的storage server之间不会相互通信。 ​ 由storage server主动向tracker server报告状态信息，tracker server之间不会相互通信。 1、文件上传1.1 时序图 1.2 流程说明 客户端访问Tracker Tracker 返回Storage的ip和端口 客户端直接访问Storage，把文件内容和元数据发送过去。 Storage返回文件存储id。包含了组名和文件名 1.3 Fastdfs-java-client1.3.1 添加依赖123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.bestwu&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ` 1.3.2 编写配置文件​ 文件名：fdfs_client.conf 12345connect_timeout = 10network_timeout = 30charset = UTF-8http.tracker_http_port = 8080tracker_server = 192.168.213.133:22122 1.3.3 导入工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205package com.util;import java.io.ByteArrayInputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import org.apache.commons.lang3.StringUtils;import org.csource.common.NameValuePair;import org.csource.fastdfs.ClientGlobal;import org.csource.fastdfs.StorageClient;import org.csource.fastdfs.StorageClient1;import org.csource.fastdfs.StorageServer;import org.csource.fastdfs.TrackerClient;import org.csource.fastdfs.TrackerServer;/** * FastDFSClient * * @author liuyong * @version 1.0 * @description com.util * @date 2022/6/19 19:40 */public class FastDFSClient &#123; private static final String CONF_FILENAME = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath() + &quot;fdfs_client.conf&quot;; private static StorageClient storageClient = null; /** * 只加载一次. */ static &#123; try &#123; ClientGlobal.init(CONF_FILENAME); TrackerClient trackerClient = new TrackerClient(ClientGlobal.g_tracker_group); TrackerServer trackerServer = trackerClient.getConnection(); StorageServer storageServer = trackerClient.getStoreStorage(trackerServer); storageClient = new StorageClient(trackerServer, storageServer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * * @param inputStream * 上传的文件输入流 * @param fileName * 上传的文件原始名 * @return */ public static String[] uploadFile(InputStream inputStream, String fileName) &#123; try &#123; // 文件的元数据 NameValuePair[] meta_list = new NameValuePair[2]; // 第一组元数据，文件的原始名称 meta_list[0] = new NameValuePair(&quot;file name&quot;, fileName); // 第二组元数据 meta_list[1] = new NameValuePair(&quot;file length&quot;, inputStream.available()+&quot;&quot;); // 准备字节数组 byte[] file_buff = null; if (inputStream != null) &#123; // 查看文件的长度 int len = inputStream.available(); // 创建对应长度的字节数组 file_buff = new byte[len]; // 将输入流中的字节内容，读到字节数组中。 inputStream.read(file_buff); &#125; // 上传文件。参数含义：要上传的文件的内容（使用字节数组传递），上传的文件的类型（扩展名），元数据 String[] fileids = storageClient.upload_file(file_buff, getFileExt(fileName), meta_list); return fileids; &#125; catch (Exception ex) &#123; ex.printStackTrace(); return null; &#125; &#125; /** * * @param file * 文件 * @param fileName * 文件名 * @return 返回Null则为失败 */ public static String[] uploadFile(File file, String fileName) &#123; FileInputStream fis = null; try &#123; NameValuePair[] meta_list = null; // new NameValuePair[0]; fis = new FileInputStream(file); byte[] file_buff = null; if (fis != null) &#123; int len = fis.available(); file_buff = new byte[len]; fis.read(file_buff); &#125; String[] fileids = storageClient.upload_file(file_buff, getFileExt(fileName), meta_list); return fileids; &#125; catch (Exception ex) &#123; return null; &#125;finally&#123; if (fis != null)&#123; try &#123; fis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 根据组名和远程文件名来删除一个文件 * * @param groupName * 例如 &quot;group1&quot; 如果不指定该值，默认为group1 * @param remoteFileName * 例如&quot;M00/00/00/wKgxgk5HbLvfP86RAAAAChd9X1Y736.jpg&quot; * @return 0为成功，非0为失败，具体为错误代码 */ public static int deleteFile(String groupName, String remoteFileName) &#123; try &#123; int result = storageClient.delete_file(groupName == null ? &quot;group1&quot; : groupName, remoteFileName); return result; &#125; catch (Exception ex) &#123; return 0; &#125; &#125; /** * 修改一个已经存在的文件 * * @param oldGroupName * 旧的组名 * @param oldFileName * 旧的文件名 * @param file * 新文件 * @param fileName * 新文件名 * @return 返回空则为失败 */ public static String[] modifyFile(String oldGroupName, String oldFileName, File file, String fileName) &#123; String[] fileids = null; try &#123; // 先上传 fileids = uploadFile(file, fileName); if (fileids == null) &#123; return null; &#125; // 再删除 int delResult = deleteFile(oldGroupName, oldFileName); if (delResult != 0) &#123; return null; &#125; &#125; catch (Exception ex) &#123; return null; &#125; return fileids; &#125; /** * 文件下载 * * @param groupName 卷名 * @param remoteFileName 文件名 * @return 返回一个流 */ public static InputStream downloadFile(String groupName, String remoteFileName) &#123; try &#123; byte[] bytes = storageClient.download_file(groupName, remoteFileName); InputStream inputStream = new ByteArrayInputStream(bytes); return inputStream; &#125; catch (Exception ex) &#123; return null; &#125; &#125; public static NameValuePair[] getMetaDate(String groupName, String remoteFileName)&#123; try&#123; NameValuePair[] nvp = storageClient.get_metadata(groupName, remoteFileName); return nvp; &#125;catch(Exception ex)&#123; ex.printStackTrace(); return null; &#125; &#125; /** * 获取文件后缀名（不带点）. * * @return 如：&quot;jpg&quot; or &quot;&quot;. */ private static String getFileExt(String fileName) &#123; if (StringUtils.isBlank(fileName) || !fileName.contains(&quot;.&quot;)) &#123; return &quot;&quot;; &#125; else &#123; return fileName.substring(fileName.lastIndexOf(&quot;.&quot;) + 1); // 不带最后的点 &#125; &#125;&#125; 1.3.4编写测试代码1234567891011public static void main(String[] args) &#123; try &#123; File file = new File(&quot;E:\\\\note\\\\source\\\\_posts\\\\software\\\\FastDFS\\\\fastdfs.png&quot;); InputStream is = new FileInputStream(file); String fileName = UUID.randomUUID().toString()+&quot;.png&quot;; String[] result = FastDFSClient.uploadFile(is, fileName); System.out.println(Arrays.toString(result)); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; 2、文件下载2.1 时序图 2.2 下载说明 client询问tracker下载文件的storage，参数为文件标识（组名和文件名）； tracker返回一台可用的storage； client直接和storage通讯完成文件下载。 2.3 测试代码直接使用工具方法完成下载。 123456789101112131415161718192021222324252627282930313233package com.down;import com.util.FastDFSClient;import java.io.*;/** * Download * * @author liuyong * @version 1.0 * @description com.down * @date 2022/6/19 20:09 */public class Download &#123; public static void main(String[] args) &#123; try &#123; InputStream is = FastDFSClient.downloadFile(&quot;group1&quot;, &quot;M00/00/00/wKjVhWKvD_iAZ0rRAACDGmk1a_U227.png&quot;); OutputStream os = new FileOutputStream(new File(&quot;E:/jqk.png&quot;)); int index = 0 ; while((index = is.read())!=-1)&#123; os.write(index); &#125; os.flush(); os.close(); is.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;","tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"https://lyblog2022.github.io/tags/FastDFS/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"FastDFS安装","date":"2022-06-19T06:02:05.000Z","path":"2022/06/19/software/FastDFS/","text":"CentOS8安装FastDFS 1、安装FastDFS依赖 FastDFS是C语言开发的应用。安装必须使用 make , cmake 和 gcc编译器。 1yum install -y make cmake gcc gcc-c++ 2、上传并解压libfastcommon-master上传libfastcommon-master 到 &#x2F;usr&#x2F;local&#x2F;tmp下。 libfastcommon是从FastDFS和FastDHT中提取出来的公共C函数库 解压 libfastcommon-master.zip 由于是zip文件所以要使用 unzip命令 12cd /usr/local/tmpunzip libfastcommon-master.zip 3、编译并安装libfastcommon没有提供make命令安装文件。使用的是shell脚本执行编译和安装。shell脚本为 make.sh 进入解压后的文件 1cd libfastcommon-master 编译 1./make.sh 安装 1./make.sh install 有固定的默认安装位置。在&#x2F;usr&#x2F;lib64 和 &#x2F;usr&#x2F;include&#x2F;fastcommon两个目录中 4、创建软连接 因为FastDFS 主程序设置的lib目录是 &#x2F;usr&#x2F;local&#x2F;lib， 所以需要创建软连接 12ln -s /user/lib64/libfastcommon.so /usr/local/lib/libfastcommon.soln -s /usr/local/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so 5、上传并解压FastDFS主程序上传 FastDFS_v5.08.tar.gz 到 &#x2F;usr&#x2F;local&#x2F;tmp下后解压 12cd /usr/local/tmptar zxf FastDFS_v5.08.tar.gz 6、编译并安装FastDFS进入到解压后的FastDFS文件中 1cd FastDFS 编译 1./make.sh 安装 1./make.sh install ​ 安装后 FastDFS主程序所在的位置是 ​ &#x2F;usr&#x2F;bin 可执行文件所在的位置 ​ &#x2F;etc&#x2F;fdfs 配置文件所在的位置 ​ &#x2F;usr&#x2F;bin 主程序代码所在位置 ​ &#x2F;usr&#x2F;include&#x2F;fastdfs 包含一些插件组所在的位置 7、配置tracker7.1 复制配置文件进入到 &#x2F;etc&#x2F;fdfs 中 ， 把tracker配置文件复制一份 12cd /etc/fdfscp tracker.conf.sample tracker.conf 7.2 创建数据目录创建放置 tracker数据的目录 1mkdir -p /usr/local/fastdfs/tracker 7.3 修改配置文件修改 tracker.conf 设置 tracker 内容存储目录 base_path&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;tracker 1vim tracker.conf 7.4 启动服务1service fdfs_trackerd start 启动成功后， 配置文件中 base_path 指向的目录出现 FastDFS服务相关数据目录(data目录， logs 目录) 7.5 查看服务运行状态1service fdfs_trackerd status 如果显示 is running 表示正常运行。 8、配置storage storage可以和tracker不在同一台服务器上。示例中把storage和tracker安装在同一台服务器上了。 8.1 复制配置文件进入到 &#x2F;etc&#x2F;fdfs, 把 storage 配置文件复制一份 12cd /etc/fdfscp storage.conf.sample storage.conf 8.2 创建目录创建两个目录， 把base用于存储基础数据和日志，store用于存储上传数据。 12mkdir -p /usr/local/fastdfs/storage/basemkdir -p /usr/local/fastdfs/storage/store 8.3 修改配置文件​ storage.conf配置文件用于描述存储服务的行为，需要进行下述修改 1vim /etc/fdfs/storage.conf 配置内容如下： 123base_path=/usr/local/fastdfs/storage/basestore_path0=/usr/local/fastdfs/storage/storetracker_server=tracker的服务IP：22122 ​ base_path - 基础路径。用于保存storage server 基础数据内容和日志内容的目录。 ​ store_path0 - 存储路径。是用于保存FastDFS中存储文件的目录，就是要创建256*256个子目录的位置。 ​ base_path 和 store_path0 可以使用同一个目录。 ​ tracker_server - 跟踪服务器位置。就是跟踪服务器的IP和端口。 ​ 启动服务 1service fdfs_storaged start ​ 启动成功后，配置文件中base_path 指向的目录中出现FastDFS服务相关数据目录（data目录、logs目录）配置文件中的store_path0指向的目录中同样出现FastDFS存储相关数据录（data目录）。其中$store_path0&#x2F;data&#x2F;目录中默认创建若干子孙目录（两级目录层级总计256*256个目录），是用于存储具体文件数据的。 ​ Storage 服务器启动比较慢，因为第一次启动的时候，需要创建256*256个目录。 ​ 查看启动状态 1service fdfs_storaged status","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"FastDFS","slug":"FastDFS","permalink":"https://lyblog2022.github.io/tags/FastDFS/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"}]},{"title":"dubbo项目","date":"2022-06-12T02:28:02.000Z","path":"2022/06/12/study/dubbo/dubbo项目/","text":"dubbo简单的小项目 1、原型1.1 部门原型​ 显示全部部门信息 1.2 员工新增 1.3 查看部门员工 2、按照分布式架构进行设计项目​ 设定员工管理和部门管理不在同一个模块中，需要有一个员工管理项目和一个部门管理项目。 ​ 为了方便，不去每个项目使用一个窗口，而是使用聚合项目。 3、创建数据库123456789101112131415create table dept(id int(11) primary key auto_increment,name varchar(20));insert into dept values(default,&#x27;开发部&#x27;);insert into dept values(default,&#x27;产品部&#x27;);create table emp(id int(11) primary key auto_increment,name varchar(20),photo varchar(200),did int(11),CONSTRAINT fk_emp_dept FOREIGN key (did) REFERENCES dept(id));","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"dubbo","slug":"dubbo","permalink":"https://lyblog2022.github.io/tags/dubbo/"},{"name":"项目","slug":"项目","permalink":"https://lyblog2022.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"dubbo学习","date":"2022-06-11T11:51:20.000Z","path":"2022/06/11/study/dubbo/dubbo学习/","text":"dubbo基础学习、架构、支持的协议及注册中心学习，一个简单的Demo项目及负载均衡的简单配置 1、简介​ Apache Dubbo 是一个高可用的，基于Java的开源RPC框架。 ​ Dubbo框架不仅仅是具备RPC访问功能，还包含服务治理功能。 1.1 发展历程​ Dubbo是最开始是阿里巴巴内部使用的RPC框架。 ​ 2011年对外提供。 ​ 2012年停止更新。 ​ 2017年开始继续更新。 ​ 2019年捐献给Apache，由Apache维护2.7以上版本。 1.2 架构 线条：虚线表示异步，实线表示同步。异步不阻塞线程性能高，同步阻塞线程必须等待响应结果才能继续执行，相对性能低。 provider：提供者。编写持久层和事务代码。 container：容器（Spring容器），Dubbo完全基于Spring实现的。 register：注册中心。放置所有Provider对外提供的信息。包含Provider的IP，访问端口，访问遵守的协议，对外提供的接口，接口中有哪些方法等相关信息。 consumer：消费者（RPC调用者，SOA调用服务的项目）开发中也是一个项目，编写service和controller（还可以报页面等）。调用XXXXServiceImpl中的方法。 monitor：监控中心。监控Provider的压力情况等。每隔2分钟Consumer和Provider会把调用次数发送给Monitor，由Monitor进行统计。 执行流程： start：启动Spring容器时会把Provider启动。 register：把Provider相关信息注册到Registry里 subscribe：Consumer从Registry中订阅Provider的信息 notify：通知给Consumer invoke：Consumer根据Registry通知的信息进行调用Provider中方法。 count:Consumer和Provider把调用次数信息异步发送给Monitor进行统计。 2、支持的协议2.1 Dubbo协议（官方推荐）​ 优点： ​ 采用NIO复用单一长连接，并使用线程池并发处理请求，减少握手和加大并发效率，性能较好（推荐使用） ​ 缺点： ​ 大文件上传时,可能出现问题(不使用Dubbo文件上传) 2.2 RMI（Remote Method Invocation）协议​ 优点: ​ JDK自带的能力。 ​ 缺点: ​ 偶尔连接失败 2.3 Hessian协议​ 优点: ​ 可与原生Hessian互操作，基于HTTP协议 ​ 缺点: ​ 需hessian.jar支持，http短连接的开销大 3、支持的注册中心3.1 Zookeeper（官方推荐）​ 优点: ​ 支持分布式.很多周边产品 ​ 缺点: ​ 受限于Zookeeper软件的稳定性.Zookeeper专门分布式辅助软件,稳定较优 3.2 Multicast​ 优点: ​ 去中心化,不需要单独安装软件. ​ 缺点: ​ Provider和Consumer和Registry不能跨机房(路由) 3.3 Redis​ 优点: ​ 支持集群,性能高 ​ 缺点: ​ 要求服务器时间同步.否则可能出现集群失败问题. 3.4 Simple​ 优点: ​ 标准RPC服务.没有兼容问题 ​ 缺点: ​ 不支持集群. 4、项目Demo​ 新建父项目Dubbo ​ pom： 1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.10.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 4.1 创建子项目api创建类DemoService（dubbo） 12345678910111213package com.dubbo.service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 20:55 * @Description: com.dubbo.service * @Version: 1.0 */public interface DemoService &#123; public String demo(String param);&#125; 4.2 创建provider项目1、添加pom依赖 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt; 2、创建实现类 12345678910111213141516171819package com.dubbo.service.Impl;import com.dubbo.service.DemoService;import org.apache.dubbo.config.annotation.Service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:01 * @Description: com.dubbo.service.Impl * @Version: 1.0 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Override public String demo(String param) &#123; System.out.println(&quot;demo 已执行&quot;); return param+&quot;xxxxxxxxxxx&quot;; &#125;&#125; 3、创建application.yml配置 12345dubbo: application: name: dubbo-provider registry: address: zookeeper://192.168.253.132:2181 4.3 创建consume子项目1、添加pom依赖 1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt; 2、创建Service接口(springboot) 12345678910111213package com.service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:07 * @Description: com.service * @Version: 1.0 */public interface DemoService &#123; public String demo();&#125; 3、创建Service接口实现类（springboot） 1234567891011121314151617181920212223242526package com.service.Impl;import com.service.DemoService;import org.apache.dubbo.config.annotation.Reference;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:07 * @Description: com.service.Impl * @Version: 1.0 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Reference private com.dubbo.service.DemoService demoService; @Override public String demo() &#123; return demoService.demo(&quot;张三&quot;); &#125;&#125; 4、创建controller控制了 1234567891011121314151617181920212223242526package com.controller;import com.service.DemoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:11 * @Description: com.controller * @Version: 1.0 */@RestControllerpublic class DemoController &#123; @Autowired private DemoService demoService; @RequestMapping(&quot;/demo&quot;) public String demo() &#123; return demoService.demo(); &#125;&#125; 5、添加配置文件 12345dubbo: application: name: dubbo-consumer registry: address: zookeeper://192.168.253.132:2181 4.4 运行项目运行顺序：先启动provider，再启动consume 控制台运行结果： dubbo运行结果 4.5 运行异常启动provider和consume报错 解决方案： 添加一下依赖即可： 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-x-discovery --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-x-discovery&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt;&lt;/dependency&gt; 5、搭建admin管理界面使用jar文件 dubbo-admin-0.2.0.jar 将jar文件内配置文件的地址改为本地的zookeeper地址 1234# centers in dubbo2.7admin.registry.address=zookeeper://192.168.253.132:2181admin.config-center=zookeeper://192.168.253.132:2181admin.metadata-report.address=zookeeper://192.168.253.132:2181 使用 java -jar命令运行jar文件 6、负载均衡 集群：一个内容，部署多次，形成的整体称为集群。集群中每个个体应该部署到不同的服务器上。 伪集群：集群中内容部署到同一台服务器上，通过不同端口区分不同个体。 负载均衡是在集群前提下，当访问整个集群时，集群中每个节点被访问次数或频率的规则。 Dubbo 内置了四个负载均衡策略。默认为Random 6.1 内置策略 Random：随机。随机访问集群中节点。访问概率和权重有关。 RoundRobin：轮询。访问频率和权重有关。 权重（weight）：占有比例。集群中每个项目部署的服务器的性能可能是不同，性能好的服务器权重应该高一些。 LeastActive：活跃数相同的随机，不同的活跃数高的放前面。 ConsistentHash：一致性Hash。相同参数请求总是发到一个提供者。 6.2 设置负载均衡6.2.1 @Reference​ 调用的服务采用的负载均衡 12@Reference(loadbalance = &quot;roundrobin&quot;)private DemoService demoService; 6.2.2 @Service​ 当前服务采用的负载均衡算法 12@Service(loadbalance = &quot;random&quot;)public class DemoServiceImpl implements DemoService &#123; ​ 设置权重 1@Service(weight = 4) 6.2.3 配置文件​ 全局设置所有provider和consumer的负载均衡效果 1234567891011dubbo: application: name: dubbo-provider registry: address: zookeeper://192.168.32.128:2181 protocol: port: 20884 provider: loadbalance: random consumer: loadbalance: random","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"dubbo","slug":"dubbo","permalink":"https://lyblog2022.github.io/tags/dubbo/"}]},{"title":"手写rpc框架","date":"2022-06-09T05:01:35.000Z","path":"2022/06/09/study/手写rpc框架/","text":"使用Zookeeper作为注册中心，RMI作为连接技术，手写RPC框架。 1、创建RPCClient项目创建父项目RPCClient 包含三个子项目 pojo: service中需要的实体类 service：包含被serviceimpl和consumer依赖的接口。 serviceimpl:provider提供的服务内容 consumer：消费者，调用服务内容。 2、pojo项目在父项目下新建子项目pojo 该子项目包括一个文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com;import java.io.Serializable;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:04 * @Description: com * @Version: 1.0 */public class User implements Serializable &#123; private Integer id; private String name; public User() &#123; &#125; public User(Integer id, String name) &#123; this.id = id; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 3、service项目添加依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 新建MyService接口，继承Remote类 12345678910111213141516171819package com.service;import com.User;import java.rmi.Remote;import java.rmi.RemoteException;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:06 * @Description: com * @Version: 1.0 */public interface MyService extends Remote &#123; public List&lt;User&gt; findAll() throws RemoteException;&#125; 4、provider项目添加依赖 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 新建ProviderRun类 123456789101112131415161718192021222324252627282930313233343536373839404142package com;import com.service.Impl.MyServiceImpl;import com.service.MyService;import org.apache.zookeeper.*;import java.nio.charset.StandardCharsets;import java.rmi.Naming;import java.rmi.Remote;import java.rmi.registry.LocateRegistry;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:15 * @Description: com * @Version: 1.0 */public class ProviderRun &#123; public static void main(String[] args) &#123; try &#123; MyService service = new MyServiceImpl(); LocateRegistry.createRegistry(8989); String url = &quot;rmi://localhost:8989/myService&quot;; Naming.bind(url, service); System.out.println(&quot;MRI服务启动成功！&quot;); //创建zookeeper并发布信息 ZooKeeper zooKeeper = new ZooKeeper(&quot;192.168.253.132:2181&quot;, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;获取链接&quot;); &#125; &#125;); //运行前确保/rpc目录存在 zooKeeper.create(&quot;/rpc/provider&quot;,url.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(&quot;注册成功&quot;); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 运行项目，打开zookeeper，查看是否写入到&#x2F;rpc&#x2F;provider 5、consume项目添加依赖 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建service接口 123456789101112131415package com.consumer.service;import com.User;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:36 * @Description: com.consumer.service * @Version: 1.0 */public interface PageService &#123; public List&lt;User&gt; show();&#125; 创建其实现类 123456789101112131415161718192021222324252627282930313233343536373839404142package com.consumer.service.Impl;import com.User;import com.consumer.service.PageService;import com.service.MyService;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import org.springframework.stereotype.Service;import java.rmi.Naming;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:37 * @Description: com.consumer.service.Impl * @Version: 1.0 */@Servicepublic class PageServiceImpl implements PageService &#123; @Override public List&lt;User&gt; show() &#123; try &#123; ZooKeeper zooKeeper = new ZooKeeper(&quot;192.168.253.132:2181&quot;, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;链接成功&quot;); &#125; &#125;); byte[] bytes = zooKeeper.getData(&quot;/rpc/provider&quot;,false,null); MyService myService = (MyService) Naming.lookup(new String(bytes)); return myService.findAll(); &#125; catch (Exception e)&#123; e.printStackTrace(); return null; &#125; &#125;&#125; 创建控制器 12345678910111213141516171819202122232425262728package com.consumer.controller;import com.User;import com.consumer.service.PageService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 22:19 * @Description: com.consumer.controller * @Version: 1.0 */@RestControllerpublic class PageController &#123; @Autowired private PageService pageService; @RequestMapping(&quot;/show&quot;) public List&lt;User&gt; show() &#123; return pageService.show(); &#125;&#125; 启动springboot项目，输入localhost:8080&#x2F;show","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"RPC","slug":"RPC","permalink":"https://lyblog2022.github.io/tags/RPC/"}]},{"title":"zookeeper使用","date":"2022-06-07T13:17:08.000Z","path":"2022/06/07/study/zookeeper使用/","text":"zookeeper内容发布及消息订阅 1、向zookeeper中注册内容新建项目ZookeeperClient 1.1 创建&#x2F;demo使用zookeeper的客户端命令工具创建&#x2F;demo 12./zkCli.shcreate /demos 1.2 添加依赖1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1.3 编写代码1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; try &#123; /** * 创建zookeeper对象 * 参数1：zookeeper IP+端口 * 参数2：访问超时设置 * 参数3：链接成功后，编写成功信息 */ String ip = &quot;192.168.253.132:2181&quot;; ZooKeeper zooKeeper = new ZooKeeper(ip, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;获取链接&quot;); &#125; &#125;); /** * 向zookeeper发送内容 * 参数1：发送的文件 * 参数2：发送的内容 * 参数3：权限 * 参数4：内容的模式 */ String content = zooKeeper.create(&quot;/demo/rmi-adress&quot;,&quot;rmi:localhost:8080/demoService&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL); System.out.println(&quot;content=&quot;+content); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; 1.4 控制台输出 1.5 zookeeper输出 1.6 异常 解决方案—-防火墙未关闭 查看防火墙状态 1systemctl status firewalld.service active表示当前防火墙处于开启状态 inactive表示关闭状态systemctl stop firewalld.service （关闭防火墙）systemctl start firewalld.service （开启防火墙）systemctl disable firewalld.service （禁止防火墙自启动）systemctl enable firewalld.service （防火墙随系统开启启动） 关闭防火墙即可 1.7 异常2—6.8新增如果在关闭防火墙后仍出现以上问题 解决方案–用记事本打开C:\\Windows\\System32\\drivers\\etc\\hosts文件，添加ZooKeeper部署的服务器ip，然后保存。 2、zookeeper消息订阅2.1 编写代码12345678910111213141516171819202122232425262728try &#123; /** * 创建zookeeper对象 * 参数1：zookeeper IP+端口 * 参数2：访问超时设置 * 参数3：链接成功后，编写成功信息 */ String ip = &quot;192.168.253.132:2181&quot;; ZooKeeper zooKeeper = new ZooKeeper(ip, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;获取链接&quot;); &#125; &#125;); //从zookeeper中获取内容 //2.1获取节点 List&lt;String&gt; list = zooKeeper.getChildren(&quot;/demo&quot;,false); System.out.println(list); //获取内容 for(String child:list)&#123; byte[] result = zooKeeper.getData(&quot;/demo/&quot;+child,false,null); System.out.println(new String(result)); &#125; &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; 2.2 控制台输出结果","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"zookeeper常用命令","date":"2022-06-07T12:53:54.000Z","path":"2022/06/07/study/zookeeper/","text":"zookeeper常用命令 1、lsls -s&#x2F;path -s 详细信息，替代老版本ls2 -R 当前目录和子目录中内容都罗列出来 例如：ls -R &#x2F; 显示根目录下所有内容 2、createcreate &#x2F;path [data] [data] 包含内容 创建指定路径信息 例如：create &#x2F;demo 创建&#x2F;demo 3、getget [-s] &#x2F;path [-s] 详细信息 查看指定路径下内容。 例如： get -s &#x2F;demo null:存放的数据 cZxid:创建时zxid(znode每次改变时递增的事务id) ctime:创建时间戳 mZxid:最近一次更新的zxid mtime:最近一次更新的时间戳 pZxid:子节点的zxid cversion:子节点更新次数 dataversion:节点数据更新次数 aclVersion:节点ACL(授权信息)的更新次数 ephemeralOwner:如果该节点为ephemeral节点(临时，生命周期与session一样), ephemeralOwner值表示与该节点绑定的session id. 如果该节点不是ephemeral节点, ephemeralOwner值为0. dataLength:节点数据字节数 numChildren:子节点数量 4、setset &#x2F;path data 设置节点内容 5、deletedelete &#x2F;path 删除节点","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"CentOS 8 安装zookeeper","date":"2022-06-06T13:43:24.000Z","path":"2022/06/06/software/zookeeper/","text":"CentOS8安装zookeeper 1、检验java环境1java -version 2、安装wget,供文件下载时使用:1yum install wget 3、下载zookeeper1wget https://downloads.apache.org/zookeeper/zookeeper-3.8.0/apache-zookeeper-3.8.0-bin.tar.gz 4、解压，安装12345cd /usrmkdir zookeepercd ./zookeepertar -zxvf apache-zookeeper-3.8.0-bin.tar.gzmv apache-zookeeper-3.8.0-bin/ /usr/local/soft/ 这块我出现点问题，直接在跟目录下下载的，最好新建一个文件夹 5、创建数据和日志目录1234mkdir -p /data/zookeepermkdir -p /data/zookeeper/datamkdir -p /data/zookeeper/datalogsmkdir -p /data/zookeeper/logs ​ 说明： data:数据目录 datalogs:事务日志 logs:zk应用的日志 6、生成配置文件12cd /usr/local/soft/apache-zookeeper-3.8.0-bin/conf/cp zoo_sample.cfg zoo.cfg 7、设置配置文件1vi zoo.cfg 添加内容 123dataDir=/data/zookeeper/datadataLogDir=/data/zookeeper/datalogsadmin.enableServer=false ​ 说明： admin.enableServer&#x3D;false 用来关闭zk内置的web管理器 dataDir 定义了zk的数据目录 dataLogDir 定义了zk的事务日志 8、配置环境变量1vi /etc/profile 在末尾增加以下内容: 12export ZK_HOME=/usr/local/soft/apache-zookeeper-3.8.0-binexport PATH=$ZK_HOME/bin:$PATH 使环境变量生效: 1source /etc/profile 9、测试启动停止zookeeper12zkServer.sh startzkServer.sh stop","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"}]},{"title":"CentOS 8 配置JDK环境","date":"2022-06-06T13:41:00.000Z","path":"2022/06/06/software/jdk/","text":"CentOS 8 安装 JDK环境 1、使用Yum安装安装OpenJDK的可以选择此方法，方便快捷 1.1 查看是否有JDK环境1java -version 可以看到系统自带的 OpenJDK 版本信息，如果不满足，则卸载现有JDK 1.2 卸载现有JDK使用 rpm 命令查询 java 1rpm -qa | grep java .noarch文件可以不用管，卸载其余条目 执行一下命令卸载信息 1rpm -e --nodeps java-1.8.0-openjdk-1.8.0.201.b09-2.el8.x86_64 1rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.201.b09-2.el8.x86_64 卸载完后查询版本信息 1.3 使用Yum安装OpenJDK1yum install -y java-1.8.0-openjdk 1.3.1 报错 报错信息为： 12Failed to synchronize cache for repo &#x27;AppStream&#x27;, ignoring this repo.Failed to synchronize cache for repo &#x27;BaseOS&#x27;, ignoring this repo. 1.3.2 解决方案切换阿里源 1、备份 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2、下载新的 CentOS-Base.repo 到 &#x2F;etc&#x2F;yum.repos.d&#x2F; 1wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo 3、生成缓存 1yum makecache 1.4 校验 2、使用rpm包安装适用于有提供RPM Package的情况，例如Oracle JDK有提供。 Oracle JDK所有版本下载 OracleJDK8下载","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"jdk","slug":"jdk","permalink":"https://lyblog2022.github.io/tags/jdk/"}]},{"title":"RPC-远程服务调用","date":"2022-06-05T08:45:21.000Z","path":"2022/06/05/study/RPC/","text":"RPC–远程服务调用 1、RPC1.1 RFC​ RFC(Request For Comments) 是由互联网工程任务组(IETF)发布的文件集。文件集中每个文件都有自己唯一编号，例如：rfc1831。目前RFC文件由互联网协会(Internet Society，ISOC)赞助发型。 ​ RPC就收集到了rfc 1831中。可以通过下面网址查看： ​ https://datatracker.ietf.org/doc/rfc1831/ 1.2 RPC​ RPC在rfc 1831中收录 ，RPC（Remote Procedure Call） 远程过程调用协议 ​ RPC协议规定允许互联网中一台主机程序调用另一台主机程序，而程序员无需对这个交互过程进行编程。在RPC协议中强调当A程序调用B程序中功能或方法时，A是不知道B中方法具体实现的。 ​ RPC是上层协议，底层可以基于TCP协议，也可以基于HTTP协议。一般我们说RPC都是基于RPC的具体实现，如：Dubbo框架。从广义上讲只要是满足网络中进行通讯调用都统称为RPC，甚至HTTP协议都可以说是RPC的具体实现，但是具体分析看来RPC协议要比HTTP协议更加高效，基于RPC的框架功能更多。 ​ RPC协议是基于分布式架构而出现的，所以RPC在分布式项目中有着得天独厚的优势。 1.3 RPC和HTTP1.3.1 具体实现​ RPC：可以基于TCP协议，也可以基于HTTP协议。 ​ HTTP：基于HTTP协议 1.3.2 效率​ RPC：自定义具体实现可以减少很多无用的报文内容，使得报文体积更小。 ​ HTTP：如果是HTTP 1.1 报文中很多内容都是无用的。如果是HTTP2.0以后和RPC相差不大，比RPC少的可能就是一些服务治理等功能。 1.3.3 链接方式​ RPC：长连接支持。 ​ HTTP：每次连接都是3次握手。 1.3.4 性能​ RPC：可以基于很多序列化方式。如：thrift ​ HTTP：主要是通过JSON，序列化和反序列效率更低。 1.3.5 注册中心​ RPC ：一般RPC框架都带有注册中心。 ​ HTTP：都是直连。 1.3.6 负载均衡​ RPC：绝大多数RPC框架都带有负载均衡测量。 ​ HTTP：一般都需要借助第三方工具。如：nginx 1.3.7 综合结论​ RPC框架：一般都带有丰富的服务治理等功能，更适合企业内部接口调用。 ​ HTTP：更适合多平台之间相互调用。 2、HttpClient实现RPC2.1 HttpClient简介​ 在JDK中java.net包下提供了用户HTTP访问的基本功能，但是它缺少灵活性或许多应用所需要的功能。 ​ HttpClient起初是Apache Jakarta Common 的子项目。用来提供高效的、最新的、功能丰富的支持 HTTP 协议的客户端编程工具包，并且它支持 HTTP 协议最新的版本。2007年成为顶级项目。 ​ 通俗解释：HttpClient可以实现使用Java代码完成标准HTTP请求及响应。 2.2 代码实现2.2.1 服务端1、新建控制器 com.controller.DemoController 12345678@Controllerpublic class DemoController &#123; @RequestMapping(&quot;/demo&quot;) @ResponseBody public String demo(String param)&#123; return &quot;demo&quot;+param; &#125;&#125; 2、启动器 com.HttpClientServerApplication 123456@SpringBootApplicationpublic class HttpClientServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HttpClientServerApplication.class,args); &#125;&#125; 2.2.2 客户端1、添加依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.10&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、新建类 新建com.HttpClientDemo，编写主方法。 ​ 1、使用Get方法访问 123456789101112131415161718192021222324public static void main(String[] args) &#123; try &#123; //创建http工具（理解成:浏览器） 发起请求，解析响应 CloseableHttpClient httpClient = HttpClients.createDefault(); //请求路径 URIBuilder uriBuilder = new URIBuilder(&quot;http://localhost:8080/demo&quot;); uriBuilder.addParameter(&quot;param&quot;, &quot;get123&quot;); //创建HttpGet请求对象 HttpGet get = new HttpGet(uriBuilder.build()); //创建响应对象 CloseableHttpResponse response = httpClient.execute(get); //由于响应体是字符串，因此把HttpEntity类型转换为字符串类型，并设置字符编码 String result = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); //输出结果 System.out.println(result); //释放资源 response.close(); httpClient.close(); &#125; catch (URISyntaxException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; ​ 2、使用Post方式访问 12345678910111213141516171819202122232425262728public class HttpClientDemo &#123; public static void main(String[] args) &#123; try &#123; //创建http工具（理解成:浏览器） 发起请求，解析响应 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建HttpPOST请求对象 HttpPost post = new HttpPost(&quot;http://localhost:8080/demo&quot;); //所有请求参数 List&lt;NameValuePair&gt; params = new ArrayList&lt;&gt;(); params.add(new BasicNameValuePair(&quot;param&quot;,&quot;123&quot;)); //创建HttpEntity接口的文本实现类的对象，放入参数并设置编码 HttpEntity httpEntity = new UrlEncodedFormEntity(params,&quot;utf-8&quot;); //放入到HttpPost对象中 post.setEntity(httpEntity); //创建响应对象 CloseableHttpResponse response = httpClient.execute(post); //由于响应体是字符串，因此把HttpEntity类型转换为字符串类型 String result = EntityUtils.toString(response.getEntity()); //输出结果 System.out.println(result); //释放资源 response.close(); httpClient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3 Jackson用法2.3.1 对象 –&gt; json字符串123ObjectMapper objectMapper = new ObjectMapper();People peo = new People();objectMapper.writeValueAsString(peo); 2.3.2 json –&gt; 对象12ObjectMapper objectMapper = new ObjectMapper();People peo = objectMapper.readValue(content, People.class); 2.3.3 json –&gt; List集合123ObjectMapper objectMapper = new ObjectMapper();JavaType javaType = objectMapper.getTypeFactory().constructParametricType(List.class, People.class);List&lt;People&gt; list = objectMapper.readValue(content, javaType); 2.4 HttpClient请求包含JSON12345678910111213141516171819public class HttpClientDemo &#123; public static void main(String[] args) &#123; try &#123; CloseableHttpClient httpClient = HttpClients.createDefault(); HttpPost post = new HttpPost(&quot;http://localhost:8080/demo&quot;); HttpEntity httpEntity= null;String json = &quot;&#123;&#125;&quot;; StringEntity entity = new StringEntity(json, ContentType.APPLICATION_JSON); post.setEntity(entity); CloseableHttpResponse response = httpClient.execute(post); String result = EntityUtils.toString(response.getEntity()); System.out.println(result); response.close(); httpClient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.5 控制器接口参数@RequestBody把请求体中流数据转换为指定的对象。多用在请求参数是json数据且请求的Content-Type&#x3D;”application&#x2F;json” 123456@RequestMapping(&quot;/demo4&quot;)@ResponseBodypublic String demo4(@RequestBody List&lt;People&gt; list) &#123; System.out.println(list); return list.toString();&#125; 2.6 Ajax发送json参数写法1234567891011121314var json = &#x27;[&#123;&quot;id&quot;:123,&quot;name&quot;:&quot;ly&quot;&#125;,&#123;&quot;id&quot;:123,&quot;name&quot;:&quot;ly123&quot;&#125;]&#x27;; $.ajax(&#123; url:&#x27;/demo5&#x27;, type:&#x27;post&#x27;, success:function(data)&#123; alert(data); for(var i = 0 ;i&lt;data.length;i++)&#123; alert(data[i].id +&quot; &quot;+data[i].name); &#125; &#125;, contentType:&#x27;application/json&#x27;,//请求体中内容类型 dataType:&#x27;json&#x27;,//响应内容类型。 data:json &#125;); 2.7 跨域跨域：协议、IP、端口中只要有一个不同的就是跨域请求 同源策略：浏览器默认只允许ajax访问同源（协议、IP、端口）内容 解决同源策略：在控制器接口上添加@CrossOrigin。表示允许跨域。本质在响应头中添加Access-Control-Allow-Origin: * 123456789101112131415var json = &#x27;[&#123;&quot;id&quot;:123,&quot;name&quot;:&quot;ly&quot;&#125;,&#123;&quot;id&quot;:456,&quot;name&quot;:&quot;ly1234&quot;&#125;]&#x27;; $.ajax(&#123; url:&#x27;/demo5&#x27;, type:&#x27;post&#x27;, success:function(data)&#123; alert(data); for(var i = 0 ;i&lt;data.length;i++)&#123; alert(data[i].id +&quot; &quot;+data[i].name); &#125; &#125;, contentType:&#x27;application/json&#x27;,//请求体中内容类型 dataType:&#x27;json&#x27;,//响应内容类型。 data:json &#125;); 3、RMI实现RPC3.1 RMI简介 RMI(Remote Method Invocation) 远程方法调用。 RMI是从JDK1.2推出的功能，它可以实现在一个Java应用中可以像调用本地方法一样调用另一个服务器中Java应用（JVM）中的内容。 RMI 是Java语言的远程调用，无法实现跨语言。 3.2 执行流程 ​ Registry(注册表)是放置所有服务器对象的命名空间。 每次服务端创建一个对象时，它都会使用bind()或rebind()方法注册该对象。 这些是使用称为绑定名称的唯一名称注册的。 ​ 要调用远程对象，客户端需要该对象的引用。即通过服务端绑定的名称从注册表中获取对象(lookup()方法)。 3.3 API3.3.1 Remotejava.rmi.Remote 定义了此接口为远程调用接口。如果接口被外部调用，需要继承此接口。 3.3.2 RemoteException​ java.rmi.RemoteException ​ 继承了Remote接口的接口中，如果方法是允许被远程调用的，需要抛出此异常。 3.3.3 UnicastRemoteObject​ java.rmi.server.UnicastRemoteObject ​ 此类实现了Remote接口和Serializable接口。 ​ 自定义接口实现类除了实现自定义接口还需要继承此类。 3.3.4 LocateRegistry​ java.rmi.registry.LocateRegistry ​ 可以通过LocateRegistry在本机上创建Registry，通过特定的端口就可以访问这个Registry。 3.3.5 Naming​ java.rmi.Naming ​ Naming定义了发布内容可访问RMI名称。也是通过Naming获取到指定的远程方法。 3.4 代码实现3.4.1 服务端1、编写接口 com.service.DemoService 编写 123public interface DemoService extends Remote &#123; String demo(String demo) throws RemoteException;&#125; 2、编写实现类 com.service.impl.DemoServiceImpl 编写。 注意：构造方法是public的。默认生成protected 12345678public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123; public DemoServiceImpl() throws RemoteException &#123; &#125; @Override public String demo(String demo) throws RemoteException &#123; return demo+&quot;123&quot;; &#125;&#125; 3、主方法 编写com.DemoServer类，生成主方法 12345678public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123; public DemoServiceImpl() throws RemoteException &#123; &#125; @Override public String demo(String demo) throws RemoteException &#123; return demo+&quot;123&quot;; &#125;&#125; 4、运行项目 运行后项目，项目一直处于启动状态，表示可以远程访问此项目中的远程方法。 3.4.2 创建客户端代码1、复制服务端接口 把服务端com.service.DemoService粘贴到项目中 2、创建主方法 新建com.DemoClient 12345678public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123; public DemoServiceImpl() throws RemoteException &#123; &#125; @Override public String demo(String demo) throws RemoteException &#123; return demo+&quot;123&quot;; &#125;&#125;","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"RPC","slug":"RPC","permalink":"https://lyblog2022.github.io/tags/RPC/"}]},{"title":"SpringBoot","date":"2022-06-05T07:02:13.000Z","path":"2022/06/05/study/SpringBoot/","text":"SpringBoot学习1 1、SpringBoot 1.1 简介 Spring Boot是Spring公司的一个顶级项目，和Spring Framework是一个级别的。 Spring Boot实际上是利用Spring Framework 4 自动配置特性完成。编写项目时不需要编写xml文件。发展到现在，Spring Boot已经具有很很大的生态圈，各种主流技术已经都提供了Spring Boot的启动器。 1.2 启动器​ Spring框架在项目中作用是Spring整合各种其他技术，让其他技术使用更加方便。Spring Boot的启动器实际上就是一个依赖。这个依赖中包含了整个这个技术的相关jar包，还包含了这个技术的自动配置，以前绝大多数XML配置都不需要配置了。当然了，启动器中自动配置无法实现所有内容的自动配置，在使用Spring Boot时还需要进行少量的配置（这个配置不是在xml中了，而是在properties或yml中即可）。如果是Spring自己封装的启动器的artifact id名字满足：spring-boot-starter-xxxx，如果是第三方公司提供的启动满足：xxxx-spring-boot-starter。以后每次使用Spring Boot整合其他技术时首先需要考虑导入启动器。 1.3 优点 使用Spring Boot可以创建独立的Spring应用程序 在Spring Boot中直接嵌入了Tomcat、Jetty、Undertow等Web 容器，在使用SpringBoot做Web开发时不需要部署WAR文件 通过提供自己的启动器(Starter)依赖，简化项目构建配置 尽量的自动配置Spring和第三方库 绝对没有代码生成，也不需要XML配置文件 1.4 核心起步依赖- 起步依赖本质上是一个Maven项目对象模型（Project Object Model，POM），定义了对其他库的传递依赖，这些东西加在一起即支持某项功能。 简单的说，起步依赖就是将具备某种功能的坐标打包到一起，并提供一些默认的功能。 自动配置 -Spring Boot的自动配置是一个运行时（更准确地说，是应用程序启动时）的过程，考虑了众多因素，才决定 Spring配置应该用哪个，不该用哪个。该过程是Spring自动完成的。","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"springboot","slug":"springboot","permalink":"https://lyblog2022.github.io/tags/springboot/"}]},{"title":"SpringMVC","date":"2022-06-05T04:55:50.000Z","path":"2022/06/05/study/SpringMVC/","text":"Springmvc学习 1、SpringMVC1.1 概念 SpringMVC是spring为展现层提供的基于MVC设计理念的优秀WEB框架，是目前最主流的MVC框架之一 SpringMVC通过一套注解，可以让普通的JAVA类成为contrllor控制器，无需继承Servlet，实现了控制层和Servlet之间的解耦 SpringMVC支持Rest风格的URL写法 SpringMVC采用了松耦合，可热插的主键结构，比其他的框架更具扩展性和灵活性 1.2 执行流程 DispatcherServlet：前端控制器 用户请求到达前端控制器，它就相当于 mvc 模式中的 c，dispatcherServlet 是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet 的存在降低了组件之间的耦合性。 HandlerMapping：处理器映射器 HandlerMapping 负责根据用户请求找到 Handler 即处理器，SpringMVC 提供了不同的映射器实现不同的 映射方式，例如：配置文件方式，实现接口方式，注解方式等。 HandlerMapping的实现类的作用：实现类RequestMappingHandlerMapping，它会处理@RequestMapping 注解，并将其注册到请求映射表中。 Handler：处理器 (自己定义的Controller处理单元) 它就是我们开发中要编写的具体业务控制器。由 DispatcherServlet 把用户请求转发到 Handler。由 Handler 对具体的用户请求进行处理。 HandlAdapter：处理器适配器 通过 HandlerAdapter 对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行 HandlerAdapter的实现类的作用：实现类RequestMappingHandlerAdapter，则是处理请求的适配器，确定调用哪个类的哪个方法，并且构造方法参数，返回值。 View Resolver：视图解析器 View Resolver 负责将处理结果生成 View 视图，View Resolver 首先根据逻辑视图名解析成物理视图名 即具体的页面地址，再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户。 View：视图 SpringMVC 框架提供了很多的 View 视图类型的支持，包括：jstlView、freemarkerView、pdfView等。我们最常用的视图就是 jsp。 一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开 发具体的页面。 2、 获取请求参数2.1 紧耦合方式​ DispatcherServlet中的service方法直接将此次请求的request对象传递给调用的单元方法即可。同时在单元方法上声明形参HttpServletRequest来接收request实参即可。 2.2 解耦合方式​ DispatcherServlet在其service方法中将请求数据根据需求从request对象中获取出来后，将数据直接传递给对应的单元方法使用。同时在单元方法上直接声明对应的形参接收请求数据即可。在单元方法上声明形参来接收请求数据时，形参名必须和请求数据的键名一致，DispatcherServlet会将调用单元方法的形参名作为请求数据的键名获取请求数据，然后传递给单元方法。 2.3 常见注解2.3.1 @RequestMapping 作用：用于建立请求 URL 和处理请求方法之间的对应关系 出现位置： 类上：请求 URL 的第一级访问目录。此处不写的话，就相当于应用的根目录。写的话需要以&#x2F;开头 方法上：请求 URL 的第二级访问目录 属性： value：用于指定请求的 URL。它和 path 属性的作用是一样的。 method：用于指定请求的方式。 2.3.2 @RequestParam 作用：把请求中指定名称的参数给控制器中的形参赋值。 属性： value：请求参数中的名称。 required：请求参数中是否必须提供此参数。默认值：true。表示必须提供，如果不提供将报错。 12345@RequestMapping(&quot;/getRequestParam&quot;) public String getRequestParam(@RequestParam(&quot;name&quot;) String uname, @RequestParam(value=&quot;age&quot;, required=false) Integer age) &#123; System.out.println(username+&quot;,&quot;+age); return &quot;success&quot;; &#125; 2.3.3 @PathVariable 作用：用于绑定 url 中的占位符。例如：请求 url 中 &#x2F;delete&#x2F;**{id}，这个{id}**就是 url 占位符。 url 支持占位符是 spring3.0 之后加入的。是 springmvc 支持 rest 风格 URL 的一个重要标志。 属性： value：用于指定 url 中占位符名称。 required：是否必须提供占位符。 12345678910@Controllerpublic class PathController &#123; @RequestMapping(&quot;/testPathVariable/&#123;id&#125;/&#123;username&#125;&quot;) public String testPathVariable( @PathVariable(&quot;id&quot;) Integer id, @PathVariable(&quot;username&quot;) String username) &#123; System.out.println(&quot;id:&quot;+id); System.out.println(&quot;username:&quot;+username); System.out.println(&quot;testPathVariable1&quot;); return &quot;success&quot;; &#125;&#125; 3、作用域传参3.1 PageContext对象 作用域范围：当前jsp页面内有效 3.2 request对象 作用域范围：一次请求内。 作用: 解决了一次请求内的资源的数据共享问题 3.3 session对象 作用域范围：一次会话内有效。 说明：浏览器不关闭，并且后台的session不失效，在任意请求中都可以获取到同一个session对象。 作用：解决了一个用户不同请求的数据共享问题。 3.4 application(ServletContext)对象 作用域范围：整个项目内有效。 特点：一个项目只有一个，在服务器启动的时候即完成初始化创建无论如何获取都是同一个项目。 作用：解决了不同用户的数据共享问题。 4、拦截器Spring MVC中的拦截器（Interceptor）类似于Servlet中的过滤器（Filter），它主要用于拦截用户请求并作相应的处理。例如通过拦截器可以进行权限验证、记录请求信息的日志、判断用户是否登录等。 要使用Spring MVC中的拦截器，就需要对拦截器类进行定义和配置。通常拦截器类可以通过两种方式来定义。 通过实现HandlerInterceptor接口，或继承HandlerInterceptor接口的实现类（如HandlerInterceptorAdapter）来定义。 通过实现WebRequestInterceptor接口，或继承WebRequestInterceptor接口的实现类来定义。 4.1 拦截器过滤器区别 拦截器SpringMVC的，而过滤器是servlet的。 拦截器不依赖与servlet容器，由spring容器初始化，过滤器依赖与servlet容器，由servlet容器初始化。 拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。 拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。 在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。 拦截器可以获取IOC容器中的各个bean，而过滤器就不太方便，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。 4.2 preHandle方法 执行时机：再进入控制单元方法之前执行 调用：按拦截器定义顺序调用 具体作用：如果程序员决定该拦截器对请求进行拦截处理后还要调用其他的拦截器，或者是业务处理器去 进行处理，则返回 true。 如果程序员决定不需要再调用其他的组件去处理请求，则返回 false。 参数： HttpServletRequest arg0，拦截的请求的request对象 HttpServletResponse arg1，拦截的请求的response对象 Object arg2 封存了单元方法对象的HandleMethod对象 123456789101112131415161718192021222324/** * * @param request 请求对象 * @param response 响应对象 * @param handler 目标要调用的Handler * @return 返回true放行,返回false拦截 * @throws Exception*/public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; /*在请求到达我们定义的handler之前工作的*/ System.out.println(&quot;MyInterceptor preHandle&quot;); /*设置请求和响应的乱码 */ /* request.setCharacterEncoding(&quot;UTF-8&quot;); response.setCharacterEncoding(&quot;UTF-8&quot;);*/ // 判断是否登录 /*User user =(User) request.getSession().getAttribute(&quot;user&quot;); if(null == user) response.sendRedirect(&quot;index.jsp&quot;); return false;*/ // 用户权限控制 return true;&#125; 4.3 postHandle方法 执行时机：在进行数据处理和做出响应之间进行这个方法的调用 调用：在拦截器链内所有拦截器返成功调用 作用：在业务处理器处理完请求后，但是 DispatcherServlet 向客户端返回响应前被调用，在该方法中对用户请求 request域数据进行处理。 参数： HttpServletRequest arg0，拦截的请求的request对象 HttpServletResponse arg1，拦截的请求的response对象 Object arg2，封存了单元方法对象的HandleMethod对象 ModelAndView arg3，封存了单元方法的返回值资源路径和请求转到的Map数据 12345678910111213141516171819/** * * @param request * @param response * @param handler * @param modelAndView controller响应的结果,视图和数据 * @throws Exception */public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;MyInterceptor postHandle&quot;); /*控制数据*/ /*Map&lt;String, Object&gt; map = modelAndView.getModel(); String msg = (String)map.get(&quot;msg&quot;); String newMsg = msg.replaceAll(&quot;脏话&quot;, &quot;**&quot;); map.put(&quot;msg&quot;, newMsg);*/ /*控制视图*/ /*modelAndView.setViewName(&quot;/testDemo1.jsp&quot;);*/&#125; 4.4 afterCompletion方法 执行时机：在进行页面渲染的时候执行 调用：按拦截器定义逆序调用 作用：在DispatcherServlet 完全处理完请求后被调用,可以在该方法中进行一些资源清理的操作。 参数： HttpServletRequest arg0，拦截的请求的request对象 HttpServletResponse arg1，拦截的请求的response对象 Object arg2，封存了单元方法对象的HandleMethod对象 Exception arg3，存储了责任链的异常信息 1234567891011121314/** * 无论controller是否出现异常,都会执行的方法 * 一般来说都做一些资源释放工作 * @param request * @param response * @param handler * @param ex * @throws Exception */public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; /*页面渲染完毕,但是还没有给浏览器响应数据的时候*/ System.out.println(&quot;MyInterceptor afterCompletion&quot;); System.out.println(ex);&#125; 5、其他注解5.1 @PostMapping 作用：指定当前发送请求的方式只可以是post请求 属性：和@RequestMapping中属性一致 5.2 @GetMapping 作用：指定当前发送请求的方式只可以是get请求 属性：和@RequestMapping中属性一致 5.3 @JsonFormat 作用：处理响应json 数据的处理 属性： pattern ：指定响应时间日期的格式 Timezone：指定响应的时区，否则会有8个小时的时间差 5.4 @RequestBody 作用：用于获取请求体json格式的字符串内容。直接使用得到是 key=value&amp;key=value结构的数据，get 请求方式不适用。 属性：required：是否必须有请求体。默认值是:true。当取值为 true 时，get 请求方式会报错。如果取值 为 false，get 请求得到是null。 5.5 @CrossOrigin​ 跨域：出于浏览器的同源策略限制。同源策略（SameOriginPolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port） 作用：解决ajax请求之间的跨域问题 属性： origins：允许可访问的域列表IP maxAge：准备响应前的缓存持续的最大时间（以秒为单位）。 1234567@CrossOrigin(origins = &quot;http://domain2.com&quot;, maxAge = 3600)@RestController@RequestMapping(&quot;/account&quot;)public class AccountController &#123; @GetMapping(&quot;/&#123;id&#125;&quot;) public Account receive(@PathVariable Long id) &#123; &#125;&#125;","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"Springmvc","slug":"Springmvc","permalink":"https://lyblog2022.github.io/tags/Springmvc/"}]},{"title":"Spring","date":"2022-06-04T08:59:55.000Z","path":"2022/06/04/study/Spring/","text":"Spring学习 1、Spring框架1.1 Spring框架​ Spring框架是由于软件开发的复杂性而创建的。Spring使用的是基本的JavaBean来完成以前只可能由EJB完成的事情。然而，Spring的用途不仅仅限于服务器端的开发。从简单性、可测试性和松耦合性角度而言，绝大部分Java应用都可以从Spring中受益。 ​ —-百度百科 目的：解决企业应用开发的复杂性 功能：使用基本的JavaBean代替EJB，并提供更对的企业应用功能 范围：任何Java应用 ​ Spring是分层的全栈式的轻量级开发框架，以IOC和AOP为核心 1.2 优点 方便解耦，简化开发 Spring通过容器，将对象的创建从代码中剥离出来，交给Spring控制，避免直接编码造成模块之间的耦合度高，用户也不必自己编码处理对象的单例和多例控制，主要关注接口功能即可，不用关注具体使用哪个实现类和实现细节问题 AOP切面编程 AOP切面编程是程序设计的一种概念，Spring对该概念实现的比较好，通过切面编程我们可以在不修改原有代码的情况下实现功能的增加，通常用于事务控制、日志记录、性能检测、权限控制等等 声明式事务 事务的控制可以托管给Spring，我们通过注解或者配置文件声明事务的处理方式即可，不用我们自己去编码处理 整合JUNIT，方便测试 spring整合JUNIT单元测试，对于项目的功能都可以进行轻松快速的测试，便于我们调试程序 方便整合各种优秀的框架 丰富的功能封装 spring对JAVAEE(JDBC ，JAVAMail)都进行了一系列的封装，简化我们对于API的使用，提高程序的开发效率 规范的源码学习样本 spring的源码设计巧妙，结构清晰，大量使用了设计模式，是java代码规范编写的典范 2、Spring模块 2.1 Data Access/Integration（数据访问／集成）数据访问&#x2F;集成层包括 JDBC、ORM、OXM、JMS 和 Transactions 模块 JDBC 模块：提供了一个 JDBC 的抽象层，大幅度减少了在开发过程中对数据库操作的编码。 ORM 模块：对流行的对象关系映射 API，包括 JPA、JDO、Hibernate和 iBatis 提供了的集成层。 OXM 模块：提供了一个支持对象XML 映射的抽象层实现，如 JAXB、Castor、XMLBeans、JiBX 和 XStream。 JMS 模块：指JAVA消息服务，包含的功能为生产和消费的信息。 Transactions 事务模块：支持编程和声明式事务管理实现特殊接口类，并为所有的 POJO。 2.2 Web 模块Spring 的 Web 层包括 Web、Servlet、Struts 和 Portlet 组件 Web 模块：提供了基本的 Web 开发集成特性，例如多文件上传功能、使用的 Servlet 监听器的 IoC 容器初始化以及 Web 应用上下文。 Servlet模块：包括 Spring 模型—视图—控制器（MVC）实现 Web应用程序。 Struts 模块：包含支持类内的 Spring 应用程序，集成了经典的 Struts Web 层。 Portlet 模块：提供了在 Portlet 环境中使用 MVC实现，类似 Web-Servlet 模块的功能。 2.3 Core Container（核心容器）Spring 的核心容器是其他模块建立的基础，由 Beans 模块、Core 核心模块、Context 上下文模块和 Expression Language 表达式语言模块组成 Beans 模块：提供了 BeanFactory，是工厂模式的经典实现，Spring 将管理对象称为 Bean。 Core 核心模块：提供了 Spring 框架的基本组成部分，包括 IoC 和 DI 功能。 Context 上下文模块：建立在核心和 Beans 模块的基础之上，它是访问定义和配置任何对象的媒介。ApplicationContext 接口是上下文模块的焦点。 Expression Language 模块：是运行时查询和操作对象图的强大的表达式语言。 2.4 其他模块Spring的其他模块还有 AOP、Aspects、Instrumentation 以及 Test 模块 AOP 模块：提供了面向切面编程实现，允许定义方法拦截器和切入点，将代码按照功能进行分离，以降低耦合性。 Aspects 模块：提供与 AspectJ 的集成，是一个功能强大且成熟的面向切面编程（AOP）框架。 Instrumentation 模块：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用。 Test 模块：支持 Spring 组件，使用 JUnit 或 TestNG 框架的测试。 3、Spring_IOC3.1 控制反转​ 控制反转（Inversion of Control，缩写为IoC），是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫依赖查找（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。–【百度】 ​ 简单来说，创建对象的权利，或者是控制的位置，由Java代码转移到Spring容器，由Spring的容器控制对象的创建，就是控制反转，Spring创建对象时，会读取配置文件中的信息，然后使用反射创建好的对象之后在容器中存储起来，当需要某个对象时，通过id获取对象即可，不需要自己去new 3.2 原理分析3.2.1 XML解析1&lt;bean id=&quot;stuDao&quot; class=&quot;com.dao.impl.StuDaoImpl&quot;&gt;&lt;/bean&gt; ​ 将上面的信息读取进入程序 对象的ID ,一个是对象的类的全路径名 3.2.2 反射123456//获得类的字节码Class clazz =Class.forName(&quot;com.dao.impl.StuDaoImpl&quot;);//通过字节码实例化对象Object obj = clazz.newInstance(); //将对象放到一个map集合中map.put(&quot;empDao&quot;,obj) 3.2.3 工厂模式1234public Object getBean(String name)&#123; Object obj =map.get(name); return obj; &#125; IOC接口 BeanFactory 接口：IOC容器基本功能接口，是spring内部使用的接口，我们在处理业务时一般不直接使用该接口 ApplicationContext 接口：BeanFactory的子接口，提供更多更强大的功能，研发人员一般使用的接口 4、Spring_XML方式实现DIspring中的Bean的管理: Bean(汉译咖啡豆)，又称JAVABean，其实就是JAVA程序程序中的一个个对象，所以Bean的管理其实就是spring对于JAVA程序中的对象的管理 管理的内容 对象的创建（IOC）：控制反转，就是Spring给我们创建对象，然后我们直接用，不用自己NEW 属性的赋值（DI）：依赖注入，即创建属性时给对象属性赋值，对象功能的实现往往要依赖属性的值，由于对象属性不仅仅是基本数据类型，还可能是其他类或者引用类型，那么依赖注入将会把更多的对象之间的关系整理到一起，可以形成一个庞大的依赖关系，DI处理的是对象的属性赋值和互相依赖的关系 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!--通过无参构造方法构造对象--&gt;&lt;bean id=&quot;user1&quot; class=&quot;com.bean.User&quot; name=&quot;user1&quot; scope=&quot;prototype&quot; lazy-init=&quot;true&quot;&gt;&lt;/bean&gt;&lt;!--id:对象的idclass:类的全路径名name:和id类似,一般不用scope：控制对象单例多例和使用范围 singleton：作用域(scope 默认值), Spring IOC容器中只会存在一个共享的bean实例 prototype：作用域部署的bean，每一次获取都会产生一个新的bean实例，相当与一个new的操作 request：表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效 session：作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效 global session：作用域类似于标准的HTTP Session作用域，不过它仅仅在基于portlet的web应用中才有意义lazy-init：懒加载 调用getBean的时候再去实例化对象--&gt;&lt;!--通过set方法给对象属性赋值--&gt;&lt;bean id=&quot;user1&quot; class=&quot;com.bean.User&quot;&gt; &lt;property name=&quot;userid&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;username&quot; value=&quot;张三&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;abcdefg&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--通过有参构造给对象属性赋值--&gt;&lt;bean id=&quot;user2&quot; class=&quot;com.bean.User&quot;&gt; &lt;constructor-arg name=&quot;userid&quot; value=&quot;2&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;username&quot; value=&quot;小明&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;password&quot; value=&quot;123456789&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;!--特殊符号--&gt;&lt;bean id=&quot;user1&quot; class=&quot;com.bean.User&quot;&gt; &lt;!--null值--&gt; &lt;property name=&quot;userid&quot;&gt; &lt;null&gt;&lt;/null&gt; &lt;/property&gt; &lt;!--特殊符号 转译字符 &lt; &amp;lt; &gt;&amp;gt; &amp; &amp;amp; --&gt; &lt;property name=&quot;username&quot; value=&quot;&amp;amp;xiaoming&amp;lt;&amp;gt;&quot;&gt;&lt;/property&gt; &lt;!-- 特殊符号 &lt;![CDATA[内容]]&gt; --&gt; &lt;property name=&quot;password&quot;&gt; &lt;value&gt;&lt;![CDATA[&amp;&lt;123456&gt;]]&gt;&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 5、Spring_Bean生命周期 通过构造器创建bean实例&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 执行构造器 为bean属性赋值&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 执行set方法 初始化bean&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 调用bean的初始化方法,需要配置指定调用的方法 bean的获取&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 容器对象 getBean方法 容器关闭销毁bean&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 调用销毁方法,需要配置指定调用的方法 6、Spring注解方式管理Bean6.1 注解方式创建对象IOC @Component：放在类上,用于标记，告诉spring当前类需要由容器实例化bean并放入容器中 @Controller：@Component子注解，用于实例化controller层bean @Service：@Component子注解，用于实例化service层bean @Repository：@Component子注解，用于实例化持久层bean 6.2 注解方式依赖注入DI @Autowired：根据属性数据类型自动装配 @Qualifier：根据属性名称注入依赖 @Resources：可以根据类型,也可以根据名称注入 @Value：注入普通数据类型(8+String) 7、Spring代理7.1 代理模式通过代理对象访问目标对象，可以在目标对象基础上增强额外的功能，如添加权限、访问控制等 7.2 静态代理​ 静态代理中代理类与被代理类都需要实现同一个接口，即一个静态代理类只能代理一个类，并且需要知道要代理哪个类才能编写代理类代码，如果有其他类想要使用代理类，就必须再写一个 ​ 在实际开发中是可能有非常多的类需要被代理，并且可能并不知道要代理哪个类，所以继续使用静态代理反而会增加更多的工作量，且效率低下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.test;/*** @Author: Ly* @Description: */public class Test1 &#123; public static void main(String[] args) &#123; Person person =new Person(&quot;张三&quot;); Court court=new Lawyer(person); court.doCourt(); &#125;&#125;// 接口interface Court&#123; void doCourt();&#125;// 代理类class Lawyer implements Court&#123; private Person person; public Lawyer(Person person) &#123; this.person = person; &#125; @Override public void doCourt() &#123; System.out.println(&quot;律师取证:视频证明张三当时正在旅游,不在案发现场&quot;); System.out.println(&quot;律师总结:张三不可能去杀人&quot;); person.doCourt(); &#125;&#125;// 被代理的类class Person implements Court&#123; private String name; public Person(String name) &#123; this.name = name; &#125; @Override public void doCourt() &#123; System.out.println(name+&quot;说:我没有杀人&quot;); &#125;&#125; 7.3 动态代理​ 动态代理可以针对于一些不特定的类或者一些不特定的方法进行代理，可以在程序运行时动态的改变代理的规则，代理类在程序运行时才创建的代理模式，在这种情况下，代理类并不是在Java代码中定义好，而是在程序运行时根据在Java代码中的指示动态生成的 Proxy动态代理：JDK动态代理，面向接口 cglib动态代理：第三方动态代理，面向父类 7.3.1 Proxy动态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.testProxy; import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.Arrays;/** * @Author: Ly * @Description: */public class Test1 &#123; public static void main(String[] args) &#123; Dinner dinner=new Person(&quot;张三&quot;); // 通过Porxy动态代理获得一个代理对象,在代理对象中,对某个方法进行增强 // ClassLoader loader,被代理的对象的类加载器 ClassLoader classLoader = dinner.getClass().getClassLoader(); // Class&lt;?&gt;[] interfaces,被代理对象所实现的所有接口 Class[] interaces= dinner.getClass().getInterfaces(); //InvocationHandler h,执行处理器对象,专门用于定义增强的规则 InvocationHandler handler = new InvocationHandler() &#123; // invoke 当我们让代理对象调用任何方法时,都会触发invoke方法的执行 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //Object proxy, 代理对象 //Method method,被代理的方法 //Object[] args,被代理方法运行时的实参 Object res = null; if (method.getName().equals(&quot;eat&quot;)) &#123; System.out.println(&quot;饭前洗手&quot;); // 让原有的eat的方法去运行 res = method.invoke(dinner, args); System.out.println(&quot;饭后刷碗&quot;); &#125; else &#123; // 如果是其他方法,那么正常执行就可以了 res = method.invoke(dinner, args); &#125; return res; &#125; &#125;; Dinner dinnerProxy =(Dinner) Proxy.newProxyInstance(classLoader,interaces,handler); //dinnerProxy.eat(&quot;包子&quot;); dinnerProxy.drink(); &#125;&#125;interface Dinner&#123; void eat(String foodName); void drink();&#125; class Person implements Dinner&#123; private String name; public Person(String name) &#123; this.name = name; &#125; @Override public void eat(String foodName) &#123; System.out.println(name+&quot;正在吃&quot;+foodName); &#125; @Override public void drink() &#123; System.out.println(name+&quot;正在喝茶&quot;); &#125;&#125; class Student implements Dinner&#123; private String name; public Student(String name) &#123; this.name = name; &#125; @Override public void eat(String foodName) &#123; System.out.println(name+&quot;正在食堂吃&quot;+foodName); &#125; @Override public void drink() &#123; System.out.println(name+&quot;正在喝可乐&quot;); &#125;&#125; ​ 总结： 在不修改原有代码的或者没有办法修改原有代码的情况下，增强对象功能使用代理对象代替原来的对象去完成功能，进而达到拓展功能的目的 JDK Proxy动态代理是面向接口的动态代理，一定要有接口和实现类，代理对象增强的是实现类，在实现接口的方法重写方法，生成的代理对象只能转换成接口，不能转换成代理类 生成的代理对象只能转换成接口，不能转换成被代理类 代理对象只能增强接口中定义的方法，实现类中其他和接口无关的方法是无法增强的 代理对象只能读取到接口中方法上的注解，不能读取到实现类方法上的注解 7.3.2 cglib动态代理模式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.testCglib; import org.junit.Test;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy; import java.lang.reflect.Method;/** * @Author: Ly * @Description: */public class Test1 &#123; @Test public void testCglib()&#123; Person person = new Person(); // 获取一个Person的代理对象 // 1 获得一个Enhancer对象 Enhancer enhancer = new Enhancer(); // 2 设置父类字节码 enhancer.setSuperclass(person.getClass()); // 3 获取MethodIntercepter对象 用于定义增强规则 MethodInterceptor methodInterceptor = new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; /* Object o, 生成之后的代理对象 personProxy Method method, 父类中原本要执行的方法 Person&gt;&gt;&gt; eat() Object[] objects, 方法在调用时传入的实参数组 MethodProxy methodProxy 子类中重写父类的方法 personProxy &gt;&gt;&gt; eat() */ Object res = null; if (method.getName().equals(&quot;eat&quot;)) &#123; // 如果是eat方法 则增强并运行 System.out.println(&quot;饭前洗手&quot;); res = methodProxy.invokeSuper(o,objects); System.out.println(&quot;饭后刷碗&quot;); &#125; else &#123; // 如果是其他方法 不增强运行 res = methodProxy.invokeSuper(o,objects); // 子类对象方法在执行,默认会调用父类对应被重写的方法 &#125; return res; &#125; &#125;; // 4 设置methodInterceptor enhancer.setCallback(methodInterceptor); // 5 获得代理对象 Person personProxy = (Person)enhancer.create(); // 6 使用代理对象完成功能 personProxy.eat(&quot;包子&quot;); &#125;&#125;class Person &#123; public Person() &#123; &#125; public void eat(String foodName) &#123; System.out.println(&quot;张三正在吃&quot;+foodName); &#125;&#125; 8、Spring AOP8.1 AOP 概念及原理​ 在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。—-【百度百科】 ​ AOP 面向切面编程一般可以在不修改现有代码的情况下，对程序功能进行拓展，往往用于实现日志处理、权限控制、性能检测、事务控制等 ​ AOP实现的原理就是动态代理，在有接口的情况下，使用**JDK动态代理，在没有接口的情况下使用cglib动态代理** 8.2 术语 连接点（Joint point）：类里面可以被增强的方法，这些方法称之为连接点，表示在程序中明确定义的点，典型的包括方法调用，对类成员的访问以及异常处理程序块的执行等待，它自身还可以嵌套其他Join point 切入点（Pointcut）：实际被增强的方法，称之为切入点，表示一组joint point，这些joint point或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的Advince将要发生的地方 通知（Advince）：实际增强的逻辑部分称为通知（增加的功能），Advince定义了在Pointcut里面定义的程序点具体要做的操作，它通过before、after、around来区别是在每个joint point之前、之后还是代替执行的代码，通知类型：前置通知、后置通知、环绕通知、异常通知、最终通知 目标对象（Target）：被增强功能的对象（被代理的对象） 切面（Aspect）：表现为功能相关的一些advice放在一起声明成为一个java类，aspect声明类似与java的类声明，在aspect中会包含一些pointcut以及相应的advince 织入（Weaving）：创建代理对象并实现功能增强的声明并运行的过程，将Aspect和其他对象链接起来，并创建Advince Object的过程 8.3 注解方式实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.aspect; import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;import java.util.Arrays;/** * @Author: Ly * @Description: */ @Component@Aspectpublic class DaoAspect &#123; //定义公共切点 @Pointcut(&quot;execution(* com.dao.*.add*(..))&quot;) public void addPointCut() &#123;&#125;. /* * 前置通知: 切点方法执行之前先执行的功能 * 参数列表可以用JoinPoint接收切点对象 * 可以获取方法执行的参数 * */ @Before(&quot;addPointCut()&quot;) public void methodBefore(JoinPoint joinPoint) &#123; System.out.println(&quot;Before invoked&quot;); &#125; /* * 后置通知:方法执行之后要增强的功能 * 无论切点方法是否出现异常都会执行的方法 * 参数列表可以用JoinPoint接收切点对象 * */ @After(&quot;addPointCut()&quot;) public void methodAfter(JoinPoint joinPoint) &#123; System.out.println(&quot;After invoked&quot;); &#125; /* * 返回通知:切点方法正常运行结束后增强的功能 * 如果方法运行过程中出现异常,则该功能不运行 * 参数列表可以用 JoinPoint joinPoint接收切点对象 * 可以用Object res接收方法返回值,需要用returning指定返回值名称 * */ @AfterReturning( value = &quot;addPointCut()&quot;,returning = &quot;res&quot;) public void methodAfterReturning(JoinPoint joinPoint, Object res) &#123; System.out.println(&quot;AfterReturning invoked&quot;); &#125; /* * 异常通知:切点方法出现异常时运行的增强功能 * 如果方法运行没有出现异常,则该功能不运行 * 参数列表可以用Exception ex接收异常对象 需要通过throwing指定异常名称 * */ @AfterThrowing( value = &quot;addPointCut()&quot;,throwing = &quot;ex&quot;) public void methodAfterThrowing(Exception ex) &#123; System.out.println(&quot;AfterThrowing invoked&quot;); &#125; /*环绕通知:在切点方法之前和之后都进行功能的增强 * 需要在通知中定义方法执行的位置,并在执行位置之前和之后自定义增强的功能 * 方法列表可以通过ProceedingJoinPoint获取执行的切点 * 通过proceedingJoinPoint.proceed()方法控制切点方法的执行位置 * proceedingJoinPoint.proceed()方法会将切点方法的返回值获取到,并交给我们,可以做后续处理 * 我们在环绕通知的最后需要将切点方法的返回值继续向上返回,否则切点方法在执行时接收不到返回值 * */ @Around(&quot;addPointCut()&quot;) public Object methodAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; System.out.println(&quot;aroundA invoked&quot;); Object proceed = proceedingJoinPoint.proceed(); System.out.println(&quot;aroundB invoked&quot;); return proceed; &#125;&#125; ​ 有多个增强类对同一个方法进行增强，通过@Order注解设置增强类优先级，数字越小，优先级越高，数字越小，其代理位置越靠近注入位置 9、Spring 事务9.1 事务​ 事务（Transaction）：指的是一个操作序列，该操作序列中的多个操作，只能都做，或者都不做，是一个不可分割的工作单位，是数据库环境中的逻辑工作单位，由DBMS中的事务管理子系统负责事务的处理 ​ 但并不是所有的操作序列都可以称为为事务，因为一个操作序列成为事务，必须满足事务的四个特性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;ACID特性 9.1.1 原子性​ 原子是自然界最小的颗粒，具有不可再分的特性。事务中的所有操作可以看做一个原子，事务是应用中不可再分的最小的逻辑执行体。 ​ 使用事务对数据进行修改的操作序列，要么全部执行，要么全不执行。通常，某个事务中的操作都具有共同的目标，并且是相互依赖的。如果数据库系统只执行这些操作中的一部分，则可能会破坏事务的总体目标，而原子性消除了系统只处理部分操作的可能性。 9.1.2 一致性​ 一致性是指事务执行的结果必须使数据库从一个一致性状态，变到另一个一致性状态。当数据库中只包含事务成功提交的结果时，数据库处于一致性状态。一致性是通过原子性来保证的。 ​ 例如：在转账时，只有保证转出和转入的金额一致才能构成事务。也就是说事务发生前和发生后，数据的总额依然匹配。 9.1.3 隔离性​ 隔离性是指各个事务的执行互不干扰，任意一个事务的内部操作对其他并发的事务，都是隔离的。也就是说：并发执行的事务之间既不能看到对方的中间状态，也不能相互影响。 ​ 例如：在转账时，只有当A账户中的转出和B账户中转入操作都执行成功后才能看到A账户中的金额减少以及B账户中的金额增多。并且其他的事务对于转账操作的事务是不能产生任何影响的。 9.1.4 持久性​ 持久性指事务一旦提交，对数据所做的任何改变，都要记录到永久存储器中，通常是保存进物理数据库，即使数据库出现故障，提交的数据也应该能够恢复。但如果是由于外部原因导致的数据库故障，如硬盘被损坏，那么之前提交的数据则有可能会丢失。 9.2 事务的并发问题9.2.1 脏读（Dirty read）​ 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 9.2.2 不可重复读（Unrepeatableread）​ 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 9.2.3 幻读（Phantom read）​ 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 9.2.4 总结​ 不可重复读的重点是修改，幻读的重点在于新增或者删除 ​ 解决不可重复读的问题只需要锁住满足条件的行，解决幻读需要锁表 9.2.5 事务的隔离级别​ 事务的隔离级别用于决定如何控制并发用户读写数据的操作。数据库是允许多用户并发访问的，如果多个用户同时开启事务并对同一数据进行读写操作的话，有可能会出现脏读、不可重复读和幻读问题，所以MySQL中提供了四种隔离级别来解决上述问题。 ​ 事务的隔离级别从低到高依次为READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ以及SERIALIZABLE，隔离级别越低，越能支持高并发的数据库操作。 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITTED（读未提交） true true true READ COMMITTED（读已提交） false true true REPEATABLE READ（可重复读） false false true SERIALIZABLE（串行化） false false false ​","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"Spring","slug":"Spring","permalink":"https://lyblog2022.github.io/tags/Spring/"}]},{"title":"Servlet","date":"2022-06-04T08:59:30.000Z","path":"2022/06/04/study/Servlet/","text":"Servlet学习 1、Servlet的继承结构 2、Servlet接口 init()：创建servlet对象后立即调用该方法完成其他初始化工作 service()：处理客户端请求，执行业务操作，利用响应对象响应客户端请求 destory()：再销毁servlet对象之前调用该方法，释放资源 getServletConfig()：ServletConfig 是容器向Servlet传递参数的载体 getServletInfo()：获取servlet相关信息 3、ServletConfig 接口​ Servlet运行期间，需要一些辅助信息，这些信息可以在web.xml文件中，使用一个或多个元素进行配置。当tomacat初始化一个servlet时，会将该servlet的配置信息，封装到ServletConfig对象中，通过调用init(ServletConfig servletConfig)方法，将ServletConfig对象传递给Servlet 4、GenericServlet 抽象类​ GenericServlet是实现了Servlet接口的抽象类。在GenericServlet中进一步的定义了Servlet接口的具体实现，其设计的目的是为了和应用层协议解耦，再GenericServlet中包含了一个Service抽象方法，可以通过继承GenericServlet并实现Service方法实现请求的处理，但是需要将ServletRequest和ServletResponse 转化为HttpServletRequest和HttpServletResponse 5、HttpServlet​ 继承自GenericServlet，针对于处理Http协议的请求定制，在HttpServlet的service()方法中已经把ServletRequest和ServletResponse 转化为HttpServletRequest和HttpServletResponse 6、Servlet的生命周期​ servlet的生命周期是由容器管理的，分别经历4个阶段 阶段 字数 时机 创建 1次 第一次请求之后 初始化 1次 实例化之后 执行服务 多次 每次请求 销毁 1次 停止服务、 7、注意事项 在Servlet中一般不要轻易使用成员变量，可能会造成线程安全问题 如果要使用，应尽量避免对成员变量产生修改 如果要产生修改，应注意线程安全问题 8、ServletContext对象和ServletConfig对象​ ServletContext叫做Servlet上下文，服务器会为每一个web应用创建一个ServletContext对象，这个对象全局唯一，而且web应用中的所有Servlet都共享这个对象 8.1、ServletContext对象的作用 相对路径转为绝对路径 获取容器的附加信息 读取配置 全局容器 8.2、ServletContext的生命周期​ 当容器启动时会创建ServletContext对象并一直缓存该对象，直到容器关闭后该对象生命周期结束，ServletContext的生命周期非常长，所以在使用全局容器时不建议存放业务数据 8.3、ServletConfig对象​ ServletConfig对象对应web.xml文件中的节点，当Tomcat初始化一个Servlet时，会将该Servlet的配置信息，封装到一个ServletConfig对象中，可以通过该对象读取节点中的配置信息 9、请求转发9.1 forward转发9.1.1 forward转发处理流程 清空response存放的正在响应正文数据缓冲区 如果目标资源为Servlet或jsp，就调用他们的service方法，把该方法产生的响应结果发送到客户端；如果目标资源是静态文件中的HTML，就读取文件中的数据把它发送到客户端 9.1.2 forward处理特点 由于forward()方法先清空用于存放相应正文的缓冲区，因此源Servlet生成的响应结果不会被发送到客户端，只有目标资源生成的响应结果才会被发送到客户端 如果源Servlet在进行请求转发之前，已经提交了响应结(flushBuffer()，close()方法)，那么forward()方法会抛出异常，为避免异常，不应该在源servlet中提交响应结果 9.2 include转发9.2.1 include处理流程 如果目标资源为Servlet或者jsp，就调用他们的service方法，把该方法产生的响应正文添加到源Servlet的响应结果中；如果目标组建为HTML文档，就直接把文档的内容添加到源Servlet的响应结果中 返回到源Servlet的服务方法中，继续执行后续代码 9.2.2 include处理特点 源Servlet与被包含的目标资源的输出数据都会被添加到响应结果中 在目标资源对响应状态码或者响应开头所做的修改都会被忽略 10、Cookie对象和HttpSession对象​ Cookie对象和HttpSession对象的作用是维护客户端浏览器与服务端的会话状态的两个对象，二者的不同是Cookie是通过客户端浏览器实现会话的维持，而HttpSession是通过服务端来实现会话的维持 10.1 区别 cookie数据存放在客户的浏览器或系统文件中，httpsession中的数据存放在服务器中 cookie不安全，httpSession是安全的 单个cookie保存的数据不能超过4K，httpSession无限制","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"servlet","slug":"servlet","permalink":"https://lyblog2022.github.io/tags/servlet/"}]},{"title":"MyBatis","date":"2022-06-04T08:59:00.000Z","path":"2022/06/04/study/MyBatis/","text":"MyBatis学习 1、简介Mybatis 是一款优秀的持久层框架，支持定制化SQL、存储过程及高级映射，可以使用简单的XML或注解来配置和映射原生信息 是一款半自动的持久层的半自动ORM映射框架 1.1 框架 框架是一个基本概念上的结构，用于解决或处理复杂的问题。 使用框架的优点：减少开发时间，降低开发难度，保证设计质量，降低程序员之间的沟通以及日后维护的成本 框架是一个半成品，已经对基础的代码进行了封装并提供响应的API，开发者再使用框架是直接调用封装好的API，可以省去很多代码编写，从而提升效率和开发速度 1.2 ORM Object-Relation Mapping，对象关系映射 它的作用是在关系型数据库和对象之间做一个映射，这样在操作具体数据的时候就像操作对象一样 1.2.1 持久化 持久：把数据保存到可永久保存的存储设备中 主要应用：将内存中的数据存储在关系型数据库中 1.2.2 持久层 专注于实现数据持久化应用领域的某一个特定系统的一个逻辑层面，将数据使用者和数据实体想关联（mapper层、DAO层） 2、Mybatis配置2.1 事务​ 在MyBatis 核心配置文件中envirment 中通过transactionManager配置事务的处理策略 JDBC：该配置使用了JDBC的提交及回滚，依赖于从数据源得到的链接来管理事务范围 MANAGED：该配置几乎无任何操作，不提交或回滚一个链接，它会让容器来管理整个生命周期（Spring应用服务器的上下文），默认情况下会关闭链接，但一些容器不希望如此，因此如果需要从链接中停止它，将closeConnection的属性值设置为false，Mybatis本身并不会处理事务，而是交给其他框架去处理 2.2 映射文件的加载方式 mapper的映射文件的文件路径导入，使用的是mapper标签的resource属性 网络资源路径使用的是mapper的url属性 接口的全限定名导入使用的是mapper标签的class属性—–基于接口的代理模式 包扫描形式加载所有的mapper映射文件，使用的package标签 3、Mybatis 开发3.1 传递参数 ${} 代表mybatis底层使用Statment语句对象,参数是以字符串拼接的形式设置 #{} 代表mybatis底层使用的preparedStatment语句对象,参数使用?作为占位符处理，更常用 4、MyBatis代理模式开发在MyBatis中提供了一种称为Mapper代理（接口绑定）的操作方式，在实际开发中也使用该方式 4.1 原理浅析​ 底层使用了动态代理模式，动态创建一个Mapper的一个代理对象并赋给接口使用 5、动态SQL​ MyBatis在简化操作方法上提出了动态SQL功能，将使用Java代码拼接SQL语句，改变为在XML映射文件中截止标签拼接SQL语句。相比而言，大大减少代码量，更灵活、有利于后期维护 ​ MyBatis中动态SQL是编写在mapper.xml中的，其语法和JSTL类似，但是却是基于强大的OGNL表达式实现的 ​ MyBatis也可以在注解中配置SQL，但是由于注解功能受限，尤其是对于复杂的SQL语句，可读性很差，所以较少使用 5.1 If标签条件查询，符合if的条件，则补充SQL语句 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.mapper.StudentMapper&quot;&gt; &lt;select id=&quot;findByCondition&quot; resultType=&quot;Student&quot;&gt; select * from student where 1=1 &lt;if test=&quot;stuno != null&quot;&gt; and stuno =#&#123;stuno&#125; &lt;/if&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; and classname like concat(&#x27;%&#x27;,#&#123;classname&#125;,&#x27;%&#x27;) &lt;/if&gt; &lt;/select&gt;&lt;/mapper&gt; 5.2 Where标签用于处理where关键字和and 1234567891011&lt;select id=&quot;findStuByCondition&quot; resultType=&quot;Student&quot;&gt; select * from student &lt;where&gt; &lt;if test=&quot;stuno != null&quot;&gt; and stuno= #&#123;stuno&#125; &lt;/if&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; and classname= #&#123;classname&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 5.3 Choose标签前面的when条件成立 后面的 when就不再判断了 12345678910111213&lt;select id=&quot;findStuByCondition&quot; resultType=&quot;Student&quot;&gt; select * from student &lt;where&gt; &lt;choose&gt; &lt;when test=&quot;stuno != null&quot;&gt; and stuno= #&#123;stuno&#125; &lt;/when&gt; &lt;when test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; and classname= #&#123;classname&#125; &lt;/when&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; 5.4 Set标签12345678910111213&lt;update id=&quot;updateStuByCondtion&quot; &gt; update student &lt;set&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27; &quot;&gt; , classname =#&#123;classname&#125; &lt;/if&gt; &lt;if test=&quot;stuno != null &quot;&gt; , stuname =#&#123;stuname&#125; &lt;/if&gt; &lt;/set&gt; where stuno =#&#123;stuno&#125;&lt;/update&gt; 5.5 Trim标签123456789101112131415161718&lt;update id=&quot;updateStuByCondition&quot; &gt; update student &lt;!--prefix 要增加什么前缀 prefixOverrides 要去除什么前缀 suffix 要增加什么后缀 suffixOverrides 要去除什么后缀 set 是trim的一种特殊情况 --&gt; &lt;trim prefix=&quot;set&quot; suffixOverrides=&quot;,&quot; &gt; &lt;if test=&quot;stuname != null and stuname != &#x27;&#x27;&quot;&gt; stuname= #&#123;stuname&#125;, &lt;/if&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; classname= #&#123;classname&#125;, &lt;/if&gt; &lt;/trim&gt; where stuno = #&#123;stuno&#125;&lt;/update&gt; 5.6 Bind标签一般用于处理模糊查询的模板 1234&lt;select id=&quot;findStuByClassName&quot; resultType=&quot;Student&quot;&gt; &lt;bind name=&quot;likePattern&quot; value=&quot;&#x27;%&#x27;+param1+&#x27;%&#x27;&quot;&gt;&lt;/bind&gt; select * from student where classname like #&#123;classname&#125;&lt;/select&gt; 6、缓存6.1 一级缓存​ 一级存储是SqlSession上的缓存，默认开启，是一种内存型缓存,不要求实体类对象实现Serializable接口 ​ 缓存中的数据使用键值对形式存储数据 ​ namespace+sqlid+args+offset&gt;&gt;&gt; hash值作为键,查询出的结果作为值 6.2 二级缓存​ 二级缓存是以namespace为标记的缓存，可以是由一个SqlSessionFactory创建的SqlSession之间共享缓存数据。默认并不开启，要求实体类必须实现序列化接口 注意： ​ 1、 MyBatis的二级缓存的缓存介质有多种多样，而并不一定是在内存中，所以需要对JavaBean对象实现序列化接口。 ​ 2、二级缓存是以 namespace 为单位的，不同 namespace 下的操作互不影响 ​ 3、加入Cache元素后，会对相应命名空间所有的select元素查询结果进行缓存，而其中的insert、update、delete在操作是会清空整个namespace的缓存 ​ 4、cache 有一些可选的属性 type, eviction, flushInterval, size, readOnly, blocking。 1&lt;cache type=&quot;&quot; readOnly=&quot;&quot; eviction=&quot;&quot;flushInterval=&quot;&quot;size=&quot;&quot;blocking=&quot;&quot;/&gt; 属性 含义 默认值 type 自定义缓存类，要求实现org.apache.ibatis.cache.Cache接口 null readOnly 是否只读 true:给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。false:会返回缓存对象的拷贝(通过序列化) 。这会慢一些,但是安全 false eviction 缓存策略LRU（默认） – 最近最少使用：移除最长时间不被使用的对象。FIFO – 先进先出：按对象进入缓存的顺序来移除它们。SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。 LRU flushInterval 刷新间隔，毫秒为单位。默认为null，也就是没有刷新间隔，只有执行update、insert、delete语句才会刷新 null size 缓存对象个数 1024 blocking 是否使用阻塞性缓存BlockingCachetrue：在查询缓存时锁住对应的Key，如果缓存命中了则会释放对应的锁，否则会在查询数据库以后再释放锁，保证只有一个线程到数据库中查找指定key对应的数据false：不使用阻塞性缓存，性能更好 false ​ 5、如果在加入Cache元素的前提下让个别select 元素不使用缓存，可以使用useCache属性，设置为false。**useCache**控制当前sql语句是否启用缓存 flushCache控制当前sql执行一次后是否刷新缓存 1&lt;select id=&quot;findStuByCondition&quot; resultType=&quot;Student&quot; useCache=&quot;true&quot; flushCache=&quot;false&quot;&gt; 6.3 三方缓存 分布式缓存框架：我们系统为了提高系统并发和性能，一般对系统进行分布式部署（集群部署方式）不适用分布缓存， 缓存的数据在各个服务单独存储，不方便系统开发。所以要使用分布式缓存对缓存数据进行集中管理.ehcache,redis ,memcache缓存框架。 Ehcache：是一种广泛使用的开源java分布式缓存。主要面向通用缓存，javaEE 和 轻量级容器。它具有内存和磁盘存储功能。被用于大型复杂分布式web application的","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://lyblog2022.github.io/tags/MyBatis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"518总结--post请求调用接口","date":"2022-05-18T13:06:35.000Z","path":"2022/05/18/dailysummary/20220518/dailysummary/","text":"使用post方式调用接口并传递参数 方式一1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.summary;import java.nio.charset.Charset;import java.util.ArrayList;import java.util.Iterator;import java.util.List;import java.util.Map;import org.apache.http.HttpEntity;import org.apache.http.NameValuePair;import org.apache.http.client.config.RequestConfig;import org.apache.http.client.entity.UrlEncodedFormEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpPost;import org.apache.http.entity.StringEntity;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.message.BasicNameValuePair;import org.apache.http.util.EntityUtils;import com.alibaba.fastjson.JSONObject;public class Summary &#123; /** * 发送post请求 * @param url：请求URL * @param headerParamsJson：请求header参数 * @param paramJson：请求参数 * @return */ public JSONObject sendData(String url, JSONObject headerParamsJson, JSONObject paramJson) &#123; JSONObject resultJson = new JSONObject(); // 发送post请求 try &#123; HttpPost httppost = new HttpPost(url); RequestConfig defaultRequestConfig = RequestConfig.custom().setConnectTimeout(5000) .setConnectionRequestTimeout(5000).setSocketTimeout(15000).build(); httppost.setConfig(defaultRequestConfig); StringEntity entity = new StringEntity(paramJson.toJSONString(), &quot;utf-8&quot;);// 解决中文乱码问题 entity.setContentEncoding(&quot;UTF-8&quot;); entity.setContentType(&quot;text/json&quot;); httppost.setEntity(entity); httppost.setHeader(&quot;Content-type&quot;, &quot;application/json&quot;); // 添加header参数 Iterator headerParamsIterator = headerParamsJson.entrySet().iterator(); while (headerParamsIterator.hasNext()) &#123; Map.Entry entry = (Map.Entry) headerParamsIterator.next(); httppost.setHeader(entry.getKey().toString(), entry.getValue().toString()); &#125; // 装填参数 List&lt;NameValuePair&gt; nvps = new ArrayList&lt;NameValuePair&gt;(); if (paramJson != null) &#123; Iterator iterator = paramJson.entrySet().iterator(); while (iterator.hasNext()) &#123; Map.Entry entry = (Map.Entry) iterator.next(); nvps.add(new BasicNameValuePair((String) entry.getKey(), (String) entry.getValue())); &#125; &#125; UrlEncodedFormEntity reqEntity = new UrlEncodedFormEntity(nvps, &quot;utf-8&quot;); httppost.setEntity(reqEntity); // 执行post请求. CloseableHttpClient httpclient = HttpClients.createDefault(); CloseableHttpResponse response1 = httpclient.execute(httppost); String resultText = &quot;&quot;; try &#123; int statusCode = response1.getStatusLine().getStatusCode(); if (statusCode != 200) &#123; throw new RuntimeException(&quot;请求失败&quot;); &#125; else &#123; // 响应实体 HttpEntity entity2 = response1.getEntity(); if (entity2 != null) &#123; // 响应内容 resultText = EntityUtils.toString(entity2, Charset.forName(&quot;UTF-8&quot;)); resultJson = JSONObject.parseObject(resultText); &#125; &#125; resultJson.put(&quot;code&quot;, statusCode); &#125; finally &#123; response1.close(); &#125; &#125; catch (Exception e) &#123; resultJson.put(&quot;code&quot;, &quot;410&quot;); resultJson.put(&quot;err&quot;, e.toString()); &#125; return resultJson; &#125;&#125;","tags":[{"name":"httpClient","slug":"httpClient","permalink":"https://lyblog2022.github.io/tags/httpClient/"},{"name":"那些代码那些总结","slug":"那些代码那些总结","permalink":"https://lyblog2022.github.io/tags/%E9%82%A3%E4%BA%9B%E4%BB%A3%E7%A0%81%E9%82%A3%E4%BA%9B%E6%80%BB%E7%BB%93/"},{"name":"接口调用","slug":"接口调用","permalink":"https://lyblog2022.github.io/tags/%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"}]}]