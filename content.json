[{"title":"线程的基础","date":"2022-08-15T14:03:13.000Z","path":"2022/08/15/study/并发编程/线程的基础/","text":"线程的基础及简单使用 1、基础概念1.1 进程与线程进程：指运行中的程序，比如使用的浏览器，微信，需要启动这个程序，操作系统会给这个程序分配一定的资源（占用内存资源） 线程：是CPU调度的基本单位，每个线程执行的都是某一个进程的某个片段 【例】：房子与人 现在有一个100平的房子，这个方式可以看做是一个进程 房子里有人，人就可以看做是一个线程 人在房子中做事，如吃饭，学习，睡觉。可以看做是线程在执行某个功能的代码 所谓进程就是线程的容器，需要线程利用进程中的一些资源，处理一个代码、指令。最终实现进程所预期的结果 进程与线程的区别： + **根本不同**：进程是操作系统分配的资源，线程是CPU调度的基本单位 + **资源方面**：同一个进程下的线程共享进程中的一些资源。线程同时拥有自身的独立存储空间，进程之间的资源通常是独立的 + **数量不同**：进程一般指的就是一个进程，而线程是依附于某个进程的，且一个进程中至少会有一个或多个线程 + **开销不同**：进程和线程不是一个级别的内容，线程的创建、终止时间是比较短的，而且线程之间的切换比进程之间的切换速度要快的多。进程之间的通讯很麻烦，通常用借助内核实现，线程之间通讯则比较简单 1.2 多线程多线程：单个进程中同时运行多个线程 多线程的使用是为了提供CPU的利用率，可以通过避免一些网络IO或者磁盘IO等需要等待的操作，让CPU去调度其他线程，这样可以大幅度的提升程序的效率，而不是一个一个的排队。如要处理一个网络等待的操作，开启一个线程取处理需要网络等待的任务，让当前业务线程可以继续往下执行逻辑，效率可以大幅度提升 多线程的局限： + 如果线程的数量特别多，CPU在切换线程上下文时，会额外造成很大的消耗 + 任务的拆分需要依赖业务场景，有一些异构化的任务，很难对任务拆分，还有很多业务并不是多线程处理更好 + **线程安全问题**：虽然多线程带来了一定的性能提升，但是在做一些操作时，多线程如果操作临界资源，可能会发生一些数据不一致的安全问题，甚至涉及到锁操作时会造成死锁问题 1.3 串行、并行、并发串行：一个一个排队，第一个做完，第二个才能开始做 并行：并行就是同时处理，一起处理，多核CPU同时调度多个线程，是真正的多个线程的同时执行，单核CPU无法实现并行效果 并发：CPU调度线程的概念，CPU在极短的时间内，反复切换执行不同的线程，宏观并行，微观串行 1.4 同步异步、阻塞非阻塞同步异步；执行某个功能后，被调用者是否会主动反馈信息 阻塞非阻塞：执行某个功能后，调用者是否需要一直等待结果的反馈 两个概念侧重点不同，下面用锅烧水的方式简述下列4种情况 同步阻塞：锅烧水，水烧开后不会主动通知用户，烧水开始执行后，需要一直等待水烧开 同步非阻塞：锅烧水，水烧开后不会主动通知用户，烧水开始执行后，不需要等待水烧开，可以在烧水的同时去做其他的事情，但需要时不时查看水是否开了 异步阻塞：水壶烧水，水烧开后，会主动通知用户，烧水开始执行后，需要一直等待水烧开 异步非阻塞：水壶烧水，水烧开后，会主动通知用户，烧水开始执行后，不需要等待水烧开，可以在烧水的同时去做其他的事情，但需要时不时查看水是否开了 【说明】异步非阻塞的效果是最好的，平时并发时，提升效率最好的方式就是采用异步非阻塞的方式处理一些多线程的任务 2、线程的创建线程的创建分为三种方式： 2.1 继承Thread类，重写run方法启动线程是调用start方法，这样会创建一个新的线程，并执行线程的任务 如果直接调用run方法，这样会让当前线程执行run方法中的业务逻辑 1234567891011121314151617181920212223242526/** * @description:多线程 * @author: ly * @create: 2022-08-16 15:49 * @version: 1.0 **/public class MyThread &#123; public static void main(String[] args) &#123; ThreadDemo threadDemo = new ThreadDemo(); threadDemo.start(); for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;main:&quot; + i); &#125; &#125;&#125;class ThreadDemo extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;thread:&quot; + i); &#125; &#125;&#125; 2.2 实现Runnable接口，重写run方法123456789101112131415161718192021222324252627/** * @description:多线程 * @author: ly * @create: 2022-08-16 15:49 * @version: 1.0 **/public class MyThread &#123; public static void main(String[] args) &#123; RunnableDemo runnableDemo = new RunnableDemo(); Thread thread = new Thread(runnableDemo); thread.start(); for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;main:&quot;+i); &#125; &#125;&#125;class RunnableDemo implements Runnable&#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;thread:&quot; + i); &#125; &#125;&#125; 最常用的方式： + 匿名内部类： 123456789101112131415161718192021222324/** * @description:多线程 * @author: ly * @create: 2022-08-16 15:49 * @version: 1.0 **/public class MyThread &#123; public static void main(String[] args) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;thread:&quot; + i); &#125; &#125; &#125;); thread.start(); for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;main:&quot;+i); &#125; &#125;&#125; lambda方法： 123456789101112131415161718192021/** * @description:多线程 * @author: ly * @create: 2022-08-16 15:49 * @version: 1.0 **/public class MyThread &#123; public static void main(String[] args) &#123; Thread thread = new Thread(()-&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;thread:&quot; + i); &#125; &#125;); thread.start(); for (int i = 0; i &lt; 100; i++) &#123; System.out.println(&quot;main:&quot;+i); &#125; &#125;&#125; 2.3 实现callable重写call方法，配合FutureTaskCallable一般用于有返回结果的非阻塞的执行方法 同步非阻塞 12345678910111213141516171819202122232425262728/** * @description:多线程 * @author: ly * @create: 2022-08-16 15:49 * @version: 1.0 **/public class MyThread &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; CallableDemo callableDemo = new CallableDemo(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(callableDemo); Thread thread = new Thread(futureTask); thread.start(); System.out.println(futureTask.get()); &#125;&#125;class CallableDemo implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; int count = 0; for (int i = 0; i &lt; 100; i++) &#123; count+=i; &#125; return count; &#125;&#125;","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"并发编程","slug":"并发编程","permalink":"https://lyblog2022.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"Nginx中location块配置","date":"2022-08-10T06:41:22.000Z","path":"2022/08/10/study/nginx/Nginx中location块配置/","text":"location 指令是 nginx 中最关键的指令之一，location 指令的功能是用来匹配不同的 URI 请求，进而对请求做不同的处理和响应，这其中较难理解的是多个 location 的匹配顺序 1、nginx文件结构先简单了解 nginx 的文件结构，nginx 的 HTTP 配置主要包括三个区块，结构如下： Global: nginx 运行相关 Events: 与用户的网络连接相关 http http Global：代理，缓存，日志，以及第三方模块的配置 server： server Global：虚拟主机相关 location：地址定向，数据缓存，应答控制，以及第三方模块的配置 从上面展示的 nginx 结构中可以看出 location 属于请求级别配置，这也是最常用的配置。 2、配置location块2.1 location 语法​ Location 块通过指定模式来与客户端请求的URI相匹配。 ​ Location基本语法： 匹配 URI 类型，有四种参数可选，当然也可以不带参数。 命名location，用@来标识，类似于定义goto语句块。 12location [ = | ~ | ~* | ^~ ] /URI &#123; … &#125;location @/name/ &#123; … &#125; 2.2 location匹配命令解释 参数 解释 空 location 后没有参数直接跟着 标准 URI，表示前缀匹配，代表跟请求中的 URI 从头开始匹配。 &#x3D; 用于标准 URI 前，要求请求字符串与其精准匹配，成功则立即处理，nginx停止搜索其他匹配。 ^~ 用于标准 URI 前，并要求一旦匹配到就会立即处理，不再去匹配其他的那些个正则 URI，一般用来匹配目录 ~ 用于正则 URI 前，表示 URI 包含正则表达式， 区分大小写 ~* 用于正则 URI 前， 表示 URI 包含正则表达式， 不区分大小写 @ @ 定义一个命名的 location，@ 定义的locaiton名字一般用在内部定向，例如error_page, try_files命令中。它的功能类似于编程中的goto。 2.3 location匹配顺序​ nginx有两层指令来匹配请求 URI 。第一个层次是 server 指令，它通过域名、ip 和端口来做第一层级匹配，当找到匹配的 server 后就进入此 server 的 location 匹配。 ​ location 的匹配并不完全按照其在配置文件中出现的顺序来匹配，请求URI 会按如下规则进行匹配： 先精准匹配 &#x3D; ，精准匹配成功则会立即停止其他类型匹配； 没有精准匹配成功时，进行前缀匹配。先查找带有 ^~ 的前缀匹配，带有 ^~ 的前缀匹配成功则立即停止其他类型匹配，普通前缀匹配（不带参数 ^~ ）成功则会暂存，继续查找正则匹配； &#x3D; 和 ^~ 均未匹配成功前提下，查找正则匹配 ~ 和 ~* 。当同时有多个正则匹配时，按其在配置文件中出现的先后顺序优先匹配，命中则立即停止其他类型匹配； 所有正则匹配均未成功时，返回步骤 2 中暂存的普通前缀匹配（不带参数 ^~ ）结果 以上规则简单总结就是优先级从高到低依次为（序号越小优先级越高） 1234561. location = # 精准匹配2. location ^~ # 带参前缀匹配3. location ~ # 正则匹配（区分大小写）4. location ~* # 正则匹配（不区分大小写）5. location /a # 普通前缀匹配，优先级低于带参数前缀匹配。6. location / # 任何没有匹配成功的，都会匹配这里处理 2.4 其他location配置相关2.4.1 匹配问号后的参数​ 请求 URI 中问号后面的参数是不能在 location 中匹配到的，这些参数存储在 $query_string 变量中，可以用 if 来判断。 例如，对于参数中带有单引号 ’ 进行匹配然后重定向到错误页面。 1234/plus/list.php?tid=19&amp;mid=1124‘if ( $query_string ~* “.*[;’&lt;&gt;].*” )&#123; return 404;&#125; 2.4.2 location URI结尾带不带 &#x2F;​ 关于 URI 尾部的 &#x2F; 有三点也需要说明一下。第一点与 location 配置有关，其他两点无关。 location 中的字符有没有 &#x2F; 都没有影响。也就是说 &#x2F;user&#x2F; 和 &#x2F;user 是一样的。 如果 URI 结构是 https://domain.com/ 的形式，尾部有没有 &#x2F; 都不会造成重定向。因为浏览器在发起请求的时候，默认加上了 &#x2F; 。虽然很多浏览器在地址栏里也不会显示 &#x2F; 如果 URI 的结构是 https://domain.com/some-dir/ 。尾部如果缺少 &#x2F; 将导致重定向。因为根据约定，URL 尾部的 &#x2F; 表示目录，没有 &#x2F; 表示文件。所以访问 &#x2F;some-dir&#x2F; 时，服务器会自动去该目录下找对应的默认文件。如果访问 &#x2F;some-dir 的话，服务器会先去找 some-dir 文件，找不到的话会将 some-dir 当成目录，重定向到 &#x2F;some-dir&#x2F; ，去该目录下找默认文件。可以去测试一下你的网站是不是这样的。 2.4.3 命名 location​ 带有 @ 的 location 是用来定义一个命名的 location，这种 location 不参与请求匹配，一般用在内部定向。用法如下： 1234567location / &#123; try_files $uri $uri/ @custom&#125;location @custom &#123; # ...do something&#125; ​ 上例中，当尝试访问 URI 找不到对应的文件就重定向到我们自定义的命名 location（此处为 custom）。 ​ 值得注意的是，命名 location 中不能再嵌套其它的命名 location。 2.5 location 实际使用建议 直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。 123location = / &#123; proxy_pass http://tomcat:8080/index&#125; 第二个必选规则是处理静态文件请求，这是 nginx 作为 http 服务器的强项，有两种配置模式，目录匹配或后缀匹配，任选其一或搭配使用： 1234567location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125; 第三个规则就是通用规则，用来转发动态请求到后端应用服务器，非静态文件请求就默认是动态请求，自己根据实际把握，毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了： 123location / &#123; proxy_pass http://tomcat:8080/&#125; 转自：Nginx 中 location 块配置详解","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"动静分离","date":"2022-08-10T05:58:27.000Z","path":"2022/08/10/study/nginx/动静分离/","text":"nginx动静分离 1、什么是动静分离​ 动静分离是指在web服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提升整个服务访问性能和可维护性。 ​ nginx 的动静分离，指的是由 nginx 将客户端请求进行分类转发，静态资源请求（如html、css、图片等）由静态资源服务器处理，动态资源请求（如 jsp页面、servlet程序等）由 tomcat 服务器处理，tomcat 本身是用来处理动态资源的，同时 tomcat 也能处理静态资源，但是 tomcat 本身处理静态资源的效率并不高，而且还会带来额外的资源开销。利用 nginx 实现动静分离的架构，能够让 tomcat 专注于处理动态资源，静态资源统一由静态资源服务器处理，从而提升整个服务系统的性能 。 ​ 参考自：使用nginx实现动静分离 2、使用nginx实现动静分离2.1 准备静态资源创建两个目录： ​ &#x2F;data&#x2F;www&#x2F;*.html ​ &#x2F;data&#x2F;images&#x2F;*.jpg","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"负载均衡","date":"2022-08-09T02:51:31.000Z","path":"2022/08/09/study/nginx/负载均衡/","text":"负载均衡及nginx负载均衡测试 1、 负载均衡1.1 什么是负载均衡​ 负载均衡（Load Balance，简称LB）是高并发、高可用系统不可少的关键组件，目标是尽力将网站流量平均分发到多个服务器上，以提高系统整体的响应速度和可用性。 1.2 作用 高并发：负载均衡通过算法调整负载，尽力均匀的分配应用集群中各节点的工作量，以此提高应用集群的并发处理能力（吞吐量）。 伸缩性：添加或减少服务器数量，然后由负载均衡进行分发控制。这使得应用集群具备伸缩性。 高可用：负载均衡器可以监控候选服务器，当服务器不可用时，自动跳过，将请求分发给可用的服务器。这使得应用集群具备高可用的特性。 安全防护：有些负载均衡软件或硬件提供了安全性功能，如：黑白名单处理、防火墙，防 DDos 攻击等。1.3 分类​ 支持负载均衡的技术很多，可以通过不同维度去进行分类。 1.3.1 载体维度分类​ 从支持负载均衡的载体来看，可以将负载均衡分为两类：硬件负载均衡、软件负载均衡 1.3.1.1 硬件负载均衡​ 硬件负载均衡，一般是在定制处理器上运行的独立负载均衡服务器，价格昂贵，土豪专属。硬件负载均衡的主流产品有:F5 和 A10。 硬件负载均衡的 优点： 功能强大：支持全局负载均衡并提供较全面的、复杂的负载均衡算法。 性能强悍：硬件负载均衡由于是在专用处理器上运行，因此吞吐量大，可支持单机百万以上的并发。 安全性高：往往具备防火墙，防 DDos 攻击等安全功能。 硬件负载均衡的 缺点： 成本昂贵：购买和维护硬件负载均衡的成本都很高。 扩展性差：当访问量突增时，超过限度不能动态扩容。 1.3.1.2 软件负载均衡​ 软件负载均衡，应用最广泛，无论大公司还是小公司都会使用。​ 软件负载均衡从软件层面实现负载均衡，一般可以在任何标准物理设备上运行。​ 软件负载均衡的 主流产品 有：Nginx、HAProxy、LVS。 LVS 可以作为四层负载均衡器。其负载均衡的性能要优于 Nginx。 HAProxy 可以作为 HTTP 和 TCP 负载均衡器。 Nginx、HAProxy 可以作为四层或七层负载均衡器。 软件负载均衡的 优点： 扩展性好：适应动态变化，可以通过添加软件负载均衡实例，动态扩展到超出初始容量的能力 成本低廉：软件负载均衡可以在任何标准物理设备上运行，降低了购买和运维的成本。 软件负载均衡的 缺点： 性能略差：相比于硬件负载均衡，软件负载均衡的性能要略低一些。1.3.2 网络通信分类​ 软件负载均衡从通信层面来看，又可以分为四层和七层负载均衡。1.3.2.1 七层负载均衡​ 就是可以根据访问用户的 HTTP 请求头、URL 信息将请求转发到特定的主机。 DNS 重定向 HTTP 重定向 反向代理1.3.2.2 四层负载均衡​ 基于 IP 地址和端口进行请求的转发。 修改 IP 地址 修改 MAC 地址1.3.2.3 DNS 负载均衡​ DNS 负载均衡一般用于互联网公司，复杂的业务系统不适合使用。大型网站一般使用 DNS 负载均衡作为 第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。DNS 负载均衡属于七层负载均衡。​ DNS 即 域名解析服务，是 OSI 第七层网络协议。DNS 被设计为一个树形结构的分布式应用，自上而下依次为：根域名服务器，一级域名服务器，二级域名服务器，… ，本地域名服务器。显然，如果所有数据都存储在根域名服务器，那么 DNS 查询的负载和开销会非常庞大。​ 因此，DNS 查询相对于 DNS 层级结构，是一个逆向的递归流程，DNS 客户端依次请求本地 DNS 服务器，上一级 DNS 服务器，上上一级 DNS 服务器，… ，根 DNS 服务器（又叫权威 DNS 服务器），一旦命中，立即返回。为了减少查询次数，每一级 DNS 服务器都会设置 DNS 查询缓存。​ DNS 负载均衡的工作原理就是：基于 DNS 查询缓存，按照负载情况返回不同服务器的 IP 地址。 ​ DNS 重定向的 优点： 使用简单：负载均衡工作，交给 DNS 服务器处理，省掉了负载均衡服务器维护的麻烦 提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址（类似 CDN 的原理），可以加快访问速度，改善性能； ​ DNS 重定向的 缺点： 可用性差：DNS 解析是多级解析，新增&#x2F;修改 DNS 后，解析时间较长；解析过程中，用户访问网站将失败； 扩展性低：DNS 负载均衡的控制权在域名商那里，无法对其做更多的改善和扩展； 维护性差：也不能反映服务器的当前运行状态；支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）。 1.3.2.4 HTTP 负载均衡​ HTTP 负载均衡是基于 HTTP 重定向实现的。HTTP 负载均衡属于七层负载均衡。 ​ HTTP 重定向原理是：根据用户的 HTTP 请求计算出一个真实的服务器地址，将该服务器地址写入 HTTP 重定向响应中，返回给浏览器，由浏览器重新进行访问。 ​ HTTP 重定向的优点：方案简单。 ​ HTTP 重定向的 缺点： 性能较差：每次访问需要两次请求服务器，增加了访问的延迟。 降低搜索排名：使用重定向后，搜索引擎会视为 SEO 作弊。 如果负载均衡器宕机，就无法访问该站点。 ​ 由于其缺点比较明显，所以这种负载均衡策略实际应用较少。 1.3.2.5 反向代理负载均衡​ 反向代理（Reverse Proxy）方式是指以 代理服务器 来接受网络请求，然后 将请求转发给内网中的服务器，并将从内网中的服务器上得到的结果返回给网络请求的客户端。反向代理负载均衡属于七层负载均衡。 ​ 反向代理服务的主流产品：Nginx、Apache。 ​ 正向代理与反向代理有什么区别？ 正向代理：发生在 客户端，是由用户主动发起的。翻墙软件就是典型的正向代理，客户端通过主动访问代理服务器，让代理服务器获得需要的外网数据，然后转发回客户端。 反向代理：发生在 服务端，用户不知道代理的存在。 反向代理的实现 ​ ​ 首先，在代理服务器上设定好负载均衡规则。然后，当收到客户端请求，反向代理服务器拦截指定的域名或 IP 请求，根据负载均衡算法，将请求分发到候选服务器上。其次，如果某台候选服务器宕机，反向代理服务器会有容错处理，比如分发请求失败 3 次以上，将请求分发到其他候选服务器上。 ​ 反向代理的 优点： 多种负载均衡算法：支持多种负载均衡算法，以应对不同的场景需求。 可以监控服务器：基于 HTTP 协议，可以监控转发服务器的状态，如：系统负载、响应时间、是否可用、连接数、流量等，从而根据这些数据调整负载均衡的策略。 ​ 反向代理的 缺点： 额外的转发开销：反向代理的转发操作本身是有性能开销的，可能会包括创建连接，等待连接响应，分析响应结果等操作。 增加系统复杂度：反向代理常用于做分布式应用的水平扩展，但反向代理服务存在以下问题，为了解决以下问题会给系统整体增加额外的复杂度和运维成本： 反向代理服务如果自身宕机，就无法访问站点，所以需要有 高可用 方案，常见的方案有：主备模式（一主一备）、双主模式（互为主备）。 反向代理服务自身也存在性能瓶颈，随着需要转发的请求量不断攀升，需要有 可扩展 方案。 1.3.2.6 IP负载均衡​ IP 负载均衡是在网络层通过修改请求目的地址进行负载均衡。 ​ ​ 如上图所示，IP 均衡处理流程大致为： 客户端请求 192.168.137.10，由负载均衡服务器接收到报文。 负载均衡服务器根据算法选出一个服务节点 192.168.0.1，然后将报文请求地址改为该节点的 IP。 真实服务节点收到请求报文，处理后，返回响应数据到负载均衡服务器。 负载均衡服务器将响应数据的源地址改负载均衡服务器地址，返回给客户端。 ​ IP 负载均衡在内核进程完成数据分发，较反向代理负载均衡有更好的从处理性能。但是，由于所有请求响应都要经过负载均衡服务器，集群的吞吐量受制于负载均衡服务器的带宽。 1.3.2.7 数据链路层负载均衡​ 数据链路层负载均衡是指在通信协议的数据链路层修改 mac 地址进行负载均衡。 ​ ​ 在 Linux 平台上最好的链路层负载均衡开源产品是 LVS (Linux Virtual Server)。LVS 是基于 Linux 内核中 netfilter 框架实现的负载均衡系统。netfilter 是内核态的 Linux 防火墙机制，可以在数据包流经过程中，根据规则设置若干个关卡（hook 函数）来执行相关的操作。 ​ LVS 的工作流程大致如下： 当用户访问 www.sina.com.cn 时，用户数据通过层层网络，最后通过交换机进入 LVS 服务器网卡，并进入内核网络层。 进入 PREROUTING 后经过路由查找，确定访问的目的 VIP 是本机 IP 地址，所以数据包进入到 INPUT 链上 IPVS 是工作在 INPUT 链上，会根据访问的 vip+port 判断请求是否 IPVS 服务，如果是则调用注册的 IPVS HOOK 函数，进行 IPVS 相关主流程，强行修改数据包的相关数据，并将数据包发往 POSTROUTING 链上。 POSTROUTING 上收到数据包后，根据目标 IP 地址（后端服务器），通过路由选路，将数据包最终发往后端的服务器上。 ​ 开源 LVS 版本有 3 种工作模式，每种模式工作原理截然不同，说各种模式都有自己的优缺点，分别适合不同的应用场景，不过最终本质的功能都是能实现均衡的流量调度和良好的扩展性。主要包括三种模式：DR 模式、NAT 模式、Tunnel 模式。 2、负载均衡算法​ 负载均衡器的实现可以分为两个部分： 根据负载均衡算法在候选服务器列表选出一个服务器; 将请求数据发送到该服务器上。 ​ 负载均衡算法是负载均衡服务核心中的核心。负载均衡产品多种多样，但是各种负载均衡算法原理是共性的。负载均衡算法有很多种，分别适用于不同的应用场景，本文仅介绍最为常见的负载均衡算法的特性及原理：轮询、随机、最小活跃数、源地址哈希、一致性哈希。 2.1 轮循(Round Robin) 将收到的请求循环分配到服务器集群中的每台机器，即有效服务器 使用这种方式，所有的标记进入虚拟服务的服务器应该有相近的资源容量以及负载形同的应用程序 如果所有的服务器有相同或者相近的性能那么选择这种方式会使服务器负载形同 基于这个前提，轮循调度是一个简单而有效的分配请求的方式 对于服务器不同的情况，选择这种方式就意味着能力比较弱的服务器也会在下一轮循环中接受轮循，即使这个服务器已经不能再处理当前这个请求了。这可能导致能力较弱的服务器超载。 2.2 加权轮循(Weighted Round Robin)​ 这种算法解决了简单轮循调度算法的缺点：传入的请求按顺序被分配到集群中服务器，但是会考虑提前为每台服务器分配的权重。管理员只是简单的通过服务器的处理能力来定义各台服务器的权重。例如，能力最强的服务器A给的权重是100，同时能力最低的服务器给的权重是50。这意味着在服务器B接收到第一个请求之前前，服务器A会连续的接受到2个请求，以此类推。 2.3 最少连接数(Least Connection) 以上两种方法都没有考虑的是系统不能识别在给定的时间里保持了多少连接。因此可能发生，服务器B服务器收到的连接比服务器A少但是它已经超载，因为服务器B上的用户打开连接持续的时间更长。这就是说连接数即服务器的负载是累加的。这种潜在的问题可以通过”最少连接数”算法来避免 传入的请求是根据每台服务器当前所打开的连接数来分配的。即活跃连接数最少的服务器会自动接收下一个传入的请求 和简单轮询的原则相同：所有拥有虚拟服务的服务器资源容量应该相近 值得注意的是，在流量率低的配置环境中，各服务器的流量并不是相同的，会优先考虑第一台服务器。这是因为，如果所有的服务器是相同的，那么第一个服务器优先，直到第一台服务器有连续的活跃流量，否则总是会优先选择第一台服务器。 2.4 源IP哈希(Source IP Hash) 这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器，这意味着对于同一主机来说他对应的服务器总是相同 使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可能导致服务器负载不平衡。 3、负载均衡测试3.1 目的 通过浏览器多次访问一个地址（http://www.ly.com/city） nginx接受上面的请求，并进行转发。 那么每个请求的响应，是来自于不同的tomcat提供的。（2台tomcat，端口：8081，8082）。两台tomcat，不同的响应内容：“8081”和“8082”。 3.2 步骤 准备2个tomcat，并做好响应的页面，启动，测试。 12345678910[root@192 sbin]# cd /usr/local/tomcatb/tomcat8082/webapps/city[root@192 city]# cat index.htmlthis is 8082[root@192 city]# pwd/usr/local/tomcatb/tomcat8082/webapps/city[root@192 sbin]# cd /usr/local/tomcatb/tomcat8081/webapps/city[root@192 city]# cat index.htmlthis is 8081[root@192 city]# pwd/usr/local/tomcatb/tomcat8081/webapps/city 访问测试： http://192.168.213.143:8081/city/ ​ http://192.168.213.143:8082/city/ 修改nginx.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # server list upstream myServers&#123; server localhost:8081; server localhost:8082; &#125; server &#123; listen 80; server_name www.ly.com; location /&#123; proxy_pass http://localhost:8080; &#125; &#125; server &#123; listen 9001; server_name www.ly.com; location ~ /beijing/ &#123; proxy_pass http://localhost:8081; &#125; location ~ /shanghai/ &#123; proxy_pass http://localhost:8082; &#125; &#125; server &#123; listen 9002; server_name www.ly.com; location / &#123; proxy_pass http://myServers; &#125; &#125;&#125; 重新加载nginx 1[root@192 sbin]# ./nginx -s reload 浏览器访问测试：http://www.ly.com:9002/city/ 4、负载均衡算法应用4.1 Round Robin轮询12345# server listupstream myServers&#123; server localhost:8081; server localhost:8082;&#125; 4.2 Least Connections123456# server listupstream myServers&#123; least_conn; server localhost:8081; server localhost:8082;&#125; 4.3 IP Hash123456# server listupstream myServers&#123; ip_hash; server localhost:8081; server localhost:8082;&#125; 调用则会显示8082 将8082标记为down 123456# server listupstream myServers&#123; ip_hash; server localhost:8081; server localhost:8082 down;&#125; 再次访问则会显示回8081 4.4 Generic Hash123456# server listupstream myServers&#123; hash $request_uri consistent; server localhost:8081; server localhost:8082;&#125; 4.5 Random123456# server listupstream myServers&#123; random two least_conn;; server localhost:8081; server localhost:8082;&#125; 4.6 服务权重12345# server listupstream myServers&#123; server localhost:8081 weight=2; server localhost:8082 weight=8;&#125; 参考自：什么是负载均衡，看完文章秒懂","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"nginx反向代理","date":"2022-08-08T12:48:36.000Z","path":"2022/08/08/study/nginx/nginx反向代理/","text":"nginx反向代理 1、单台代理1.1 目的： 在浏览器访问一个地址：www.ly.com Nginx接受上面的请求。 转发请求到tomcat。 tomcat响应一个页面，页面中有：”tomcat hello !!!”。 1.2 操作 启动nginx 1234[root@192 nginx]# ps -ef | grep nginxroot 2290 1 0 08:20 ? 00:00:00 nginx: master process ./nginxnginx 2320 2290 0 08:23 ? 00:00:00 nginx: worker processroot 2667 2175 0 09:02 pts/0 00:00:00 grep --color=auto nginx 浏览器访问：http://192.168.213.143/ 准备一个tomcat。 查看服务器上是否有tomcat？ 12[root@192 nginx]# systemctl status tomcatUnit tomcat.service could not be found. tomcat安装 在tomcat下创建文件 123456789101112131415161718192021222324252627282930313233343536373839[root@192 tomcat]# ll总用量 136drwxr-xr-x. 2 root root 4096 8月 8 09:25 bin-rw-r--r--. 1 root root 19992 8月 8 09:26 BUILDING.txtdrwxr-xr-x. 3 root root 4096 8月 8 09:32 conf-rw-r--r--. 1 root root 6210 8月 8 09:26 CONTRIBUTING.mddrwxr-xr-x. 2 root root 4096 8月 8 09:25 lib-rw-r--r--. 1 root root 57092 8月 8 09:26 LICENSEdrwxr-xr-x. 2 root root 4096 8月 8 09:32 logs-rw-r--r--. 1 root root 2333 8月 8 09:26 NOTICE-rw-r--r--. 1 root root 3398 8月 8 09:26 README.md-rw-r--r--. 1 root root 6901 8月 8 09:26 RELEASE-NOTES-rw-r--r--. 1 root root 16505 8月 8 09:26 RUNNING.txtdrwxr-xr-x. 2 root root 30 8月 8 09:25 tempdrwxr-xr-x. 7 root root 81 8月 8 09:26 webappsdrwxr-xr-x. 3 root root 22 8月 8 09:32 work[root@192 tomcat]# cd webapps[root@192 webapps]# ll总用量 8drwxr-xr-x. 15 root root 4096 8月 8 09:25 docsdrwxr-xr-x. 7 root root 99 8月 8 09:26 examplesdrwxr-xr-x. 6 root root 79 8月 8 09:26 host-managerdrwxr-xr-x. 6 root root 114 8月 8 09:26 managerdrwxr-xr-x. 3 root root 4096 8月 8 09:25 ROOT[root@192 webapps]# mkdir root[root@192 webapps]# ll总用量 8drwxr-xr-x. 15 root root 4096 8月 8 09:25 docsdrwxr-xr-x. 7 root root 99 8月 8 09:26 examplesdrwxr-xr-x. 6 root root 79 8月 8 09:26 host-managerdrwxr-xr-x. 6 root root 114 8月 8 09:26 managerdrwxr-xr-x. 2 root root 6 8月 8 09:34 rootdrwxr-xr-x. 3 root root 4096 8月 8 09:25 ROOT[root@192 webapps]# cd root[root@192 root]# vi index.html[root@192 root]# cat index.htmltomcat hello !!![root@192 root]# curl localhost:8080/root/index.htmltomcat hello !!! tomcat启动测试：http://192.168.213.143:8080/root/index.html 修改nginx配置文件 1234567891011121314151617181920http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server &#123; listen 80; server_name www.ly.com; location /&#123; proxy_pass http://localhost:8080; &#125; &#125;&#125; 重新加载配置文件： 1[root@192 sbin]# ./nginx -s reload 访问测试： http://www.ly.com/root/index.html 2、多台代理2.1 目的 浏览器访问：（http://www.ly.com/beijing），通过nginx，跳转到一个tomcat上（http://localhost:8081），在浏览器上显示：beijing。 浏览器访问：（http://www.ly.com/shanghai），通过nginx，跳转到一个tomcat上（http://localhost:8082），在浏览器上显示：shanghai。 2.2 操作 复制一个tomcat，一个为8081，另一个为8082 1234&lt;Server port=&quot;8015&quot; shutdown=&quot;SHUTDOWN&quot;&gt;&lt;Connector port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; 准备文件 8081&#x2F;webapps&#x2F;ROOT下添加index.html 1this is BEIJING 8082&#x2F;webapps&#x2F;ROOT下添加index.html 1this is SHANGHAI 创建文件，拷贝文件 1234567891011121314151617181920[root@192 tomcat8081]# cd webapps[root@192 webapps]# ll总用量 8drwxr-xr-x. 15 root root 4096 8月 8 10:15 docsdrwxr-xr-x. 7 root root 99 8月 8 10:16 examplesdrwxr-xr-x. 6 root root 79 8月 8 10:16 host-managerdrwxr-xr-x. 6 root root 114 8月 8 10:16 managerdrwxr-xr-x. 3 root root 4096 8月 8 10:48 ROOT[root@192 webapps]# mkdir beijing[root@192 webapps]# cp ROOT/index.html beijing/[root@192 tomcat8082]# cd webapps[root@192 webapps]# ll总用量 8drwxr-xr-x. 15 root root 4096 8月 8 10:16 docsdrwxr-xr-x. 7 root root 99 8月 8 10:16 examplesdrwxr-xr-x. 6 root root 79 8月 8 10:16 host-managerdrwxr-xr-x. 6 root root 114 8月 8 10:16 managerdrwxr-xr-x. 3 root root 4096 8月 8 10:48 ROOT[root@192 webapps]# mkdir shanghai[root@192 webapps]# cp ROOT/index.html shanghai/ 服务器端访问测试 修改nginx配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server &#123; listen 80; server_name www.ly.com; location /&#123; proxy_pass http://localhost:8080; &#125; &#125; server &#123; listen 9001; server_name www.ly.com; location ~ /beijing/ &#123; proxy_pass http://localhost:8081; &#125; location ~ /shanghai/ &#123; proxy_pass http://localhost:8082; &#125; &#125;&#125; 访问测试 http://www.ly.com:9001/shanghai/ http://www.ly.com:9001/beijing/","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"nginx常用命令及配置文件","date":"2022-08-08T12:17:04.000Z","path":"2022/08/08/study/nginx/nginx常用命令/","text":"nginx常用命令及配置文件 1、nginx常用命令1.1 查看nginx版本号12[root@192 sbin]# ./nginx -vnginx version: nginx/1.22.0 1.2 关闭nginx1234567[root@192 sbin]# ps -ef | grep nginxroot 2222 1 0 08:14 ? 00:00:00 nginx: master process ./nginxnginx 2223 2222 0 08:14 ? 00:00:00 nginx: worker processroot 2276 2175 0 08:19 pts/0 00:00:00 grep --color=auto nginx[root@192 sbin]# ./nginx -s stop[root@192 sbin]# ps -ef | grep nginxroot 2280 2175 0 08:19 pts/0 00:00:00 grep --color=auto nginx 1.3 启动nginx1234567[root@192 sbin]# ps -ef | grep nginxroot 2280 2175 0 08:19 pts/0 00:00:00 grep --color=auto nginx[root@192 sbin]# ./nginx[root@192 sbin]# ps -ef | grep nginxroot 2290 1 0 08:20 ? 00:00:00 nginx: master process ./nginxnginx 2291 2290 0 08:20 ? 00:00:00 nginx: worker processroot 2293 2175 0 08:20 pts/0 00:00:00 grep --color=auto nginx 1.4 重载配置文件配置文件位置：&#x2F;etc&#x2F;nginx&#x2F;nginx.conf 1[root@192 sbin]# ./nginx -s reload 2、配置文件介绍2.1 配置文件位置： 2.2 指令2.2.1 简单指令： 名称+参数组成 2.2.2 块指令： 2.3 整体分类2.3.1 全局块 从配置文件开始到events 配置一些影响nginx服务器整体运行的一些指令 2.3.2 events块 配置服务器与用户的网络链接相关的 2.3.3 http块 修改最频繁部分 配置文件引入、日志格式等等","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"树","date":"2022-08-01T06:04:23.000Z","path":"2022/08/01/algorithm/tree/tree/","text":"树的基本概念及二叉树的概念和遍历，转自数据结构：树(Tree)【详解】 1. 树的基本概念1.1 树的定义​ 树是n（n&gt;&#x3D;0）个结点的有限集。当n &#x3D; 0时，称为空树。在任意一棵非空树中应满足： 有且仅有一个特定的称为根的结点。 当n&gt;1时，其余节点可分为m（m&gt;0）个互不相交的有限集T1,T2,…,Tm，其中每个集合本身又是一棵树，并且称为根的子树。 ​ 显然，树的定义是递归的，即在树的定义中又用到了自身，树是一种递归的数据结构。树作为一种逻辑结构，同时也是一种分层结构，具有以下两个特点： 树的根结点没有前驱，除根结点外的所有结点有且只有一个前驱。 树中所有结点可以有零个或多个后继。 ​ 因此n个结点的树中有n-1条边。 1.2 基本术语​ 下面结合图示来说明一下树的一些基本术语和概念。 考虑结点K。根A到结点K的唯一路径上的任意结点,称为结点K的祖先。如结点B是结点K的祖先,而结点K是结点B的子孙。路径上最接近结点K的结点E称为K的双亲,而K为结点E的孩子。根A是树中唯一没有双亲的结点。有相同双亲的结点称为兄弟,如结点K和结点L有相同的双亲E,即K和L为兄弟。 树中一个结点的孩子个数称为该结点的度,树中结点的最大度数称为树的度。如结点B的度为2,结点D的度为3,树的度为3。 度大于0的结点称为分支结点(又称非终端结点);度为0(没有子女结点)的结点称为叶子结点(又称终端结点)。在分支结点中,每个结点的分支数就是该结点的度。 结点的深度、高度和层次。 结点的层次从树根开始定义,根结点为第1层,它的子结点为第2层,以此类推。双亲在同一层的结点互为堂兄弟,图中结点G与E,F,H,I,J互为堂兄弟。 结点的深度是从根结点开始自顶向下逐层累加的。 结点的高度是从叶结点开始自底向上逐层累加的。 树的高度(或深度)是树中结点的最大层数。图中树的高度为4。 有序树和无序树。树中结点的各子树从左到右是有次序的,不能互换,称该树为有序树,否则称为无序树。假设图为有序树,若将子结点位置互换,则变成一棵不同的树。 路径和路径长度。树中两个结点之间的路径是由这两个结点之间所经过的结点序列构成的,而路径长度是路径上所经过的边的个数。注意:由于树中的分支是有向的,即从双亲指向孩子,所以树中的路径是从上向下的,同一双亲的两个孩子之间不存在路径。 森林。森林是m (m≥0)棵互不相交的树的集合。森林的概念与树的概念十分相近，因为只要把树的根结点删去就成了森林。反之，只要给m棵独立的树加上一个结点，并把这m棵树作为该结点的子树，则森林就变成了树。 1.3 树的性质​ 树具有如下最基本的性质： 树中的结点数等于所有结点的度数加1. 度为m的树中，第i层上至多有m^(i-1)个节点（i&gt;&#x3D;1） 高度为h的m叉树至多有(m^h-1)&#x2F;(m-1)个节点 具有n个节点的m叉树的最小高度为[logm(n(m-1)+1)] 2. 二叉树2.1 概念​ 二叉树是另一种树形结构，其特点是每个结点至多只有两棵子树( 即二叉树中不存在度大于2的结点)，并且二叉树的子树有左右之分，其次序不能任意颠倒。​ 与树相似，二叉树也以递归的形式定义。二叉树是n (n≥0) 个结点的有限集合: ​ 二叉树是有序树，若将其左、右子树颠倒，则成为另一棵不同的二叉树。即使树中结点只有一棵子树，也要区分它是左子树还是右子树。二叉树的5种基本形态如图所示。 2.2 特殊的二叉树2.2.1 斜树​ 所有的结点都只有左子树的二叉树叫左斜树。所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 2.2.2 满二叉树​ 一颗高度为h，且含有2^h-1个节点的二叉树称为满二叉树，即树中的每层都含有最多的节点。满二叉树的叶子结点都集中在二叉树的最下一层，并且出叶子结点之外的每个节点度数均为2。可以对满二叉树按层序编号：约定编号从根节点(根节点编号为1)起，自上而下，自左而右。这样，每个节点对应一个编号，对于编号为i的节点，若有双亲，则其双亲为i&#x2F;2，若有左孩子，则左孩子为2i；若有右孩子，则右孩子为2i+1 2.2.3 完全二叉树​ 高度为h，有n个节点的二叉树，当且仅当其每个节点都与高度为h的满二叉树中编号为1~n的节点一一对应时，称为完全二叉树，其特点为： 若i&lt;&#x3D;n&#x2F;2，则节点i为分支节点，否则为叶子节点 叶子结点只可能在层次最大的两层上出现。对于最大层次中的叶子结点，都依次排列在该层最左边的位置上。 若有度为1 的结点，则只可能有一个，且该结点只有左孩子而无右孩子(重要特征)。 按层序编号后，一旦出现某结点(编号为i)为叶子节点或只有左孩子，则编号大于i的节点均为叶子节点 若n为奇数，则每个分支节点都有左孩子和右孩子；若n为偶数，则编号最大的分支节点(编号为n&#x2F;2)只有左孩子，没有右孩子，其余分支节点左右孩子都有 2.2.4 二叉排序树​ 左子树上所有结点的关键字均小于根结点的关键字;右子树上的所有结点的关键字均大于根结点的关键字;左子树和右子树又各是一棵二叉排序树。 2.2.5 平衡二叉树​ 树上任一结点的左子树和右子树的深度之差不超过1。 2.3 二叉树的性质 任意一棵树，若节点数量为n，则边的数量为n-1 非空二叉树上的叶子节点树等于度为2的节点数+1 非空二叉树上第k层上至多有2^(k-1)个节点（k&gt;&#x3D;1） 高度为h的二叉树至多有2^h-1个节点（k&gt;&#x3D;1） 对完全二叉树按从上到下、从左到右的顺序依次编号1,2..n，则有以下关系 i&gt;1时，节点i的双亲的编号为i&#x2F;2，即当i为偶数时，它是双亲的左孩子；当i为奇数时，它是双亲的右孩子 当2i&lt;&#x3D;n时，节点i的左孩子编号为2i，否则无左孩子 当2i+1&lt;&#x3D;n时，节点i的右孩子编号为2i+1，否则无右孩子 节点i所在的层次（深度）为{log2 i} +1 具有n个（n&gt;0）节点的完全二叉树的高度为{log2 n}+1 2.4 二叉排序树​ 二叉排序树(也称二叉查找树)或者是一棵空树，或者是具有下列特性的二叉树: 若左子树非空，则左子树上所有结点的值均小于根结点的值。 若右子树非空，则右子树上所有结点的值均大于根结点的值。 左、右子树也分别是一棵二叉排序树。 2.5 平衡二叉树​ 平衡二叉树是一种儿茶排序树，其中每一个节点的左子树和右子树的高度差至多等于1 ​ 它是一种高度平衡的二叉排序树。它要么是一棵空树， 要么它的左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值不超过1。","tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://lyblog2022.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"树","slug":"树","permalink":"https://lyblog2022.github.io/tags/%E6%A0%91/"}]},{"title":"leetcode:814. 二叉树剪枝","date":"2022-07-21T09:06:19.000Z","path":"2022/07/21/leetcode/middle/question814/","text":"二叉树剪枝 给你二叉树的根结点 root ，此外树的每个结点的值要么是 0 ，要么是 1 。 返回移除了所有不包含 1 的子树的原二叉树。 节点 node 的子树为 node 本身加上所有 node 的后代。 示例 1： 1234输入：root = [1,null,0,0,1]输出：[1,null,0,null,1]解释：只有红色节点满足条件“所有不包含 1 的子树”。 右图为返回的答案。 示例 2： 12输入：root = [1,0,1,0,0,0,1]输出：[1,null,1,null,1] 示例 3： 12输入：root = [1,1,0,1,1,0,1,0]输出：[1,1,0,1,1,null,1] 提示： 树中节点的数目在范围 [1, 200] 内 Node.val 为 0 或 1 12345678910111213141516171819202122232425262728package com.question814;/** * TreeNode * * @author liuyong * @version 1.0 * @description com.question814 * @date 2022/7/21 17:01 */public class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode() &#123; &#125; TreeNode(int val) &#123; this.val = val; &#125; TreeNode(int val, TreeNode left, TreeNode right) &#123; this.val = val; this.left = left; this.right = right; &#125;&#125; 1234567891011121314151617181920212223242526272829package com.question814;/** * Solution * * @author liuyong * @version 1.0 * @description com.question814 * @date 2022/7/21 17:01 */public class Solution &#123; public static void main(String[] args) &#123; &#125; public TreeNode pruneTree(TreeNode root) &#123; if (root == null) &#123; return null; &#125; else &#123; root.left = pruneTree(root.left); root.right = pruneTree(root.right); if (root.left == null &amp;&amp; root.right == null &amp;&amp; root.val == 0) &#123; return null; &#125; return root; &#125; &#125;&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://lyblog2022.github.io/tags/leetcode/"}]},{"title":"leetcode:1260. 二维网格迁移","date":"2022-07-20T09:32:32.000Z","path":"2022/07/20/leetcode/easy/question1260/","text":"二维网格迁移 给你一个 m 行 n 列的二维网格 grid 和一个整数 k。你需要将 grid 迁移 k 次。每次「迁移」操作将会引发下述活动： 位于 grid [i][j] 的元素将会移动到 grid[i][j + 1]。 位于 grid[i][n - 1] 的元素将会移动到 grid[i + 1][0]。 位于 grid[m - 1][n - 1] 的元素将会移动到 grid[0][0]。 请你返回 k 次迁移操作后最终得到的 二维网格。 示例 1： 12输入：grid = [[1,2,3],[4,5,6],[7,8,9]], k = 1输出：[[9,1,2],[3,4,5],[6,7,8]] 示例 2： 123456输入：grid = [[3,8,1,9],[19,7,2,5],[4,6,11,10],[12,0,21,13]], k = 4输出：[[12,0,21,13],[3,8,1,9],[19,7,2,5],[4,6,11,10]]示例 3：输入：grid = [[1,2,3],[4,5,6],[7,8,9]], k = 9输出：[[1,2,3],[4,5,6],[7,8,9]] 提示： m &#x3D;&#x3D; grid.length n &#x3D;&#x3D; grid[i].length 1 &lt;&#x3D; m &lt;&#x3D; 50 1 &lt;&#x3D; n &lt;&#x3D; 50 -1000 &lt;&#x3D; grid[i][j] &lt;&#x3D; 1000 0 &lt;&#x3D; k &lt;&#x3D; 100 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.question1260;import java.util.ArrayList;import java.util.List;/** * Solution * * @author liuyong * @version 1.0 * @description com.question1260 * @date 2022/7/20 15:52 */public class Solution &#123; public static void main(String[] args) &#123; int[][] grid = &#123;&#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;&#125;; System.out.println(new Solution().shiftGrid(grid, 4)); &#125; public List&lt;List&lt;Integer&gt;&gt; shiftGrid(int[][] grid, int k) &#123; List&lt;List&lt;Integer&gt;&gt; resultList = new ArrayList&lt;&gt;(); //行数 int m = grid.length; //列数 int n = grid[0].length; if (k % (m * n) == 0) &#123; //特殊情况1，翻转次数是行*列的倍数，不需要处理 &#125; else &#123; int rest = k % (m * n); int index = 0; //特殊情况2，翻转次数是列的倍数，则行整体翻转 if (rest % n == 0) &#123; index = k / n; System.out.println(index); while (index != 0) &#123; int f = m - 1; int[] tmp = grid[f]; while (f&gt;0) &#123; grid[f] = grid[f-1]; f--; &#125; grid[0] = tmp; index--; &#125; &#125; else &#123; //数据处理 while (k&gt;0) &#123; //列交换 int h = m-1; //最后一列备份 int tmp0 = grid[m-1][n-1]; int[] tmp = new int[m]; while (h&gt;0) &#123; tmp[h] = grid[h-1][n-1]; h--; &#125; tmp[0] = tmp0; h =0; //交换 while (h&lt;m) &#123; int l = n-1; while (l&gt;0) &#123; grid[h][l] = grid[h][l-1]; l--; &#125; grid[h][0]=tmp[h]; h++; &#125; k--; &#125; &#125; &#125; //格式转化 for (int i = 0; i &lt; m; i++) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; n; j++) &#123; list.add(grid[i][j]); &#125; resultList.add(list); &#125; return resultList; &#125;&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://lyblog2022.github.io/tags/leetcode/"}]},{"title":"leetcode:8. 字符串转换整数 (atoi)","date":"2022-07-19T08:48:34.000Z","path":"2022/07/19/leetcode/middle/question8/","text":"请你来实现一个 myAtoi(string s) 函数，使其能将字符串转换成一个 32 位有符号整数（类似 C&#x2F;C++ 中的 atoi 函数）。 函数 myAtoi(string s) 的算法如下： 读入字符串并丢弃无用的前导空格检查下一个字符（假设还未到字符末尾）为正还是负号，读取该字符（如果有）。 确定最终结果是负数还是正数。 如果两者都不存在，则假定结果为正。读入下一个字符，直到到达下一个非数字字符或到达输入的结尾。字符串的其余部分将被忽略。将前面步骤读入的这些数字转换为整数（即，”123” -&gt; 123， “0032” -&gt; 32）。如果没有读入数字，则整数为 0 。必要时更改符号（从步骤 2 开始）。如果整数数超过 32 位有符号整数范围 [−231, 231 − 1] ，需要截断这个整数，使其保持在这个范围内。具体来说，小于 −231 的整数应该被固定为 −231 ，大于 231 − 1 的整数应该被固定为 231 − 1 。返回整数作为最终结果。注意： 本题中的空白字符只包括空格字符 ‘ ‘ 。除前导空格或数字后的其余字符串外，请勿忽略 任何其他字符。 示例 1： 1234567891011输入：s = &quot;42&quot;输出：42解释：加粗的字符串为已经读入的字符，插入符号是当前读取的字符。第 1 步：&quot;42&quot;（当前没有读入字符，因为没有前导空格） ^第 2 步：&quot;42&quot;（当前没有读入字符，因为这里不存在 &#x27;-&#x27; 或者 &#x27;+&#x27;） ^第 3 步：&quot;42&quot;（读入 &quot;42&quot;） ^解析得到整数 42 。由于 &quot;42&quot; 在范围 [-231, 231 - 1] 内，最终结果为 42 。 示例 2： 1234567891011输入：s = &quot; -42&quot;输出：-42解释：第 1 步：&quot; -42&quot;（读入前导空格，但忽视掉） ^第 2 步：&quot; -42&quot;（读入 &#x27;-&#x27; 字符，所以结果应该是负数） ^第 3 步：&quot; -42&quot;（读入 &quot;42&quot;） ^解析得到整数 -42 。由于 &quot;-42&quot; 在范围 [-231, 231 - 1] 内，最终结果为 -42 。 示例 3： 1234567891011输入：s = &quot;4193 with words&quot;输出：4193解释：第 1 步：&quot;4193 with words&quot;（当前没有读入字符，因为没有前导空格） ^第 2 步：&quot;4193 with words&quot;（当前没有读入字符，因为这里不存在 &#x27;-&#x27; 或者 &#x27;+&#x27;） ^第 3 步：&quot;4193 with words&quot;（读入 &quot;4193&quot;；由于下一个字符不是一个数字，所以读入停止） ^解析得到整数 4193 。由于 &quot;4193&quot; 在范围 [-231, 231 - 1] 内，最终结果为 4193 。 提示： 0 &lt;&#x3D; s.length &lt;&#x3D; 200s 由英文字母（大写和小写）、数字（0-9）、’ ‘、’+’、’-‘ 和 ‘.’ 组成 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.question8;/** * Solution * * @author liuyong * @version 1.0 * @description com.question8 * @date 2022/7/19 16:31 */public class Solution &#123; public static void main(String[] args) &#123; System.out.println(new Solution().myAtoi(&quot;-+12&quot;)); &#125; public int myAtoi(String s) &#123; String result = &quot;&quot;; s = s.trim(); int index = 0; while (index &lt; s.length()) &#123; Character c = s.charAt(index); if (index == 0) &#123; if (c == &#x27;+&#x27;) &#123; index++; continue; &#125; else if (c == &#x27;-&#x27;) &#123; result += c; index++; continue; &#125; else if (Character.isDigit(c)) &#123; result += c; index++; continue; &#125; else &#123; break; &#125; &#125; else &#123; if (Character.isDigit(c)) &#123; result += c; index++; continue; &#125; else &#123; break; &#125; &#125; &#125; if (!&quot;&quot;.equals(result)) &#123; if (&quot;-&quot;.equals(result)) &#123; return 0; &#125; if (Double.parseDouble(result) &gt; Integer.MAX_VALUE) &#123; return Integer.MAX_VALUE; &#125; else if (Double.parseDouble(result) &lt; Integer.MIN_VALUE) &#123; return Integer.MIN_VALUE; &#125; else &#123; return Integer.parseInt(result); &#125; &#125; else &#123; return 0; &#125; &#125;&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://lyblog2022.github.io/tags/leetcode/"}]},{"title":"leetcode:14. 最长公共前缀","date":"2022-07-18T08:40:03.000Z","path":"2022/07/18/leetcode/easy/question14/","text":"最长公共前缀编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，返回空字符串“”。 示例 1： 12输入：strs = [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]输出：&quot;fl&quot; 示例 2： 123输入：strs = [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]输出：&quot;&quot;解释：输入不存在公共前缀。 提示： 1 &lt;&#x3D; strs.length &lt;&#x3D; 200 0 &lt;&#x3D; strs[i].length &lt;&#x3D; 200 strs[i] 仅由小写英文字母组成 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.question14;/** * Solution * * @author liuyong * @version 1.0 * @description com.question14 * @date 2022/7/18 16:25 */public class Solution &#123; public static void main(String[] args) &#123; String[] str1 = &#123;&quot;dog&quot;, &quot;racecar&quot;, &quot;car&quot;&#125;; System.out.println(new Solution().longestCommonPrefix(str1)); &#125; public String longestCommonPrefix(String[] strs) &#123; String text = &quot;&quot;; if (strs != null &amp;&amp; strs.length != 0) &#123; if (strs.length == 1) &#123; return strs[0]; &#125; else &#123; //先读取前两个字符串的公共前缀 String str1 = strs[0]; String str2 = strs[1]; int index = 0; while (index &lt; str1.length() &amp;&amp; index &lt; str2.length()) &#123; char s1 = str1.charAt(index); char s2 = str2.charAt(index); if (s1 == s2) &#123; index++; text += s1; &#125; else &#123; break; &#125; &#125; if (text == null || &quot;&quot;.equals(text)) &#123; return text; &#125; else &#123; index = 2; while (index &lt; strs.length) &#123; if (strs[index].startsWith(text)) &#123; index++; &#125; else &#123; while (text.length() &gt; 0) &#123; text = text.substring(0, text.length() - 1); if (strs[index].startsWith(text)) &#123; break; &#125; &#125; if (&quot;&quot;.equals(text)) &#123; return text; &#125; &#125; &#125; return text; &#125; &#125; &#125; else &#123; return text; &#125; &#125;&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://lyblog2022.github.io/tags/leetcode/"}]},{"title":"leetcode:13.罗马数字转整数","date":"2022-07-16T05:36:08.000Z","path":"2022/07/16/leetcode/easy/question13/","text":"罗马数字转整数难度简单1965收藏分享切换为英文接收动态反馈 罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。 12345678字符 数值I 1V 5X 10L 50C 100D 500M 1000 例如， 罗马数字 2 写做 II ，即为两个并列的 1 。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给定一个罗马数字，将其转换成整数。 示例 1: 12输入: s = &quot;III&quot;输出: 3 示例 2: 12输入: s = &quot;IV&quot;输出: 4 示例 3: 12输入: s = &quot;IX&quot;输出: 9 示例 4: 123输入: s = &quot;LVIII&quot;输出: 58解释: L = 50, V= 5, III = 3. 示例 5: 123输入: s = &quot;MCMXCIV&quot;输出: 1994解释: M = 1000, CM = 900, XC = 90, IV = 4. 提示： 1 &lt;= s.length &lt;= 15 s 仅含字符 (&#39;I&#39;, &#39;V&#39;, &#39;X&#39;, &#39;L&#39;, &#39;C&#39;, &#39;D&#39;, &#39;M&#39;) 题目数据保证 s 是一个有效的罗马数字，且表示整数在范围 [1, 3999] 内 题目所给测试用例皆符合罗马数字书写规则，不会出现跨位等情况。 IL 和 IM 这样的例子并不符合题目要求，49 应该写作 XLIX，999 应该写作 CMXCIX 。 关于罗马数字的详尽书写规则，可以参考 罗马数字 - Mathematics 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.question13;import java.util.HashMap;import java.util.Map;/** * 13题 * @author liuyong * @version 1.0 * @description com.question13 * @date 2022/7/16 13:47 */public class Solution &#123; public static void main(String[] args) &#123; System.out.println(new Solution().romanToInt(&quot;DCXXI&quot;)); &#125; public int romanToInt(String s) &#123; int result = 0; //数据初始化 Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); map.put(&quot;I&quot;, 1); map.put(&quot;V&quot;, 5); map.put(&quot;X&quot;, 10); map.put(&quot;L&quot;, 50); map.put(&quot;C&quot;, 100); map.put(&quot;D&quot;, 500); map.put(&quot;M&quot;, 1000); map.put(&quot;IV&quot;, 4); map.put(&quot;IX&quot;, 9); map.put(&quot;XL&quot;, 40); map.put(&quot;XC&quot;, 90); map.put(&quot;CD&quot;, 400); map.put(&quot;CM&quot;, 900); if (s != null &amp;&amp; !&quot;&quot;.equals(s)) &#123; int index = 0; while (index &lt; s.length()) &#123; int num = 0; Character s1 = s.charAt(index); String text = s1.toString(); //组合字符处理 if ((&quot;I&quot;.equals(text) || &quot;X&quot;.equals(text) || &quot;C&quot;.equals(text)) &amp;&amp; index &lt; (s.length() - 1)) &#123; text += s.charAt(++index); //组合字符取值 if (map.containsKey(text)) &#123; num += map.get(text); index++; &#125; else &#123; //单个字符取值 text = text.substring(0, 1); num += map.get(text); &#125; &#125; else &#123; num += map.get(text); index++; &#125; result += num; &#125; return result; &#125; else &#123; return 0; &#125; &#125;&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://lyblog2022.github.io/tags/leetcode/"}]},{"title":"平衡树及红黑树","date":"2022-07-11T09:38:25.000Z","path":"2022/07/11/algorithm/tree/平衡树及红黑树/","text":"平衡二叉树及红黑树 1. 平衡二叉树​ 平衡二叉树有以下规则： 规则1：每个节点最多只有两个子节点（二叉） 规则2：每个节点的值比它的左子树所有的节点大，比它的右子树所有节点小（有序） 规则3：每个节点左子树的高度与右子树高度之差的绝对值不超过1 【总结】:平衡二叉树其实就是高度相对平衡的有两个子节点的有序树。 2. 红黑树​ 红黑树和上面的平衡二叉树类似，本质上都是为了解决排序二叉树在极端情况下退化成链表导致检索效率大大降低的问题，红黑树最早是由 Rudolf Bayer 于 1972 年发明的。 红黑树首先肯定是一个排序二叉树，它在每个节点上增加了一个存储位来表示节点的颜色，可以是 RED 或 BLACK 。 2.1 特性 每个节点要么是红色，要么是黑色。 根节点永远是黑色的。 所有的叶子节点都是空节点（即null），并且是黑色的。 每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点 从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。 红黑树的平衡通过旋转实现，任何不平衡都会在三次旋转之内解决。查找，插入，删除的时间复杂度均为O(log(N)) 【说明】 对于性质 1 和性质 2 ，相当于是对红黑树每个节点的约束，根节点是黑色，其他的节点要么是红色，要么是黑色。 性质 3 中指定红黑树的每个叶子节点都是空节点，而且叶子节点都是黑色，但 Java 实现的红黑树会使用 null 来代表空节点，因此我们在遍历 Java里的红黑树的时候会看不到叶子节点，而看到的是每个叶子节点都是红色的，这一点需要注意。 约束4和5，保证了红黑树的大致平衡：根到叶子的所有路径中，最长路径不会超过最短路径的2倍。 使得红黑树在最坏的情况下，也能有O(log2 N)的查找效率 红黑树在最差情况下，最长的路径都不会比最短的路径长出两倍。其实红黑树并不是真正的平衡二叉树，它只能保证大致是平衡的，因为红黑树的高度不会无限增高，在实际应用用，红黑树的统计性能要高于平衡二叉树，但极端性能略差。 2.2 红黑树的插入​ 红黑树的插入和普通排序二叉树的插入基本一致，排序二叉树的要求是左子树上的所有节点都要比根节点小，右子树上的所有节点都要比跟节点大，当插入一个新的节点的时候，首先要找到当前要插入的节点适合放在排序二叉树哪个位置，然后插入当前节点即可。红黑树和排序二叉树不同的是，红黑树需要在插入节点调整树的结构来让树保持平衡。 ​ 一般情况下，红黑树中新插入的节点都是红色的，那么，为什么说新加入到红黑树中的节点要是红色的呢？ ​ 这个问题可以这样理解，我们从性质5中知道，当前红黑树中从根节点到每个叶子节点的黑色节点数量是一样的，此时假如新的黑色节点的话，必然破坏规则，但加入红色节点却不一定，除非其父节点就是红色节点，因此加入红色节点，破坏规则的可能性小一些。 ​ 接下来我们重点来讲红黑树插入新节点后是如何保持平衡的。 ​ 给定下面这样一颗红黑树： ​ 当插入值为66的节点的时候，示意图如下： ​ 很明显，这个时候结构依然遵循着上述5大特性，无需启动自动平衡机制调整节点平衡状态。 ​ 如果再向里面插入值为51的节点，这个时候红黑树变成了这样。 ​ 这样的结构实际上是不满足性质4的，红色两个子节点必须是黑色的，而这里49这个红色节点现在有个51的红色节点与其相连。 ​ 这个时候需要调整这个树的结构来保证红黑树的平衡。 ​ 首先尝试将49这个节点设置为黑色，如下示意图。 ​ 这个时候黑高是不对的，其中 60-56-45-49-51-null 这条路径有 4 个黑节点，其他路径的黑色节点是 3 个。 ​ 接着调整红黑树，再次尝试把45这个节点设置为红色的，如下图所示： ​ 这个时候又出现新的问题，56-45-43 都是红色节点的，出现了红色节点相连的问题。 ​ 于是需要再把 56 和 43 设置为黑色的，如下图所示。 ​ 于是把 68 这个红色节点设置为黑色的。 ​ 对于这种红黑树插入节点的情况下，可以只需要通过变色就可以保持树的平衡了。但是并不是每次都是这么幸运的，当变色行不通的时候，需要考虑另一个手段就是旋转了。 【例如】下面这种情况，同样还是拿这颗红黑树举例。 ​ ​ 现在这颗红黑树，我们现在插入节点65。 ​ ​ 尝试把 66 这个节点设置为黑色，如下图所示。 ​ ​ 这样操作之后黑高又出现不一致的情况了，60-68-64-null 有 3 个黑色节点，而60-68-64-66-null 这条路径有 4 个黑色节点，这样的结构是不平衡的。 ​ 或者把 68 设置为黑色，把 64 设置为红色，如下图所示： ​ ​ 但是，同样的问题，上面这颗红黑树的黑色高度还是不一致，60-68-64-null 和 60-68-64-66-null 这两条路径黑色高度还是不一致。 ​ 这种情况如果只通过变色的情况是不能保持红黑树的平衡的。 2.3 红黑树的旋转2.3.1 左旋​ 逆时针旋转两个节点，让一个节点被其右子节点取代，而该节点成为右子节点的左子节点。 ​ 首先断开节点PL与右子节点G的关系，同时将其右子节点的引用指向节点C2；然后断开节点G与左子节点C2的关系，同时将G的左子节点的应用指向节点PL。 ​ ​ 2.3.2 右旋​ 顺时针旋转两个节点，让一个节点被其左子节点取代，而该节点成为左子节点的右子节点。 ​ 首先断开节点G与左子节点PL的关系，同时将其左子节点的引用指向节点C2；然后断开节点PL与右子节点C2的关系，同时将PL的右子节点的应用指向节点G。 ​ ​ 2.4 红黑树的几种旋转场景2.4.1 左左节点旋转（插入节点的父节点是左节点，插入节点也是左节点）​ 如下图所示的红黑树，插入节点是65。 ​ ​ 操作步骤如下可以围绕祖父节点 69 右旋，再结合变色，步骤如下所示 ​ 2.4.2 左右节点旋转（插入节点的父节点是左节点，插入节点是右节点）​ 还是上面这颗红黑树，再插入节点 67。 ​ ​ 这种情况可以这样操作，先围绕父节点 66 左旋，然后再围绕祖父节点 69 右旋，最后再将 67 设置为黑色，把 69 设置为红色，如下图所示。 ​ 2.4.3 右左节点旋转（插入节点的父节点是右节点，插入节点左节点）​ 如下图这种情况，要插入节点68。 ​ ​ 这种情况，可以先围绕父节点 69 右旋，接着再围绕祖父节点 66 左旋，最后把 68 节点设置为黑色，把 66 设置为红色，具体操作步骤如下所示。 ​ 2.4.4 右右节点旋转（插入节点的父节点是右节点，插入节点也是右节点）​ 还是来上面的图来举例，在这颗红黑树上插入节点 70 。 ​ ​ 可以这样操作围绕祖父节点 66 左旋，再把旋转后的根节点 69 设置为黑色，把 66 这个节点设置为红色。具体可以参看下图： ​ 参考： 红黑树与平衡二叉树_百图详解红黑树 【数据结构】红黑树与平衡二叉树的区别以及原理详解（附图解）","tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://lyblog2022.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"红黑树","slug":"红黑树","permalink":"https://lyblog2022.github.io/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"平衡树","slug":"平衡树","permalink":"https://lyblog2022.github.io/tags/%E5%B9%B3%E8%A1%A1%E6%A0%91/"}]},{"title":"RabbitMQ初步学习","date":"2022-06-26T02:17:45.000Z","path":"2022/06/26/study/rabbitMq/rabbitMQ1/","text":"RabbitMQ学习及简单原理简介 1、AMQP1.1 AMQP​ AMQP(Advanced Message Queuing Protocol，高级消息队列协议)是进程之间传递异步消息的网络协议。 1.2 AMQP工作过程​ 发布者(Publisher)发布消息(Message)，经过交换机(Exchange)，交换机根据路由规则将收到消息分发给交换机绑定的队列(Queue)，最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。 1.3 队列​ 队列是数据结构中概念。数据存储在一个队列中，数据是有顺序的，先进的先出，后进后出。其中一侧负责进数据，另一侧负责出数据。 ​ MQ（消息队列）很多功能都是基于此队列结构实现的 ​ 2、RabbitMQ2.1 RabbitMQ介绍​ RabbitMQ是由Erlang语言编写的基于AMQP的消息中间件。而消息中间件作为分布式系统重要组件之一，可以解决应用耦合，异步消息，流量削峰等问题。 2.1.1 解决应用耦合​ 不使用MQ时 ​ ​ 使用MQ解决耦合 ​ 2.2 RabbitMQ适用场景 排队算法 : 使用消息队列特性 秒杀活动 : 使用消息队列特性 消息分发 : 使用消息异步特性 异步处理 : 使用消息异步特性 数据同步 : 使用消息异步特性 处理耗时任务 : 使用消息异步特性 流量销峰 3、RabbitMQ原理​ Message：消息。消息是不具名的，它由消息头消息体组成。消息体是不透明的，而消息头则由一系列可选属性组成，这些属性包括：routing-key(路由键)、priority(相对于其他消息的优先权)、delivery-mode(指出消息可能持久性存储)等。 Publisher：消息的生产者。也是一个向交换器发布消息的客户端应用程序。 Consumer：消息的消费者。表示一个从消息队列中取得消息的客户端应用程序。 Exchange：交换器。用来接收生产者发送的消息并将这些消息路由给服务器中的队列。三种常用的交换器类型1. direct(发布与订阅 完全匹配)2. fanout(广播)3. topic(主题，规则匹配) Binding：绑定。用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue：消息队列。用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者链接到这个队列将其取走。 Routing-key：路由键。RabbitMQ决定消息该投递到哪个队列的规则。（也可以理解为队列的名称，路由键是key，队列是value）队列通过路由键绑定到交换器。消息发送到MQ服务器时，消息将拥有一个路由键，即便是空的，RabbitMQ也会将其和绑定使用的路由键进行匹配。如果相匹配，消息将会投递到该队列。如果不匹配，消息将会进入黑洞 Connection：链接。指rabbit服务器和服务建立的TCP链接。 Channel：信道。 Channel中文叫做信道，是TCP里面的虚拟链接。例如：电缆相当于TCP，信道是一个独立光纤束，一条TCP连接上创建多条信道是没有问题的。 TCP一旦打开，就会创建AMQP信道 无论是发布消息、接收消息、订阅队列，这些动作都是通过信道完成的。 Virtual Host：虚拟主机。表示一批交换器，消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个vhost本质上就是一个mini版的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在链接时指定，RabbitMQ默认的vhost是**&#x2F;** Borker：表示消息队列服务器实体。 交换器和队列的关系：交换器是通过路由键和队列绑定在一起的，如果消息拥有的路由键跟队列和交换器的路由键匹配，那么消息就会被路由到该绑定的队列中。也就是说，消息到队列的过程中，消息首先会经过交换器，接下来交换器在通过路由键匹配分发消息到具体的队列中。 路由键可以理解为匹配的规则。 RabbitMQ为什么需要信道？为什么不是TCP直接通信？ TCP的创建和销毁开销特别大。创建需要3次握手，销毁需要4次分手 如果不用信道，那应用程序就会以TCP链接Rabbit，高峰时每秒成千上万条链接会造成资源巨大的浪费，而且操作系统每秒处理TCP链接数也是有限制的，必定造成性能瓶颈 信道的原理是一条线程一条通道，多条线程多条通道同用一条TCP链接。一条TCP链接可以容纳无限的信道，即使每秒成千上万的请求也不会成为性能的瓶颈。 4、交换器（交换机）​ 交换器负责接收客户端传递过来的消息，并转发到对应的队列中。在RabbitMQ中支持四种交换器 Direct Exchange：直连交换器（默认） Fanout Exchange：扇形交换器 Topic Exchange：主题交换器 Header Exchange：首部交换器。 ​ 在RabbitMq的Web管理界面中Exchanges选项卡就可以看见这四个交换器。 4.1 direct交换器​ direct交换器是RabbitMQ默认交换器。默认会进行公平调度。所有接受者依次从消息队列中获取值。Publisher给哪个队列发消息，就一定是给哪个队列发送消息。对交换器绑定的其他队列没有任何影响。 ​ 代码实现 4.1.1 添加依赖1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 4.1.2 编写配置文件​ 新建application.yml. ​ host:默认值localhost ​ username默认值：guest ​ password默认值：guest 12345spring: rabbitmq: host: 192.168.213.133 username: ly password: qwq 4.1.3 配置类​ 队列的创建只有没有这个队列的时候需要编写。以后没有这个queue()方法也可以。 1234567891011121314151617181920212223package com.rabbitmq.config;import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * RabbitwqConfig * * @author liuyong * @version 1.0 * @description com.rabbitmq.config * @date 2022/6/26 11:08 */@Configurationpublic class RabbitwqConfig &#123; @Bean protected Queue queue() &#123; Queue queue = new Queue(&quot;myQueue&quot;); return queue; &#125;&#125; 4.1.4 编写测试类12345678910111213141516171819202122package com.rabbitmq;import org.junit.jupiter.api.Test;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;@SpringBootTest()class RabbitmqApplicationTests &#123; @Autowired private AmqpTemplate amqpTemplate; /** * provider */ @Test void contextLoads() &#123; amqpTemplate.convertAndSend(&quot;myQueue&quot;,&quot;send text312312&quot;); System.out.println(&quot;success&quot;); &#125;&#125; 4.1.5 创建consumerpom文件，yml文件，config文件与provider相同 4.1.6 编写监听器​ 注意： ​ 类上要有@Componet，项目启动时此类生效。 ​ @RabbitListener 监听指定队列。 1234567891011121314151617181920212223242526package com.rabbitmq.receive;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;/** * ReceiveDemo * * @author liuyong * @version 1.0 * @description com.rabbitmq.receive * @date 2022/6/26 11:49 */@Componentpublic class ReceiveDemo &#123; @RabbitListener(queues = &quot;myQueue&quot;) protected void demo(String msg) &#123; System.out.println(&quot;获取到的消息：&quot; + msg); &#125; @RabbitListener(queues = &quot;myQueue&quot;) protected void demo2(String msg) &#123; System.out.println(&quot;获取到的消息22222222：&quot; + msg); &#125;&#125; 4.2 fanout交换器​ 扇形交换器，实际上做的事情就是广播，fanout会把消息发送给所有的绑定在当前交换器上的队列。且每个队列消息中第一个Consumer能收到消息。 ​ 代码示例 pom文件、yml文件与direct示例相同 4.2.1 修改配置类在config配置文件内添加以下代码 12345678910111213141516171819202122@Bean public Queue createQueue1() &#123; return new Queue(&quot;myfanout1&quot;); &#125; @Bean public Queue createQueue2() &#123; return new Queue(&quot;myfanout2&quot;); &#125; @Bean public FanoutExchange getFanout() &#123; return new FanoutExchange(&quot;amq.fanout&quot;); &#125; @Bean public Binding binding(Queue createQueue1,FanoutExchange getFanout)&#123; return BindingBuilder.bind(createQueue1).to(getFanout); &#125; @Bean public Binding binding2(Queue createQueue2,FanoutExchange getFanout)&#123; return BindingBuilder.bind(createQueue2).to(getFanout); &#125; 4.2.2 编写发送方法12345@Test void contextLoads2() &#123; amqpTemplate.convertAndSend(&quot;amq.fanout&quot;,&quot;core&quot;,&quot;hhhh&quot;); System.out.println(&quot;success&quot;); &#125; 4.2.3 consumer在receiveDemo下添加以下代码 12345678@RabbitListener(queues = &quot;myfanout1&quot;) public void demo3(String msg) &#123; System.out.println(&quot;myfanout1:&quot;+msg); &#125; @RabbitListener(queues = &quot;myfanout2&quot;) public void demo4(String msg) &#123; System.out.println(&quot;myfanout2:&quot;+msg); &#125; 4.3 topic交换器​ 允许在路由键（RoutingKey）中出现匹配规则。 ​ 路由键的写法和包写法相同。com.xxxx.xxx格式。 ​ 在绑定时可以带有下面特殊符号，中间可以出现: ​ * : 代表一个单词（两个.之间内容） ​ # : 0个或多个字符 ​ 接收方依然是公平调度，同一个队列中内容轮换获取值。 ​ 示例代码 pom，yml文件与以上相同 4.3.1 修改配置类在config文件中添加以下代码 1234567891011121314151617181920@Bean public Queue topicQueue1()&#123; return new Queue(&quot;topic1&quot;); &#125; @Bean public Queue topicQueue2()&#123; return new Queue(&quot;topic2&quot;); &#125; @Bean public TopicExchange getTopic() &#123; return new TopicExchange(&quot;amq.topic&quot;); &#125; @Bean public Binding topicBinding1(Queue topicQueue1,TopicExchange getTopic)&#123; return BindingBuilder.bind(topicQueue1).to(getTopic).with(&quot;com.*&quot;); &#125; @Bean public Binding topicBinding2(Queue topicQueue2,TopicExchange getTopic)&#123; return BindingBuilder.bind(topicQueue2).to(getTopic).with(&quot;com.#&quot;); &#125; 4.3.2 发送消息​ 第二个参数为路由键，匹配配置类中绑定时的路由规则。 12345@Test void contextLoads3() &#123; amqpTemplate.convertAndSend(&quot;amq.topic&quot;,&quot;com.q.w&quot;,&quot;msg&quot;); System.out.println(&quot;success&quot;); &#125; 4.3.3 Consumer​ 在receiveDemo下添加以下代码 12345678@RabbitListener(queues = &quot;topic1&quot;) public void demo5(String msg) &#123; System.out.println(&quot;topic1:&quot;+msg); &#125; @RabbitListener(queues = &quot;topic2&quot;) public void demo6(String msg) &#123; System.out.println(&quot;topic2:&quot;+msg); &#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://lyblog2022.github.io/tags/RabbitMQ/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"RabbitMQ安装","date":"2022-06-25T05:16:19.000Z","path":"2022/06/25/software/rabbitMq/","text":"CentOS8安装RabbitMQ 1、Erlang安装​ RabbitMQ是使用Erlang语言编写的，所以需要先配置Erlang 1.1 修改主机名​ RabbitMQ是通过主机名进行访问的，必须指定能访问的主机名。 1vim /etc/sysconfig/network 12NETWORKING=yesHOSTNAME=ly 1vim /etc/hosts ​ 新添加了一行，前面为服务器ip，空格后面添加计算机主机名 1.2 安装依赖1yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel unixODBC unixODBC-devel 1.3 上传并解压​ 上传otp_src_22.0.tar.gz到&#x2F;usr&#x2F;local&#x2F;tmp目录中，进入目录并解压 ​ 解压时注意，此压缩包不具有gzip属性，解压参数没有z，只有xf 12cd /usr/local/tmptar xf otp_src_22.0.tar.gz 1.4 配置参数​ 先新建&#x2F;usr&#x2F;local&#x2F;erlang文件夹，作为安装文件夹 1mkdir -p /usr/local/erlang ​ 进入文件夹 1cd otp_src_22.0 ​ 配置参数 1./configure --prefix=/usr/local/erlang --with-ssl --enable-threads --enable-smp-support --enable-kernel-poll --enable-hipe --without-javac 1.5 编译并安装​ 编译 1make ​ 安装 1make install 1.6 修改环境变量​ 修改&#x2F;etc&#x2F;profile文件 1vim /etc/profile ​ 在文件中添加下面代码 1export PATH=$PATH:/usr/local/erlang/bin ​ 运行文件，让修改内容生效 1source /etc/profile 1.7 查看配置是否成功1erl -version 2、安装RabbitMQ2.1 上传并解压​ 上传rabbitmq-server-generic-unix-3.7.18.tar.xz到&#x2F;usr&#x2F;loca&#x2F;tmp中 12cd /usr/local/tmptar xf rabbitmq-server-generic-unix-3.7.18.tar.xz 2.2 复制到local下​ 复制解压文件到&#x2F;usr&#x2F;local下，命名为rabbitmq 1cp -r rabbitmq_server-3.7.18 /usr/local/rabbitmq 2.3 配置环境变量1vim /etc/profile ​ 在文件中添加 1export PATH=$PATH:/usr/local/rabbitmq/sbin ​ 解析文件 1source /etc/profile 2.4 开启web管理插件​ 进入rabbitmq&#x2F;sbin目录 1cd /usr/local/rabbitmq/sbin ​ 查看插件列表 1./rabbitmq-plugins list ​ 生效管理插件 1./rabbitmq-plugins enable rabbitmq_management 2.5 后台运行​ 启动rabbitmq。 1./rabbitmq-server -detached ​ 停止命令，如果无法停止，使用kill -9 进程号进行关闭 1./rabbitmqctl stop_app 2.6 查看web管理界面​ 默认可以在安装rabbitmq的电脑上通过用户名：guest密码guest进行访问web管理界面 ​ 端口号：15672（放行端口，或关闭防火墙） ​ 在虚拟机浏览器中输入：http://localhost:15672/#/ 3、RabbitMq账户管理3.1 创建账户​ 语法：.&#x2F;rabbitmqctl add_user username password 12cd /usr/local/rabbitmq/sbin./rabbitmqctl add_user ly qwq 3.2 给用户授予管理员角色​ 其中ly为新建用户的用户名 1./rabbitmqctl set_user_tags ly administrator 3.3 给用户授权​ “&#x2F;” 表示虚拟机 ​ ly 表示用户名 ​ “.“ “.“ “.*” 表示完整权限 1./rabbitmqctl set_permissions -p &quot;/&quot; ly &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 3.4 登录​ 使用新建账户和密码在windows中访问rabbitmq并登录 ​ 在浏览器地址栏输入：http://192.168.213.133:15672/#/ ​ 用户名：ly ​ 密码：qwq","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://lyblog2022.github.io/tags/RabbitMQ/"}]},{"title":"springboot整合redis","date":"2022-06-25T04:54:39.000Z","path":"2022/06/25/study/redis/redis4/","text":"SpringBoot整合SpringDataRedis操作redis ​ Spring Data是Spring公司的顶级项目，里面包含了N多个二级子项目，这些子项目都是相对独立的项目。每个子项目是对不同API的封装。 ​ 所有Spring Boot整合Spring Data xxxx的启动器都叫做spring-boot-starter-data-xxxx ​ Spring Data 好处很方便操作对象类型。 ​ 把Redis不同值得类型放到一个opsForXXX方法中。 opsForValue : String值 opsForList : 列表List opsForHash: 哈希表Hash opsForZSet: 有序集合Sorted Set opsForSet : 集合 1、SpringBoot整合Redis1.1 创建mysql数据库12345678910111213141516171819202122232425262728293031/* Navicat Premium Data Transfer Source Server : localhost Source Server Type : MySQL Source Server Version : 80029 Source Host : localhost:3306 Source Schema : study Target Server Type : MySQL Target Server Version : 80029 File Encoding : 65001 Date: 25/06/2022 16:23:52*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for product-- ----------------------------DROP TABLE IF EXISTS `product`;CREATE TABLE `product` ( `id` int NOT NULL, `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `price` decimal(10, 2) NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;SET FOREIGN_KEY_CHECKS = 1; 1.2 创建 redis配置文件1234567891011121314151617181920212223242526272829package com.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * RedisConfig * * @author liuyong * @version 1.0 * @description com.config * @date 2022/6/25 16:12 */@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String ,Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String , Object&gt; redisTemplate = new RedisTemplate&lt;String , Object&gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class)); redisTemplate.setConnectionFactory(factory); return redisTemplate; &#125;&#125; 1.3 创建pojo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.pojo;import java.io.Serializable;/** * Product * * @author liuyong * @version 1.0 * @description com.pojo * @date 2022/6/25 15:59 */public class Product implements Serializable &#123; private Integer id; private String name; private Double price; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getPrice() &#123; return price; &#125; public void setPrice(Double price) &#123; this.price = price; &#125; @Override public String toString() &#123; return &quot;Product&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, price=&quot; + price + &#x27;&#125;&#x27;; &#125;&#125; 1.4 创建mapper及配置文件12345678package com.mapper;import com.pojo.Product;public interface ProductMapper &#123; public Product findProductById(Integer id);&#125; 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.mapper.ProductMapper&quot;&gt; &lt;select id=&quot;findProductById&quot; resultType=&quot;com.pojo.Product&quot;&gt; select id, name, price from product where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 1.5 创建service接口及实现类1234567package com.service;import com.pojo.Product;public interface ProductService &#123; public Product findProductById(Integer id) ;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.service.impl;import com.mapper.ProductMapper;import com.pojo.Product;import com.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.stereotype.Service;/** * ProductServiceImpl * * @author liuyong * @version 1.0 * @description com.service.impl * @date 2022/6/25 16:01 */@Servicepublic class ProductServiceImpl implements ProductService&#123; @Autowired private ProductMapper productMapper; @Autowired private RedisTemplate&lt;String,Object&gt; redisTemplate; @Override public Product findProductById(Integer id) &#123; String key = &quot;product:&quot; +id; //先从redis中获取数据 if(redisTemplate.hasKey(key)) &#123; System.out.println(&quot;执行缓存&quot;); redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer&lt;Product&gt;(Product.class)); Product product = (Product) redisTemplate.opsForValue().get(key); return product; &#125; System.out.println(&quot;执行mysql&quot;); Product product = productMapper.findProductById(id); redisTemplate.opsForValue().set(key, product); return product; &#125;&#125; 1.6 创建控制类123456789101112131415161718192021222324252627282930package com.controller;import com.pojo.Product;import com.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;/** * ProductController * * @author liuyong * @version 1.0 * @description com.controller * @date 2022/6/25 16:03 */@Controllerpublic class ProductController &#123; @Autowired private ProductService productService; @GetMapping(&quot;/show&quot;) public String select(Integer id , Model model) &#123; Product product = productService.findProductById(id); model.addAttribute(&quot;product&quot; , product); return &quot;show&quot;; &#125;&#125; 1.7 创建启动器12345678910111213141516171819202122package com;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * ProductApplication * * @author liuyong * @version 1.0 * @description com * @date 2022/6/25 15:58 */@SpringBootApplication@MapperScan(&quot;com.mapper&quot;)public class ProductApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProductApplication.class , args); &#125;&#125; 1.8 创建配置文件123456789101112spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/study?characterEncoding=utf-8&amp;serverTimezone=UTC username: root password: liuyong redis: cluster: nodes: 192.168.213.133:7001,192.168.213.133:7002,192.168.213.133:7003,192.168.213.133:7004,192.168.213.133:7005,192.168.213.133:7006mybatis: type-aliases-package: com.pojo mapper-locations: classpath:com/mapper/*.xml 1.9 创建视图123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;span th:text=&quot;$&#123;product.id&#125;&quot;&gt;&lt;/span&gt; &lt;span th:text=&quot;$&#123;product.name&#125;&quot;&gt;&lt;/span&gt; &lt;span th:text=&quot;$&#123;product.price&#125;&quot;&gt;&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; 1.10 运行​ 第一次运行 ​ 第二次运行","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"springboot","slug":"springboot","permalink":"https://lyblog2022.github.io/tags/springboot/"},{"name":"centos8","slug":"centos8","permalink":"https://lyblog2022.github.io/tags/centos8/"}]},{"title":"redis哨兵及集群","date":"2022-06-23T12:15:01.000Z","path":"2022/06/23/study/redis/redis3/","text":"redis哨兵及集群配置及学习 1、哨兵（Sentinel）​ 在redis主从默认是只有主具备写的能力，而从只能读。如果主宕机，整个节点不具备写能力。但是如果这是让一个从变成主，整个节点就可以继续工作。即使之前的主恢复过来也当做这个节点的从即可。 ​ Redis的哨兵就是帮助监控整个节点的，当节点主宕机等情况下，帮助重新选取主。 ​ Redis中哨兵支持单哨兵和多哨兵。单哨兵是只要这个哨兵发现master宕机了，就直接选取另一个master。而多哨兵是根据我们设定，达到一定数量哨兵认为master宕机后才会进行重新选取主。 1.1 没有哨兵下主从效果​ 只要杀掉主，整个节点无法在写数据，从身份不会变化，主的信息还是以前的信息。 1.2 搭建多哨兵​ 前提：安装了单机的redis 1.2.1 新建目录1mkdir /usr/local/sentinel 1.2.2 复制redis1cp -r /usr/local/redis/bin/* /usr/local/sentinel 1.2.3 复制配置文件​ 从redis解压目录中复制sentinel配置文件 12cd /usr/local/tmp/redis-5.0.5/cp sentinel.conf /usr/local/sentinel/ 1.2.4 修改配置文件12cd /usr/local/sentinelvim sentinel.conf 1234port 26379daemonize yeslogfile “/usr/local/sentinel/26379.log”sentinel monitor mymaster 192.168.93.10 6379 2 ​ 复制sentinel.conf，命名为sentinel-26380.conf 12cp sentinel.conf sentinel-26380.confvim sentinel-26380.conf 1234port 26380daemonize yeslogfile “/usr/local/sentinel/26380.log”sentinel monitor mymaster 192.168.93.10 6379 2 ​ 复制sentinel.conf，命名为sentinel-26381.conf 12cp sentinel.conf sentinel-26381.confvim sentinel-26381.conf 1234port 26381daemonize yeslogfile “/usr/local/sentinel/26381.log”sentinel monitor mymaster 192.168.93.10 6379 2 1.2.5 启动主从​ 如果已经启动状态，忽略下面命令。如果启动部分，全部kill后重新启动。 ​ 使用kill杀死全部redis 12ps aux|grep rediskill -9 进程号 ​ 启动redis主从 12cd /usr/local/replica./startup.sh 1.2.6 启动三个哨兵1234cd /usr/local/sentinel./redis-sentinel sentinel.conf./redis-sentinel sentinel-26380.conf./redis-sentinel sentinel-26381.conf 1.2.7 查看日志1cat 26379.log 1.2.8 测试宕机​ 查看redis进程号 1ps aux|grep redis ​ 杀死主进程号 1kill -9 进程号 ​ 查看日志，短暂延迟后会发现，出现新的主。 1cat 26379.log 2、集群（Cluster）​ 前提：已经安装好redis单机版。 ​ 当集群中超过或等于1&#x2F;2节点不可用时，整个集群不可用。为了搭建稳定集群，都采用奇数节点。 2.1 复制redis配置文件​ 从&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin下把redis.conf复制到当前目录中，命名为redis-7001.conf 1cp /usr/local/redis/bin/redis.conf /usr/local/redis/bin/redis-7001.conf 2.2 修改redis-7001.conf12cd /usr/local/redis/binvim redis-7001.conf ​ 需要修改如下 12345678port 7001cluster-enabled yescluster-config-file nodes-7001.confcluster-node-timeout 15000# appendonly yes 如果开启aof默认，需要修改为yes。如果使用rdb，此处不需要修改daemonize yesprotected-mode nopidfile /var/run/redis_7001.pid 2.3 复制配置文件，并修改内容​ 把redis-7001.conf 复制5份，分别叫做redis-7002.conf、redis-7003.conf、redis-7004.conf、redis-7005.conf、redis-7006.conf 12345cp redis-7001.conf redis-7002.confcp redis-7001.conf redis-7003.confcp redis-7001.conf redis-7004.confcp redis-7001.conf redis-7005.confcp redis-7001.conf redis-7006.conf ​ 新复制的5个配置文件都需要需改三处。 ​ 例如nodes-7002.conf中需要把所有7001都换成7002。 ​ 可以使用 :%s&#x2F;7001&#x2F;7002&#x2F;g 进行全局修改。 2.4 启动6个redis​ 可以使用redis-server结合6个配置文件进行启动6个实例。 ​ 执行之前一定要先删除dump.rdb 12rm -f dump.rdbvim startup.sh 123456./redis-server redis-7001.conf./redis-server redis-7002.conf./redis-server redis-7003.conf./redis-server redis-7004.conf./redis-server redis-7005.conf./redis-server redis-7006.conf 12chmod a+x startup.sh./startup.sh 2.5 查看启动状态2.6 建立集群​ 在redis3的时候需要借助ruby脚本实现集群。在redis5中可以使用自带的redis-cli实现集群功能，比redis3的时候更加方便了。 ​ 建议配置静态ip，ip改变集群失效 1./redis-cli --cluster create 192.168.213.133:7001 192.168.213.133:7002 192.168.213.133:7003 192.168.213.133:7004 192.168.213.133:7005 192.168.213.133:7006 --cluster-replicas 1 2.7 测试​ 集群测试时，千万不要忘记最后一个-c参数。 1234./redis-cli -p 7001 -c127.0.0.1:7001&gt; set age 18OK127.0.0.1:7001&gt; 2.8 编写关闭脚本1vim stop.sh 123456./redis-cli -p 7001 shutdown./redis-cli -p 7002 shutdown./redis-cli -p 7003 shutdown./redis-cli -p 7004 shutdown./redis-cli -p 7005 shutdown./redis-cli -p 7006 shutdown 12chmod a+x stop.sh./stop.sh 3、Jedis​ Redis给Java语言提供了客户端API，称之为Jedis。 ​ Jedis API和Redis 命令几乎是一样的。 ​ 例如：Redis对String值新增时set命令，Jedis中也是set方法。 ​ Jedis API特别简单，基本上都是创建对象调用方法即可。 依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;!--版本号可根据实际情况填写2.9.0--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.1 单机版1234567891011121314151617181920package com.jedis;import redis.clients.jedis.Jedis;/** * Main * * @author liuyong * @version 1.0 * @description com.jedis * @date 2022/6/23 21:44 */public class Main &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;192.168.213.133&quot;,7001); jedis.set(&quot;text&quot;,&quot;hello jedis&quot;); String result = jedis.get(&quot;text&quot;); System.out.println(result); &#125;&#125; 3.2 带有连接池123456789101112131415161718192021222324252627package com.jedis;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;/** * PoolDemo * * @author liuyong * @version 1.0 * @description com.jedis * @date 2022/6/23 21:54 */public class PoolDemo &#123; public static void main(String[] args) &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(20); jedisPoolConfig.setMaxIdle(5); jedisPoolConfig.setMinIdle(3); JedisPool jedisPool = new JedisPool(jedisPoolConfig,&quot;192.168.213.133&quot;,7001); Jedis jedis = jedisPool.getResource(); jedis.set(&quot;jedisdemo&quot;,&quot;pool1&quot;); String value = jedis.get(&quot;jedisdemo&quot;); System.out.println(value); &#125;&#125; 3.3 集群12345678910111213141516171819202122232425262728293031package com.jedis;import redis.clients.jedis.HostAndPort;import redis.clients.jedis.JedisCluster;import java.util.HashSet;import java.util.Set;/** * ClusterDemo * * @author liuyong * @version 1.0 * @description com.jedis * @date 2022/6/23 21:59 */public class ClusterDemo &#123; public static void main(String[] args) &#123; Set&lt;HostAndPort&gt; set = new HashSet&lt;&gt;(); set.add(new HostAndPort(&quot;192.168.213.133&quot;,7001)); set.add(new HostAndPort(&quot;192.168.213.133&quot;,7002)); set.add(new HostAndPort(&quot;192.168.213.133&quot;,7003)); set.add(new HostAndPort(&quot;192.168.93.10&quot;,7004)); set.add(new HostAndPort(&quot;192.168.93.10&quot;,7005)); set.add(new HostAndPort(&quot;192.168.93.10&quot;,7006)); JedisCluster jedisCluster = new JedisCluster(set); jedisCluster.set(&quot;name&quot;,&quot;bjmsb&quot;); String value = jedisCluster.get(&quot;name&quot;); System.out.println(value); &#125;&#125; 报错： 1234567891011121314java.lang.NumberFormatException: For input string: &quot;7002@17002&quot;at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)at java.lang.Integer.parseInt(Integer.java:580)at java.lang.Integer.valueOf(Integer.java:766)at redis.clients.util.ClusterNodeInformationParser.getHostAndPortFromNodeLine(ClusterNodeInformationParser.java:38)at redis.clients.util.ClusterNodeInformationParser.parse(ClusterNodeInformationParser.java:14)at redis.clients.jedis.JedisClusterInfoCache.discoverClusterNodesAndSlots(JedisClusterInfoCache.java:43)at redis.clients.jedis.JedisClusterConnectionHandler.initializeSlotsCache(JedisClusterConnectionHandler.java:52)at redis.clients.jedis.JedisClusterConnectionHandler.&lt;init&gt;(JedisClusterConnectionHandler.java:37)at redis.clients.jedis.JedisSlotBasedConnectionHandler.&lt;init&gt;(JedisSlotBasedConnectionHandler.java:16)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:48)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:35)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:27)at redis.clients.jedis.JedisCluster.&lt;init&gt;(JedisCluster.java:31) 解决方案： 将redis依赖调高","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"centos8","slug":"centos8","permalink":"https://lyblog2022.github.io/tags/centos8/"}]},{"title":"redis持久化及主从复制","date":"2022-06-23T04:46:55.000Z","path":"2022/06/23/study/redis/redis2/","text":"Redis持久化策略及主从复制 1、Redis持久化策略​ Redis不仅仅是一个内存型数据库，还具备持久化能力。 1.1 RDB​ rdb模式是默认模式，可以在指定的时间间隔内生成数据快照（snapshot），默认保存到dump.rdb文件中。当redis重启后会自动加载dump.rdb文件中内容到内存中。 ​ 用户可以使用SAVE（同步）或BGSAVE（异步）手动保存数据。 ​ 可以设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令，可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行BGSAVE命令。 ​ 例如： ​ save 900 1 save 300 10 save 60 10000 ​ 那么只要满足以下三个条件中的任意一个，BGSAVE命令就会被执行 服务器在900秒之内，对数据库进行了至少1次修改 服务器在300秒之内，对数据库进行了至少10次修改 服务器在60秒之内，对数据库进行了至少10000次修改 1.1.1 优点 rdb文件是一个紧凑文件，直接使用rdb文件就可以还原数据。 数据保存会由一个子进程进行保存，不影响父进程。 恢复数据的效率要高于aof 1.1.2 缺点 每次保存点之间导致redis不可意料的关闭，可能会丢失数据。 由于每次保存数据都需要fork()子进程，在数据量比较大时可能会比较耗费性能。 1.2 AOF​ AOF默认是关闭的，需要在配置文件中开启AOF。Redis支持AOF和RDB同时生效，如果同时存在，AOF优先级高于RDB（Redis重新启动时会使用AOF进行数据恢复） ​ 监听执行的命令，如果发现执行了修改数据的操作，同时直接同步到数据库文件中。 1.2.1 优点​ 相对RDB数据更加安全。 1.2.2 缺点 相同数据集AOF要大于RDB。 相对RDB可能会慢一些。 1.2.3 开启办法​ 修改redis.conf文件 1234# 默认noappendonly yes# aof文件名appendfilename &quot;appendonly.aof&quot; 2、主从复制​ Redis支持集群功能。为了保证单一节点可用性，redis支持主从复制功能。每个节点有N个复制品（replica），其中一个复制品是主（master），另外N-1个复制品是从（Slave），也就是说Redis支持一主多从。 ​ 一个主可有多个从，而一个从又可以看成主，它还可以有多个从。 2.1 主从优点 增加单一节点的健壮性，从而提升整个集群的稳定性。（Redis中当超过1&#x2F;2节点不可用时，整个集群不可用） 从节点可以对主节点数据备份，提升容灾能力。 读写分离。在redis主从中，主节点一般用作写（具备读的能力），从节点只能读，利用这个特性实现读写分离，写用主，读用从。 2.2 一主多从搭建​ 在已经搭建的单机版redis基础上进行操作。 ​ 并且关闭redis单机版 1./redis-cli shutdown 2.2.1 新建目录1mkdir /usr/local/replica 2.2.2 复制目录把之前安装的redis单机版中bin目录复制三份，分别叫做：master、slave1、slave2 123cp -r /usr/local/redis/bin /usr/local/replica/mastercp -r /usr/local/redis/bin /usr/local/replica/slave1cp -r /usr/local/redis/bin /usr/local/replica/slave2 2.2.3 修改从的配置文件​ 修改2个从的redis.conf，指定主节点ip和端口。并修改自身端口号防止和其他redis冲突。 1vim /usr/local/replica/slave1/redis.conf ​ 指定主节点ip和端口 1replicaof 192.168.93.10 6379 ​ 修改自己端口 1port 6380 1vim /usr/local/replica/slave2/redis.conf ​ 指定主节点ip和端口 1replicaof 192.168.93.10 6379 ​ 修改自己端口 1port 6381 2.2.4 启动三个redis实例​ 注意：一定要关闭单机的redis，否则端口冲突。 12cd /usr/local/replicavim startup.sh ​ 在文件中添加下面内容 123456cd /usr/local/replica/master/./redis-server redis.conf cd /usr/local/replica/slave1./redis-server redis.conf cd /usr/local/replica/slave2./redis-server redis.conf ​ 赋予权限 1chmod a+x startup.sh ​ 开启 1./startup.sh 2.2.5 查看启动状态1ps aux|grep redis 2.2.6 测试12cd /usr/local/replica/master/./redis-cli 在客户端命令行模式下，添加一条数据 1127.0.0.1:6379&gt; set demo1 &quot;ly&quot; 进去slave查看数据是否同步。 12cd /usr/local/replica/slave1./redis-cli -p 6380","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"centos8","slug":"centos8","permalink":"https://lyblog2022.github.io/tags/centos8/"}]},{"title":"redis初步使用","date":"2022-06-22T05:13:45.000Z","path":"2022/06/22/study/redis/redis1/","text":"Redis初步学习及使用 1、Redis简介1.1 NoSQL简介​ 目前市场主流数据存储都是使用关系型数据库。每次操作关系型数据库时都是I&#x2F;O操作，I&#x2F;O操作是主要影响程序执行性能原因之一，连接数据库关闭数据库都是消耗性能的过程。尽量减少对数据库的操作，能够明显的提升程序运行效率。 ​ 针对上面的问题，市场上就出现了各种NoSQL(Not Only SQL,不仅仅可以使用关系型数据库)数据库，它们的宣传口号：不是什么样的场景都必须使用关系型数据库，一些特定的场景使用NoSQL数据库更好。 ​ 常见NoSQL数据库： memcached ：键值对，内存型数据库，所有数据都在内存中。 Redis：和Memcached类似，还具备持久化能力。 HBase：以列作为存储。 MongoDB：以Document做存储。 1.2 Redis简介 Redis是以Key-Value形式进行存储的NoSQL数据库。 Redis是使用C语言进行编写的。 平时操作的数据都在内存中，效率特高，读的效率110000&#x2F;s，写81000&#x2F;s，所以多把Redis当做缓存工具使用。 Redis以solt（槽）作为数据存储单元，每个槽中可以存储N多个键值对。Redis中固定具有16384。理论上可以实现一个槽是一个Redis。每个向Redis存储数据的key都会进行crc16算法得出一个值后对16384取余就是这个key存放的solt位置。 同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 2、常用的五大类型​ Redis不仅仅支持简单的k&#x2F;v类型的数据，同时还提供list，set，zset，hash等数据结构的存储，它还支持数据的备份，即master-slave模式的数据备份，同样Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 ​ Redis支持的五大数据类型包括String（字符串 用法： 键 值），Hash（哈希 类似Java中的 map 用法： 键 键值对），List（列表 用法：键 集合 不可以重复），Set（集合 用法：键 集合 可以重复），Zset（sorted set 有序集合 用法： 键 值 值） 2.1 String（字符串） string 是 redis 最基本的类型 可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据 是 Redis 最基本的数据类型 最大能存储 512MB。 应用场景 String是最常用的一种数据类型，普通的key&#x2F;value存储都可以归为此类，value其实不仅是String， 也可以是数字：比如想知道什么时候封锁一个IP地址(访问超过几次)。 2.2 Hash（哈希） Redis hash 是一个键值(key&#x3D;&gt;value)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 使用场景： 存储、读取、修改用户属性 如我们要存储一个用户信息对象数据，包含以下信息： 用户ID，为查找的key，存储的value用户对象包含姓名name，年龄age，生日birthday 等信息， 如果用普通的key&#x2F;value结构来存储，主要有以下2种存储方式： 第一种方式将用户ID作为查找key,把其他信息封装成一个对象以序列化的方式存储， 如：set u001 “李三,18,20010101” 这种方式的缺点是，增加了序列化&#x2F;反序列化的开销，并且在需要修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护，引入CAS等复杂问题。 第二种方法是这个用户信息对象有多少成员就存成多少个key-value对儿，用用户ID+对应属性的名称作为唯一标识来取得对应属性的值， ​ 如：mset user:001:name “李三 “user:001:age18 user:001:birthday “20010101” 虽然省去了序列化开销和并发问题，但是用户ID为重复存储，如果存在大量这样的数据，内存浪费还是非常可观的。 Redis提供的Hash很好的解决了这个问题。 2.3 List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序 可以添加一个元素到列表的头部（左边）或者尾部（右边）。 应用场景： Redis list的应用场景非常多，也是Redis最重要的数据结构之一。 Lists的另一个应用就是消息队列，可以利用Lists的PUSH操作，将任务存在Lists中，然后工作线程再用POP操作将任务取出进行执行。 2.4 Set（集合） Redis的Set是string类型的无序集合 使用场景 共同好友、二度好友 利用唯一性，可以统计访问网站的所有独立 IP 与list区别：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 比如在微博应用中，每个人的好友存在一个集合（set）中，这样求两个人的共同好友的操作，可能就只需要用求交集命令即可。 Redis还为集合提供了求交集、并集、差集等操作，可以非常方便的实 set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。 2.5 zset(sorted set：有序集合) 与set区别及联系：Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 使用场景 带有权重的元素，比如一个游戏的用户得分排行榜 比较复杂的数据结构，一般用到的场景不算太多 3、常用命令Redis命令手册 Redis命令参考","tags":[{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"redis单机版安装","date":"2022-06-22T03:16:38.000Z","path":"2022/06/22/software/redis/","text":"CentOS8安装Redis单机版 1、安装C语言依赖环境​ redis使用C语言编写，所以需要安装C语言库 1yum install -y gcc-c++ automake autoconf libtool make tcl 2、上传并解压​ 把redis-5.0.5.tar.gz上传到/usr/local/tmp中 ​ 解压文件 12cd /usr/local/tmptar zxf redis-5.0.5.tar.gz 3、编译并安装​ 进入解压文件夹 1cd /usr/local/tmp/redis-5.0.5/ ​ 编译 1make ​ 安装 1make install PREFIX=/usr/local/redis 4、开启守护进程复制/usr/local/tmp/redis-5.0.5/中redis.conf配置文件 1cp redis.conf /usr/local/redis/bin/ 修改配置文件 12cd /usr/local/redis/bin/vim redis.conf 把daemonize的值由no修改为yes 5、修改外部访问在redis5中需要修改配置文件redis.conf允许外部访问。需要修改两处。 注释掉bind 127.0.0.1 protected-mode yes 改成 no 6、启动并测试6.1 启动redis1./redis-server redis.conf 6.2 启动客户端工具1./redis-cli 6.3 关闭redis1./redis-cli shutdown","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"redis","slug":"redis","permalink":"https://lyblog2022.github.io/tags/redis/"}]},{"title":"nginx初步学习","date":"2022-06-21T13:44:31.000Z","path":"2022/06/21/study/nginx/nginx1/","text":"nginx简介及常用命令 1、nginx简介​ Nginx是一个高性能的Web服务器和反向代理的软件 ​ Web服务器：就是运行我们web服务的容器，提供web功能，还有tomcat也提供类似的功能。 ​ 代理是软件架构和网络设计中，非常重要的一个概念。有两种代理：正向代理和反向代理。 1.1 正向代理​ 用户端设置代理服务器。 ​ 所有的请求都由代理服务器发出，无法判断代理了多少用户端，叫正向代理 1.2 反向代理​ 和正向代理相反：在服务端设置代理，所有请求，由服务端接受，然后再由代理服务器发到后方的服务器。 ​ 这么一来，所有请求，都由一个服务器接收，无法判断代理了多少服务端。这就是反向代 理。 ​ 利用反向代理，就可以将请求分发到系统内部的多个节点上，从而减少每个节点的并发数。 ​ 而这些节点在外界看来，就是一个系统，表现出唯一的ip，也就是代理服务器的IP。 1.3 发展历程​ 最初是由一个俄罗斯人（Igor Sysoev：伊戈尔 塞索耶夫）开发的。 ​ Nginx的第一个版本发布于 2004年，因其系统资源消耗低、运行稳定，且具有高性能的并发处理能力等特性，Nginx在互联网 企业中得到广泛应用。 ​ Nginx是互联网上最受欢迎的开源Web服务器之一，Netcraft公司2019年7月 的统计数据表明，Nginx为全球最繁忙网站中的25.42%提供了服务或代理。得益于近几年云计算和 微服务的快速发展，Nginx因在其中发挥了自身优势而得到广泛应用，且有望在未来占有更多的市场 份额。 ​ 2019年3月，著名硬件负载均衡厂商F5宣布收购Nginx，Nginx成为F5的一部分。 2、nginx启动及验证2.1 找到命令目录12[root@192 sbin]# pwd/usr/local/nginx/sbin 2.2 启动123456[root@192 sbin]# ./nginxngx_http_fastdfs_set pid=13620[root@192 sbin]# ps -ef | grep nginxroot 13621 1 0 10:01 ? 00:00:00 nginx: master process ./nginxroot 13622 13621 0 10:01 ? 00:00:00 nginx: worker processroot 13628 3146 0 10:01 pts/0 00:00:00 grep --color=auto nginx 2.3 启动验证 本机访问：Welcome to nginx! 2.4 关闭1234[root@192 sbin]# ./nginx -s quitngx_http_fastdfs_set pid=13727[root@192 sbin]# ps -ef | grep nginxroot 13729 3146 0 10:07 pts/0 00:00:00 grep --color=auto nginx 3、nginx常用命令3.1 查看版本号12[root@192 sbin]# ./nginx -vnginx version: nginx/1.16.1 3.2 关闭nginx12345[root@192 sbin]# ./nginx -s quit[root@192 sbin]# ./nginx -s stopngx_http_fastdfs_set pid=13727[root@192 sbin]# ps -ef | grep nginxroot 13729 3146 0 10:07 pts/0 00:00:00 grep --color=auto nginx 3.3 启动Nginx命令123456[root@192 sbin]# ./nginxngx_http_fastdfs_set pid=13620[root@192 sbin]# ps -ef | grep nginxroot 13621 1 0 10:01 ? 00:00:00 nginx: master process ./nginxroot 13622 13621 0 10:01 ? 00:00:00 nginx: worker processroot 13628 3146 0 10:01 pts/0 00:00:00 grep --color=auto nginx 3.4 重新加载配置文件12[root@192 sbin]# ./nginx -s reloadngx_http_fastdfs_set pid=13917 4、配置文件找到nginx配置文件：&#x2F;etc&#x2F;nginx 指令种类： 简单指令： 块指令： 全局块：就是最开始的简单指令。从配置文件开始到events 1234user nginx;worker_processes auto;error_log /var/log/nginx/error.log notice;pid /var/run/nginx.pid; events块：配置服务器和用户网络连接相关的参数。 http块： 1234567891011121314151617181920212223http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # server块可以是 多个 server &#123; listen 80; # server_name 127.0.0.1; server_name www.cpf.com; # location 块可以是 多 个 location / &#123; proxy_pass http://127.0.0.1:8080; &#125; &#125;&#125;","tags":[{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"高并发场景下的 httpClient 优化使用","date":"2022-06-21T01:59:25.000Z","path":"2022/06/21/summary/High-concurrency/高并发场景下的httpClient优化使用/","text":"高并发场景下的 httpClient 优化使用，参考自：仰望星空的尘埃 1、HttpClient优化思路 池化 长链接 httpclient和httpget复用 合理的配置参数（最大并发请求数、各种超时时间、重试次数） 异步 源码 2、分析​ 原始的使用比较简单，即每次请求时初始化一个httpclient，生成一个httppost对象，执行，然后从返回结果中取出entity，保存成一个字符串，最后显示关闭response和client 2.1 httpclient反复创建开销​ httpclient是一个线程安全的类，没有必要由每个线程在每次使用时创建，全局保留一个即可 2.2 反复创建tcp连接的开销​ tcp的三次握手四次挥手两大过程，对于高频词的请求来说，消耗过大，如果每次请求需要花费5ms用于协商过程，那么对于qps为100的单系统，1秒钟就要花费500ms用于握手和挥手，so改成keep alive的方式实现连接复用 2.3 重复缓存entity的开销​ 一般情况下，使用了以下的代码 1String resultString = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); ​ 这里相当于额外复制了一份content到一个字符串内，而原本的httpResponse仍然保留了一份content，需要被consume掉，在高并发且content非常大的情况下，会消耗大量内存，并且需要显示的关闭链接 3、实现按照上面的分析，主要完成三件事： 单例的client 缓存的保持链接 更好的处理返回结果 提到连接缓存，很容易想到数据库连接池。httpclient4提供了一个PoolngHttpClientConnectionManager作为连接池。通过以下步骤进行优化 3.1 定义一个keep alive strategy​ 是否使用keep-alive要根据业务情况来定，其并不是灵丹妙药，而且keep-alive和time_wait/close_wait之间也有不少故事 ​ 在本业务场景下，相当于有少数固定的客户端，长时间高频次的访问服务器，启用keep-alive非常合适 ​ 【注意】 http的keep-alive与tcp的KEEPALIVE不是一个东西 定义一个strategy 1234567891011121314151617ConnectionKeepAliveStrategy strategy = new ConnectionKeepAliveStrategy() &#123; @Override public long getKeepAliveDuration(HttpResponse response, HttpContext context) &#123; HeaderElementIterator iterator = new BasicHeaderElementIterator(response.headerIterator(HTTP.CONN_KEEP_ALIVE)); while (iterator.hasNext()) &#123; HeaderElement element = iterator.nextElement(); String param = element.getName(); String value = element.getValue(); if (value != null &amp;&amp; param.equalsIgnoreCase(&quot;timeout&quot;)) &#123; return Long.parseLong(value) * 1000; &#125; &#125; //默认时长为60s return 60 * 1000; &#125;&#125;; 3.2 配置一个PoolingHttpClientConnectionManager1234PoolingHttpClientConnectionManager connectionManager = new PoolingHttpClientConnectionManager();connectionManager.setMaxTotal(500);//默认每个路由最高50并发，也可以针对每个路由设置并发数。connectionManager.setDefaultMaxPerRoute(50); 3.3 生成httpclient1234HttpClientBuilder httpClient = HttpClients.custom();httpClient.setConnectionManager(connectionManager);httpClient.setKeepAliveStrategy(strategy);httpClient.setDefaultRequestConfig(RequestConfig.custom().setStaleConnectionCheckEnabled(true).build()); 【注意】：使用setStaleConnectionCheckEnabled方法来逐出已被关闭的链接不被推荐。更好的方式是手动启用一个线程，定时运行closeExpiredConnections 和closeIdleConnections方法，如下所示。 12345678910111213141516171819202122232425262728293031public static class IdleConnectionMonitorThread extends Thread &#123; private final HttpClientConnectionManager manager; private volatile boolean shutdown; public IdleConnectionMonitorThread(HttpClientConnectionManager manager) &#123; super(); this.manager = manager; &#125; @Override public void run() &#123; try &#123; while(!shutdown)&#123; synchronized (this)&#123; wait(5000); manager.closeExpiredConnections(); manager.closeIdleConnections(30, TimeUnit.SECONDS); &#125; &#125; &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; public void shutdown() &#123; shutdown = true; synchronized (this)&#123; notifyAll(); &#125; &#125;&#125; 3.4 使用httpclient执行method时降低开销这里要注意的是，不要关闭connection。 一种可行的获取内容的方式类似于，把entity里的东西复制一份： 12res = EntityUtils.toString(response.getEntity(),&quot;UTF-8&quot;);EntityUtils.consume(response1.getEntity()); 但是，更推荐的方式是定义一个ResponseHandler，其相关源码如下： 1234567891011121314151617181920212223242526272829303132333435public &lt;T&gt; T execute(final HttpHost target, final HttpRequest request, final ResponseHandler&lt;? extends T&gt; responseHandler, final HttpContext context) throws IOException, ClientProtocolException &#123; Args.notNull(responseHandler, &quot;Response handler&quot;); final HttpResponse response = execute(target, request, context); final T result; try &#123; result = responseHandler.handleResponse(response); &#125; catch (final Exception t) &#123; final HttpEntity entity = response.getEntity(); try &#123; EntityUtils.consume(entity); &#125; catch (final Exception t2) &#123; // Log this exception. The original exception is more // important and will be thrown to the caller. this.log.warn(&quot;Error consuming content after an exception.&quot;, t2); &#125; if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; if (t instanceof IOException) &#123; throw (IOException) t; &#125; throw new UndeclaredThrowableException(t); &#125; // Handling the response was successful. Ensure that the content has // been fully consumed. final HttpEntity entity = response.getEntity(); // EntityUtils.consume(entity); return result; &#125; ​ 可以看到，如果我们使用resultHandler执行execute方法，会最终自动调用consume方法，而这个consume方法如下所示： 1234567891011public static void consume(final HttpEntity entity) throws IOException &#123; if (entity == null) &#123; return; &#125; if (entity.isStreaming()) &#123; final InputStream instream = entity.getContent(); if (instream != null) &#123; instream.close(); &#125; &#125; &#125; ​ 可以看到最终它关闭了输入流。 4、其他​ 通过以上步骤，基本就完成了一个支持高并发的httpclient的写法，下面是一些额外的配置和提醒： 4.1 httpclient的一些超时配置​ CONNECTION_TIMEOUT是连接超时时间，SO_TIMEOUT是socket超时时间，这两者是不同的。连接超时时间是发起请求前的等待时间；socket超时时间是等待数据的超时时间。 1234567891011121314151617181920HttpParams params = new BasicHttpParams();//设置连接超时时间//设置请求超时2秒钟 根据业务调整Integer CONNECTION_TIMEOUT = 2 * 1000; //设置等待数据超时时间2秒钟 根据业务调整Integer SO_TIMEOUT = 2 * 1000; //定义了当从ClientConnectionManager中检索ManagedClientConnection实例时使用的毫秒级的超时时间//这个参数期望得到一个java.lang.Long类型的值。如果这个参数没有被设置，默认等于CONNECTION_TIMEOUT，因此一定要设置。//在httpclient4.2.3中我记得它被改成了一个对象导致直接用long会报错，后来又改回来了Long CONN_MANAGER_TIMEOUT = 500L; params.setIntParameter(CoreConnectionPNames.CONNECTION_TIMEOUT, CONNECTION_TIMEOUT);params.setIntParameter(CoreConnectionPNames.SO_TIMEOUT, SO_TIMEOUT);params.setLongParameter(ClientPNames.CONN_MANAGER_TIMEOUT, CONN_MANAGER_TIMEOUT);//在提交请求之前 测试连接是否可用params.setBooleanParameter(CoreConnectionPNames.STALE_CONNECTION_CHECK, true); //另外设置http client的重试次数，默认是3次；当前是禁用掉（如果项目量不到，这个默认即可）httpClient.setHttpRequestRetryHandler(new DefaultHttpRequestRetryHandler(0, false)); 4.2 如果配置了nginx的话，nginx也要设置面向两端的keep-alive​ 现在的业务里，没有nginx的情况反而比较稀少。nginx默认和client端打开长连接而和server端使用短链接。注意client端的keepalive_timeout和keepalive_requests参数，以及upstream端的keepalive参数设置 ​ 依赖： 123456&lt;!-- httpclient --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.6&lt;/version&gt;&lt;/dependency&gt; 123456789101112//Basic认证private static final CredentialsProvider credsProvider = new BasicCredentialsProvider();//httpClientprivate static final CloseableHttpClient httpclient;//httpGet方法private static final HttpGet httpget;//private static final RequestConfig reqestConfig;//响应处理器private static final ResponseHandler&lt;String&gt; responseHandler;//jackson解析工具private static final ObjectMapper mapper = new ObjectMapper(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static &#123; System.setProperty(&quot;http.maxConnections&quot;,&quot;50&quot;); System.setProperty(&quot;http.keepAlive&quot;, &quot;true&quot;); //设置basic校验 credsProvider.setCredentials( new AuthScope(AuthScope.ANY_HOST, AuthScope.ANY_PORT, AuthScope.ANY_REALM), new UsernamePasswordCredentials(&quot;&quot;, &quot;&quot;)); //创建http客户端 httpclient = HttpClients.custom() .useSystemProperties() .setRetryHandler(new DefaultHttpRequestRetryHandler(3,true)) .setDefaultCredentialsProvider(credsProvider) .build(); //初始化httpGet httpget = new HttpGet(); //初始化HTTP请求配置 reqestConfig = RequestConfig.custom() .setContentCompressionEnabled(true) .setSocketTimeout(100) .setAuthenticationEnabled(true) .setConnectionRequestTimeout(100) .setConnectTimeout(100).build(); httpget.setConfig(reqestConfig); //初始化response解析器 responseHandler = new BasicResponseHandler();&#125;/* * 功能：返回响应 * @author zhangdaquan * @date 2019/1/3 上午11:19 * @param [url] * @return org.apache.http.client.methods.CloseableHttpResponse * @exception */public static String getResponse(String url) throws IOException &#123; HttpGet get = new HttpGet(url); String response = httpclient.execute(get,responseHandler); return response;&#125; /* * 功能：发送http请求，并用net.sf.json工具解析 * @author zhangdaquan * @date 2018/8/15 下午2:21 * @param [url] * @return org.json.JSONObject * @exception */public static JSONObject getUrl(String url) throws Exception&#123; try &#123; httpget.setURI(URI.create(url)); String response = httpclient.execute(httpget,responseHandler); JSONObject json = JSONObject.fromObject(response); return json; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125; 1234567891011121314151617181920212223242526272829303132333435363738/* * 功能：发送http请求，并用jackson工具解析 * @author zhangdaquan * @date 2018/12/24 下午2:58 * @param [url] * @return com.fasterxml.jackson.databind.JsonNode * @exception */public static JsonNode getUrl2(String url)&#123; try &#123; httpget.setURI(URI.create(url)); String response = httpclient.execute(httpget,responseHandler); JsonNode node = mapper.readTree(response); return node; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125;/* * 功能：发送http请求，并用fastjson工具解析 * @author zhangdaquan * @date 2018/12/24 下午2:58 * @param [url] * @return com.fasterxml.jackson.databind.JsonNode * @exception */public static com.alibaba.fastjson.JSONObject getUrl3(String url)&#123; try &#123; httpget.setURI(URI.create(url)); String response = httpclient.execute(httpget,responseHandler); com.alibaba.fastjson.JSONObject jsonObject = com.alibaba.fastjson.JSONObject.parseObject(response); return jsonObject; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125;","tags":[{"name":"httpClient","slug":"httpClient","permalink":"https://lyblog2022.github.io/tags/httpClient/"},{"name":"那些代码那些总结","slug":"那些代码那些总结","permalink":"https://lyblog2022.github.io/tags/%E9%82%A3%E4%BA%9B%E4%BB%A3%E7%A0%81%E9%82%A3%E4%BA%9B%E6%80%BB%E7%BB%93/"},{"name":"接口调用","slug":"接口调用","permalink":"https://lyblog2022.github.io/tags/%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"},{"name":"高并发","slug":"高并发","permalink":"https://lyblog2022.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"}]},{"title":"nginx安装","date":"2022-06-20T08:31:29.000Z","path":"2022/06/20/software/nginx/","text":"centos8安装nginx 1、上传并安装fastdfs-nginx-module​ 上传 &#x2F;fastdfs-nginx-model_v1.16.tar.gz 到 &#x2F;usr&#x2F;local&#x2F;tmp 中 ​ 进入 tmp 目录 1cd /usr/local/tmp ​ 解压 1tar zxf fastdfs-nginx-module_v1.16.tar.gz 2、修改配置文件​ 进入解压目录中src目录 1cd fastdfs-nginx-module/src ​ 编辑config文件 1vim config ​ 修改配置文件中第四行，把路径中local去掉。参数是用于配置安装nginx中的FastDFS组件的时候，在什么位置查找FastDFS核心代码。 1CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot; 3、安装nginx的依赖1yum install -y gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel 4、上传Nginx 并解压​ 上传nginx-1.16.1.tar.gz 到&#x2F;usr&#x2F;local&#x2F;tmp中 12cd /usr/local/tmptar zxf nginx-1.16.1.tar.gz 5、修改Nginx配置5.1 进入到Nginx文件夹1cd nginx-1.16.1 5.2 创建临时目录​ 修改配置文件中好多位置都使用了&#x2F;var&#x2F;temp&#x2F;nginx目录，但是默认不会自动创建这个目录，需要手动创建。 1mkdir -p /var/temp/nginx 5.3 修改配置文件参数内容为： 12345678910111213./configure \\--prefix=/usr/local/nginx \\--pid-path=/var/run/nginx/nginx.pid \\--lock-path=/var/lock/nginx.lock \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path=/var/temp/nginx/client \\--http-proxy-temp-path=/var/temp/nginx/proxy \\--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\--http-scgi-temp-path=/var/temp/nginx/scgi \\--add-module=/usr/local/tmp/fastdfs-nginx-module/src ​ –add-module 必须定义，此配置信息是用于指定安装Nginx时需要加载的模块，如果未指定，Nginx安装过程不会加载fastdfs-nginx-module模块，后续功能无法实现。 【报错：执行文件无权限】 先执行以下命令： 1chmod +x configure ​ 再继续执行后续代码 6、编译并安装12makemake install 7、配置fastdfs-nginx-module模块配置文件​ 复制配置文件fastdfs-nginx-module&#x2F;src&#x2F;mod_fastdfs.conf 到 &#x2F;etc&#x2F;fdfs目录中 1cp /usr/local/tmp/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ 8、修改 mod_fastdfs.conf8.1 进入到 &#x2F;etc&#x2F;fdfs1cd /etc/fdfs 8.2 编辑配置文件1vim mod_fastdfs.conf 8.3 文件内容修改​ 需要修改文件中四处内容， 这四处内容的含义： ​ connect_timeout&#x3D;2 #连接超时时间，单位秒 ​ tracker_server&#x3D;tracker:22122 #tracker 服务结点 ​ url_have_group_name&#x3D;false #URL是否包含group名称 ​ store_path0&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs #storage服务结点的存储位置，与配置storage结点一致 ​ 修改为以下内容 1234connect_timeout=10tracker_server=192.168.93.10:22122url_have_group_name=truestore_path0=/usr/local/fastdfs/storage/store 9、提供FastDFS需要的HTTP配置文件​ 复制FastDFS安装包中的两个配置文件(http.conf 和 mine.types) 到 &#x2F;etc&#x2F;fdfs目录中 12cp /usr/local/tmp/FastDFS/conf/http.conf /etc/fdfs/cp /usr/local/tmp/FastDFS/conf/mime.types /etc/fdfs/ 10、创建网络访问存储服务的软连接​ 在上传文件到FastDFS后，FastDFS会返回group1&#x2F;M00&#x2F;00&#x2F;00&#x2F;xxxxxxxxx.xxx其中group1是卷名，在mod_fastdfs.conf配置文件中已配置了url_have_group_name， 以保证URL解析正确。其中的M00是FastDFS保存数据时使用的虚拟目录， 需要将这个虚拟目录定位到真实数据目录上。 1ln -s /usr/local/fastdfs/storage/store/data/ /usr/local/fastdfs/storage/store/data/M00 11、修改nginx配置文件11.1 进入到安装后 nginx目录1cd /usr/local/nginx/conf 11.2 编辑配置文件1vim nginx.conf 11.2.1 修改1​ user root； #Nginx需要访问linux文件系统，必须有文件系统的权限。User root代表nginx文件系统的权限是root用户权限。如果不开启权限，可能有404反问错误。 123user root;worker_processes 1; 11.2.2 修改21234567server&#123; listen 8888; #storage 配置中， 有http.server_port=8888的配置信息，必须一致。配置文件是 /etc/fdfs/storaged.conf server_name localhost; location ~/group([0-9])/M00&#123; ngx_fastdfs_module; &#125;&#125; 12、启动nginx进入到nginx安装目录的sbin文件夹 1cd /usr/local/nginx/sbin/ 启动nginx 1./nginx 关闭nginx 1./nginx -s quit","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"nginx","slug":"nginx","permalink":"https://lyblog2022.github.io/tags/nginx/"}]},{"title":"FastDFS实现图片上传及下载","date":"2022-06-20T05:21:29.000Z","path":"2022/06/20/study/FastDFS/FastDFS-file1/","text":"FastDFS简介及简单实现图片上传及下载 1、分布式文件系统概述1.1 分类1.1.1 通用分布式文件系统​ 和传统的本地文件系统（如ext3、NTFS等）相对应。典型代表：lustre、MooseFS 优点：标准文件系统操作方式，对开发者门槛较低 缺点： 系统复杂性较高，需要支持若干标准的文件操作，如：目录结构、文件读写权限、文件锁等。复杂性更高 系统整体性能有所降低，因为要支持POSIX标准（表示可移植操作系统接口（Portable Operating System Interface of UNIX），POSIX标准定义了操作系统应该为应用程序提供的接口标准） 1.1.2 专用分布式文件系统​ 基于google File System的思想，文件上传后不能修改。需要使用专有API对文件进行访问，也可称作分布式文件存储服务。典型代表：MogileFS、FastDFS、TFS。 优点： 系统复杂性较低，不需要支持若干标准的文件操作，如：目录结构、文件读写权限、文件锁等，系统比较简洁。 系统整体性能较高，因为无需支持POSIX标准，可以省去支持POSIX引入的环节，系统更加高效。 缺点：采用专有API，对开发者门槛较高（直接封装成工具类） 1.2 Google FS 体系结构 两个角色： 名字服务器（索引服务器） 存储服务器 架构特点 不支持文件修改功能。 文件分块存储，需要索引服务器 一个文件可以存储多份，一个文件存储到哪些存储服务器，通常采用动态分配的方式。 2、FastDFS2.1 简介​ FastDFS是一个轻量级的开源分布式文件系统。2008年4月份开始启动。类似google FS的一个轻量级分布式文件系统，纯C实现，支持Linux、FreeBSD、AIX等UNIX系统。 ​ 主要解决了大容量的文件存储和高并发访问的问题，文件存取时实现了负载均衡。实现了软件方式的磁盘阵列（Redundant Arrays of Independent Drives，RAID），可以使用廉价的IDE（Integrated Drive Electronics）硬盘进行存储。并且支持存储服务器在线扩容。支持相同内容的文件只保存一份，节约磁盘空间。 ​ FastDFS只能通过Client API访问，不支持POSIX访问方式。 ​ FastDFS特别适合大中型网站使用，用来存储资源文件（如：图片、文档、音频、视频等等） 2.2 架构 2.2.1 角色 Client：客户端。使用java语言编写的项目属于客户端。 Tracker Server：跟踪服务器，主要做调度工作，在访问上起负载均衡的作用。在内存中记录集群中group和storage server的状态信息，是连接Client和Storage server的枢纽。 Storage Server：存储服务器，文件和文件属性（meta data）都保存到存储服务器上 2.2.2 架构解读​ 只有两个角色，tracker server和storage server，不需要存储文件索引信息。 ​ 所有服务器都是对等的，不存在Master-Slave关系。 ​ 存储服务器采用分组方式，同组内存储服务器上的文件完全相同（RAID 1）。 ​ 不同组的storage server之间不会相互通信。 ​ 由storage server主动向tracker server报告状态信息，tracker server之间不会相互通信。 1、文件上传1.1 时序图 1.2 流程说明 客户端访问Tracker Tracker 返回Storage的ip和端口 客户端直接访问Storage，把文件内容和元数据发送过去。 Storage返回文件存储id。包含了组名和文件名 1.3 Fastdfs-java-client1.3.1 添加依赖123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.bestwu&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ` 1.3.2 编写配置文件​ 文件名：fdfs_client.conf 12345connect_timeout = 10network_timeout = 30charset = UTF-8http.tracker_http_port = 8080tracker_server = 192.168.213.133:22122 1.3.3 导入工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205package com.util;import java.io.ByteArrayInputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import org.apache.commons.lang3.StringUtils;import org.csource.common.NameValuePair;import org.csource.fastdfs.ClientGlobal;import org.csource.fastdfs.StorageClient;import org.csource.fastdfs.StorageClient1;import org.csource.fastdfs.StorageServer;import org.csource.fastdfs.TrackerClient;import org.csource.fastdfs.TrackerServer;/** * FastDFSClient * * @author liuyong * @version 1.0 * @description com.util * @date 2022/6/19 19:40 */public class FastDFSClient &#123; private static final String CONF_FILENAME = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath() + &quot;fdfs_client.conf&quot;; private static StorageClient storageClient = null; /** * 只加载一次. */ static &#123; try &#123; ClientGlobal.init(CONF_FILENAME); TrackerClient trackerClient = new TrackerClient(ClientGlobal.g_tracker_group); TrackerServer trackerServer = trackerClient.getConnection(); StorageServer storageServer = trackerClient.getStoreStorage(trackerServer); storageClient = new StorageClient(trackerServer, storageServer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * * @param inputStream * 上传的文件输入流 * @param fileName * 上传的文件原始名 * @return */ public static String[] uploadFile(InputStream inputStream, String fileName) &#123; try &#123; // 文件的元数据 NameValuePair[] meta_list = new NameValuePair[2]; // 第一组元数据，文件的原始名称 meta_list[0] = new NameValuePair(&quot;file name&quot;, fileName); // 第二组元数据 meta_list[1] = new NameValuePair(&quot;file length&quot;, inputStream.available()+&quot;&quot;); // 准备字节数组 byte[] file_buff = null; if (inputStream != null) &#123; // 查看文件的长度 int len = inputStream.available(); // 创建对应长度的字节数组 file_buff = new byte[len]; // 将输入流中的字节内容，读到字节数组中。 inputStream.read(file_buff); &#125; // 上传文件。参数含义：要上传的文件的内容（使用字节数组传递），上传的文件的类型（扩展名），元数据 String[] fileids = storageClient.upload_file(file_buff, getFileExt(fileName), meta_list); return fileids; &#125; catch (Exception ex) &#123; ex.printStackTrace(); return null; &#125; &#125; /** * * @param file * 文件 * @param fileName * 文件名 * @return 返回Null则为失败 */ public static String[] uploadFile(File file, String fileName) &#123; FileInputStream fis = null; try &#123; NameValuePair[] meta_list = null; // new NameValuePair[0]; fis = new FileInputStream(file); byte[] file_buff = null; if (fis != null) &#123; int len = fis.available(); file_buff = new byte[len]; fis.read(file_buff); &#125; String[] fileids = storageClient.upload_file(file_buff, getFileExt(fileName), meta_list); return fileids; &#125; catch (Exception ex) &#123; return null; &#125;finally&#123; if (fis != null)&#123; try &#123; fis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 根据组名和远程文件名来删除一个文件 * * @param groupName * 例如 &quot;group1&quot; 如果不指定该值，默认为group1 * @param remoteFileName * 例如&quot;M00/00/00/wKgxgk5HbLvfP86RAAAAChd9X1Y736.jpg&quot; * @return 0为成功，非0为失败，具体为错误代码 */ public static int deleteFile(String groupName, String remoteFileName) &#123; try &#123; int result = storageClient.delete_file(groupName == null ? &quot;group1&quot; : groupName, remoteFileName); return result; &#125; catch (Exception ex) &#123; return 0; &#125; &#125; /** * 修改一个已经存在的文件 * * @param oldGroupName * 旧的组名 * @param oldFileName * 旧的文件名 * @param file * 新文件 * @param fileName * 新文件名 * @return 返回空则为失败 */ public static String[] modifyFile(String oldGroupName, String oldFileName, File file, String fileName) &#123; String[] fileids = null; try &#123; // 先上传 fileids = uploadFile(file, fileName); if (fileids == null) &#123; return null; &#125; // 再删除 int delResult = deleteFile(oldGroupName, oldFileName); if (delResult != 0) &#123; return null; &#125; &#125; catch (Exception ex) &#123; return null; &#125; return fileids; &#125; /** * 文件下载 * * @param groupName 卷名 * @param remoteFileName 文件名 * @return 返回一个流 */ public static InputStream downloadFile(String groupName, String remoteFileName) &#123; try &#123; byte[] bytes = storageClient.download_file(groupName, remoteFileName); InputStream inputStream = new ByteArrayInputStream(bytes); return inputStream; &#125; catch (Exception ex) &#123; return null; &#125; &#125; public static NameValuePair[] getMetaDate(String groupName, String remoteFileName)&#123; try&#123; NameValuePair[] nvp = storageClient.get_metadata(groupName, remoteFileName); return nvp; &#125;catch(Exception ex)&#123; ex.printStackTrace(); return null; &#125; &#125; /** * 获取文件后缀名（不带点）. * * @return 如：&quot;jpg&quot; or &quot;&quot;. */ private static String getFileExt(String fileName) &#123; if (StringUtils.isBlank(fileName) || !fileName.contains(&quot;.&quot;)) &#123; return &quot;&quot;; &#125; else &#123; return fileName.substring(fileName.lastIndexOf(&quot;.&quot;) + 1); // 不带最后的点 &#125; &#125;&#125; 1.3.4编写测试代码1234567891011public static void main(String[] args) &#123; try &#123; File file = new File(&quot;E:\\\\note\\\\source\\\\_posts\\\\software\\\\FastDFS\\\\fastdfs.png&quot;); InputStream is = new FileInputStream(file); String fileName = UUID.randomUUID().toString()+&quot;.png&quot;; String[] result = FastDFSClient.uploadFile(is, fileName); System.out.println(Arrays.toString(result)); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; 2、文件下载2.1 时序图 2.2 下载说明 client询问tracker下载文件的storage，参数为文件标识（组名和文件名）； tracker返回一台可用的storage； client直接和storage通讯完成文件下载。 2.3 测试代码直接使用工具方法完成下载。 123456789101112131415161718192021222324252627282930313233package com.down;import com.util.FastDFSClient;import java.io.*;/** * Download * * @author liuyong * @version 1.0 * @description com.down * @date 2022/6/19 20:09 */public class Download &#123; public static void main(String[] args) &#123; try &#123; InputStream is = FastDFSClient.downloadFile(&quot;group1&quot;, &quot;M00/00/00/wKjVhWKvD_iAZ0rRAACDGmk1a_U227.png&quot;); OutputStream os = new FileOutputStream(new File(&quot;E:/jqk.png&quot;)); int index = 0 ; while((index = is.read())!=-1)&#123; os.write(index); &#125; os.flush(); os.close(); is.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;","tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"https://lyblog2022.github.io/tags/FastDFS/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"FastDFS安装","date":"2022-06-19T06:02:05.000Z","path":"2022/06/19/software/FastDFS/","text":"CentOS8安装FastDFS 1、安装FastDFS依赖 FastDFS是C语言开发的应用。安装必须使用 make , cmake 和 gcc编译器。 1yum install -y make cmake gcc gcc-c++ 2、上传并解压libfastcommon-master上传libfastcommon-master 到 &#x2F;usr&#x2F;local&#x2F;tmp下。 libfastcommon是从FastDFS和FastDHT中提取出来的公共C函数库 解压 libfastcommon-master.zip 由于是zip文件所以要使用 unzip命令 12cd /usr/local/tmpunzip libfastcommon-master.zip 3、编译并安装libfastcommon没有提供make命令安装文件。使用的是shell脚本执行编译和安装。shell脚本为 make.sh 进入解压后的文件 1cd libfastcommon-master 编译 1./make.sh 安装 1./make.sh install 有固定的默认安装位置。在&#x2F;usr&#x2F;lib64 和 &#x2F;usr&#x2F;include&#x2F;fastcommon两个目录中 4、创建软连接 因为FastDFS 主程序设置的lib目录是 &#x2F;usr&#x2F;local&#x2F;lib， 所以需要创建软连接 12ln -s /user/lib64/libfastcommon.so /usr/local/lib/libfastcommon.soln -s /usr/local/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so 5、上传并解压FastDFS主程序上传 FastDFS_v5.08.tar.gz 到 &#x2F;usr&#x2F;local&#x2F;tmp下后解压 12cd /usr/local/tmptar zxf FastDFS_v5.08.tar.gz 6、编译并安装FastDFS进入到解压后的FastDFS文件中 1cd FastDFS 编译 1./make.sh 安装 1./make.sh install ​ 安装后 FastDFS主程序所在的位置是 ​ &#x2F;usr&#x2F;bin 可执行文件所在的位置 ​ &#x2F;etc&#x2F;fdfs 配置文件所在的位置 ​ &#x2F;usr&#x2F;bin 主程序代码所在位置 ​ &#x2F;usr&#x2F;include&#x2F;fastdfs 包含一些插件组所在的位置 7、配置tracker7.1 复制配置文件进入到 &#x2F;etc&#x2F;fdfs 中 ， 把tracker配置文件复制一份 12cd /etc/fdfscp tracker.conf.sample tracker.conf 7.2 创建数据目录创建放置 tracker数据的目录 1mkdir -p /usr/local/fastdfs/tracker 7.3 修改配置文件修改 tracker.conf 设置 tracker 内容存储目录 base_path&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;tracker 1vim tracker.conf 7.4 启动服务1service fdfs_trackerd start 启动成功后， 配置文件中 base_path 指向的目录出现 FastDFS服务相关数据目录(data目录， logs 目录) 7.5 查看服务运行状态1service fdfs_trackerd status 如果显示 is running 表示正常运行。 8、配置storage storage可以和tracker不在同一台服务器上。示例中把storage和tracker安装在同一台服务器上了。 8.1 复制配置文件进入到 &#x2F;etc&#x2F;fdfs, 把 storage 配置文件复制一份 12cd /etc/fdfscp storage.conf.sample storage.conf 8.2 创建目录创建两个目录， 把base用于存储基础数据和日志，store用于存储上传数据。 12mkdir -p /usr/local/fastdfs/storage/basemkdir -p /usr/local/fastdfs/storage/store 8.3 修改配置文件​ storage.conf配置文件用于描述存储服务的行为，需要进行下述修改 1vim /etc/fdfs/storage.conf 配置内容如下： 123base_path=/usr/local/fastdfs/storage/basestore_path0=/usr/local/fastdfs/storage/storetracker_server=tracker的服务IP：22122 ​ base_path - 基础路径。用于保存storage server 基础数据内容和日志内容的目录。 ​ store_path0 - 存储路径。是用于保存FastDFS中存储文件的目录，就是要创建256*256个子目录的位置。 ​ base_path 和 store_path0 可以使用同一个目录。 ​ tracker_server - 跟踪服务器位置。就是跟踪服务器的IP和端口。 ​ 启动服务 1service fdfs_storaged start ​ 启动成功后，配置文件中base_path 指向的目录中出现FastDFS服务相关数据目录（data目录、logs目录）配置文件中的store_path0指向的目录中同样出现FastDFS存储相关数据录（data目录）。其中$store_path0&#x2F;data&#x2F;目录中默认创建若干子孙目录（两级目录层级总计256*256个目录），是用于存储具体文件数据的。 ​ Storage 服务器启动比较慢，因为第一次启动的时候，需要创建256*256个目录。 ​ 查看启动状态 1service fdfs_storaged status","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"FastDFS","slug":"FastDFS","permalink":"https://lyblog2022.github.io/tags/FastDFS/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"}]},{"title":"dubbo项目","date":"2022-06-12T02:28:02.000Z","path":"2022/06/12/study/dubbo/dubbo项目/","text":"dubbo简单的小项目 1、原型1.1 部门原型​ 显示全部部门信息 1.2 员工新增 1.3 查看部门员工 2、按照分布式架构进行设计项目​ 设定员工管理和部门管理不在同一个模块中，需要有一个员工管理项目和一个部门管理项目。 ​ 为了方便，不去每个项目使用一个窗口，而是使用聚合项目。 3、创建数据库123456789101112131415create table dept(id int(11) primary key auto_increment,name varchar(20));insert into dept values(default,&#x27;开发部&#x27;);insert into dept values(default,&#x27;产品部&#x27;);create table emp(id int(11) primary key auto_increment,name varchar(20),photo varchar(200),did int(11),CONSTRAINT fk_emp_dept FOREIGN key (did) REFERENCES dept(id));","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"dubbo","slug":"dubbo","permalink":"https://lyblog2022.github.io/tags/dubbo/"},{"name":"项目","slug":"项目","permalink":"https://lyblog2022.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"dubbo学习","date":"2022-06-11T11:51:20.000Z","path":"2022/06/11/study/dubbo/dubbo学习/","text":"dubbo基础学习、架构、支持的协议及注册中心学习，一个简单的Demo项目及负载均衡的简单配置 1、简介​ Apache Dubbo 是一个高可用的，基于Java的开源RPC框架。 ​ Dubbo框架不仅仅是具备RPC访问功能，还包含服务治理功能。 1.1 发展历程​ Dubbo是最开始是阿里巴巴内部使用的RPC框架。 ​ 2011年对外提供。 ​ 2012年停止更新。 ​ 2017年开始继续更新。 ​ 2019年捐献给Apache，由Apache维护2.7以上版本。 1.2 架构 线条：虚线表示异步，实线表示同步。异步不阻塞线程性能高，同步阻塞线程必须等待响应结果才能继续执行，相对性能低。 provider：提供者。编写持久层和事务代码。 container：容器（Spring容器），Dubbo完全基于Spring实现的。 register：注册中心。放置所有Provider对外提供的信息。包含Provider的IP，访问端口，访问遵守的协议，对外提供的接口，接口中有哪些方法等相关信息。 consumer：消费者（RPC调用者，SOA调用服务的项目）开发中也是一个项目，编写service和controller（还可以报页面等）。调用XXXXServiceImpl中的方法。 monitor：监控中心。监控Provider的压力情况等。每隔2分钟Consumer和Provider会把调用次数发送给Monitor，由Monitor进行统计。 执行流程： start：启动Spring容器时会把Provider启动。 register：把Provider相关信息注册到Registry里 subscribe：Consumer从Registry中订阅Provider的信息 notify：通知给Consumer invoke：Consumer根据Registry通知的信息进行调用Provider中方法。 count:Consumer和Provider把调用次数信息异步发送给Monitor进行统计。 2、支持的协议2.1 Dubbo协议（官方推荐）​ 优点： ​ 采用NIO复用单一长连接，并使用线程池并发处理请求，减少握手和加大并发效率，性能较好（推荐使用） ​ 缺点： ​ 大文件上传时,可能出现问题(不使用Dubbo文件上传) 2.2 RMI（Remote Method Invocation）协议​ 优点: ​ JDK自带的能力。 ​ 缺点: ​ 偶尔连接失败 2.3 Hessian协议​ 优点: ​ 可与原生Hessian互操作，基于HTTP协议 ​ 缺点: ​ 需hessian.jar支持，http短连接的开销大 3、支持的注册中心3.1 Zookeeper（官方推荐）​ 优点: ​ 支持分布式.很多周边产品 ​ 缺点: ​ 受限于Zookeeper软件的稳定性.Zookeeper专门分布式辅助软件,稳定较优 3.2 Multicast​ 优点: ​ 去中心化,不需要单独安装软件. ​ 缺点: ​ Provider和Consumer和Registry不能跨机房(路由) 3.3 Redis​ 优点: ​ 支持集群,性能高 ​ 缺点: ​ 要求服务器时间同步.否则可能出现集群失败问题. 3.4 Simple​ 优点: ​ 标准RPC服务.没有兼容问题 ​ 缺点: ​ 不支持集群. 4、项目Demo​ 新建父项目Dubbo ​ pom： 1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.10.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 4.1 创建子项目api创建类DemoService（dubbo） 12345678910111213package com.dubbo.service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 20:55 * @Description: com.dubbo.service * @Version: 1.0 */public interface DemoService &#123; public String demo(String param);&#125; 4.2 创建provider项目1、添加pom依赖 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt; 2、创建实现类 12345678910111213141516171819package com.dubbo.service.Impl;import com.dubbo.service.DemoService;import org.apache.dubbo.config.annotation.Service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:01 * @Description: com.dubbo.service.Impl * @Version: 1.0 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Override public String demo(String param) &#123; System.out.println(&quot;demo 已执行&quot;); return param+&quot;xxxxxxxxxxx&quot;; &#125;&#125; 3、创建application.yml配置 12345dubbo: application: name: dubbo-provider registry: address: zookeeper://192.168.253.132:2181 4.3 创建consume子项目1、添加pom依赖 1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt; 2、创建Service接口(springboot) 12345678910111213package com.service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:07 * @Description: com.service * @Version: 1.0 */public interface DemoService &#123; public String demo();&#125; 3、创建Service接口实现类（springboot） 1234567891011121314151617181920212223242526package com.service.Impl;import com.service.DemoService;import org.apache.dubbo.config.annotation.Reference;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:07 * @Description: com.service.Impl * @Version: 1.0 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Reference private com.dubbo.service.DemoService demoService; @Override public String demo() &#123; return demoService.demo(&quot;张三&quot;); &#125;&#125; 4、创建controller控制了 1234567891011121314151617181920212223242526package com.controller;import com.service.DemoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @Author: liuyong * @Date: 2022 - 06 - 11 - 21:11 * @Description: com.controller * @Version: 1.0 */@RestControllerpublic class DemoController &#123; @Autowired private DemoService demoService; @RequestMapping(&quot;/demo&quot;) public String demo() &#123; return demoService.demo(); &#125;&#125; 5、添加配置文件 12345dubbo: application: name: dubbo-consumer registry: address: zookeeper://192.168.253.132:2181 4.4 运行项目运行顺序：先启动provider，再启动consume 控制台运行结果： dubbo运行结果 4.5 运行异常启动provider和consume报错 解决方案： 添加一下依赖即可： 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-x-discovery --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-x-discovery&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt;&lt;/dependency&gt; 5、搭建admin管理界面使用jar文件 dubbo-admin-0.2.0.jar 将jar文件内配置文件的地址改为本地的zookeeper地址 1234# centers in dubbo2.7admin.registry.address=zookeeper://192.168.253.132:2181admin.config-center=zookeeper://192.168.253.132:2181admin.metadata-report.address=zookeeper://192.168.253.132:2181 使用 java -jar命令运行jar文件 6、负载均衡 集群：一个内容，部署多次，形成的整体称为集群。集群中每个个体应该部署到不同的服务器上。 伪集群：集群中内容部署到同一台服务器上，通过不同端口区分不同个体。 负载均衡是在集群前提下，当访问整个集群时，集群中每个节点被访问次数或频率的规则。 Dubbo 内置了四个负载均衡策略。默认为Random 6.1 内置策略 Random：随机。随机访问集群中节点。访问概率和权重有关。 RoundRobin：轮询。访问频率和权重有关。 权重（weight）：占有比例。集群中每个项目部署的服务器的性能可能是不同，性能好的服务器权重应该高一些。 LeastActive：活跃数相同的随机，不同的活跃数高的放前面。 ConsistentHash：一致性Hash。相同参数请求总是发到一个提供者。 6.2 设置负载均衡6.2.1 @Reference​ 调用的服务采用的负载均衡 12@Reference(loadbalance = &quot;roundrobin&quot;)private DemoService demoService; 6.2.2 @Service​ 当前服务采用的负载均衡算法 12@Service(loadbalance = &quot;random&quot;)public class DemoServiceImpl implements DemoService &#123; ​ 设置权重 1@Service(weight = 4) 6.2.3 配置文件​ 全局设置所有provider和consumer的负载均衡效果 1234567891011dubbo: application: name: dubbo-provider registry: address: zookeeper://192.168.32.128:2181 protocol: port: 20884 provider: loadbalance: random consumer: loadbalance: random","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"dubbo","slug":"dubbo","permalink":"https://lyblog2022.github.io/tags/dubbo/"}]},{"title":"手写rpc框架","date":"2022-06-09T05:01:35.000Z","path":"2022/06/09/study/手写rpc框架/","text":"使用Zookeeper作为注册中心，RMI作为连接技术，手写RPC框架。 1、创建RPCClient项目创建父项目RPCClient 包含三个子项目 pojo: service中需要的实体类 service：包含被serviceimpl和consumer依赖的接口。 serviceimpl:provider提供的服务内容 consumer：消费者，调用服务内容。 2、pojo项目在父项目下新建子项目pojo 该子项目包括一个文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com;import java.io.Serializable;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:04 * @Description: com * @Version: 1.0 */public class User implements Serializable &#123; private Integer id; private String name; public User() &#123; &#125; public User(Integer id, String name) &#123; this.id = id; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 3、service项目添加依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 新建MyService接口，继承Remote类 12345678910111213141516171819package com.service;import com.User;import java.rmi.Remote;import java.rmi.RemoteException;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:06 * @Description: com * @Version: 1.0 */public interface MyService extends Remote &#123; public List&lt;User&gt; findAll() throws RemoteException;&#125; 4、provider项目添加依赖 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 新建ProviderRun类 123456789101112131415161718192021222324252627282930313233343536373839404142package com;import com.service.Impl.MyServiceImpl;import com.service.MyService;import org.apache.zookeeper.*;import java.nio.charset.StandardCharsets;import java.rmi.Naming;import java.rmi.Remote;import java.rmi.registry.LocateRegistry;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:15 * @Description: com * @Version: 1.0 */public class ProviderRun &#123; public static void main(String[] args) &#123; try &#123; MyService service = new MyServiceImpl(); LocateRegistry.createRegistry(8989); String url = &quot;rmi://localhost:8989/myService&quot;; Naming.bind(url, service); System.out.println(&quot;MRI服务启动成功！&quot;); //创建zookeeper并发布信息 ZooKeeper zooKeeper = new ZooKeeper(&quot;192.168.253.132:2181&quot;, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;获取链接&quot;); &#125; &#125;); //运行前确保/rpc目录存在 zooKeeper.create(&quot;/rpc/provider&quot;,url.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(&quot;注册成功&quot;); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 运行项目，打开zookeeper，查看是否写入到&#x2F;rpc&#x2F;provider 5、consume项目添加依赖 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建service接口 123456789101112131415package com.consumer.service;import com.User;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:36 * @Description: com.consumer.service * @Version: 1.0 */public interface PageService &#123; public List&lt;User&gt; show();&#125; 创建其实现类 123456789101112131415161718192021222324252627282930313233343536373839404142package com.consumer.service.Impl;import com.User;import com.consumer.service.PageService;import com.service.MyService;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import org.springframework.stereotype.Service;import java.rmi.Naming;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 21:37 * @Description: com.consumer.service.Impl * @Version: 1.0 */@Servicepublic class PageServiceImpl implements PageService &#123; @Override public List&lt;User&gt; show() &#123; try &#123; ZooKeeper zooKeeper = new ZooKeeper(&quot;192.168.253.132:2181&quot;, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;链接成功&quot;); &#125; &#125;); byte[] bytes = zooKeeper.getData(&quot;/rpc/provider&quot;,false,null); MyService myService = (MyService) Naming.lookup(new String(bytes)); return myService.findAll(); &#125; catch (Exception e)&#123; e.printStackTrace(); return null; &#125; &#125;&#125; 创建控制器 12345678910111213141516171819202122232425262728package com.consumer.controller;import com.User;import com.consumer.service.PageService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;/** * @Author: ly * @Date: 2022 - 06 - 08 - 22:19 * @Description: com.consumer.controller * @Version: 1.0 */@RestControllerpublic class PageController &#123; @Autowired private PageService pageService; @RequestMapping(&quot;/show&quot;) public List&lt;User&gt; show() &#123; return pageService.show(); &#125;&#125; 启动springboot项目，输入localhost:8080&#x2F;show","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"RPC","slug":"RPC","permalink":"https://lyblog2022.github.io/tags/RPC/"}]},{"title":"zookeeper使用","date":"2022-06-07T13:17:08.000Z","path":"2022/06/07/study/zookeeper使用/","text":"zookeeper内容发布及消息订阅 1、向zookeeper中注册内容新建项目ZookeeperClient 1.1 创建&#x2F;demo使用zookeeper的客户端命令工具创建&#x2F;demo 12./zkCli.shcreate /demos 1.2 添加依赖1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1.3 编写代码1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; try &#123; /** * 创建zookeeper对象 * 参数1：zookeeper IP+端口 * 参数2：访问超时设置 * 参数3：链接成功后，编写成功信息 */ String ip = &quot;192.168.253.132:2181&quot;; ZooKeeper zooKeeper = new ZooKeeper(ip, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;获取链接&quot;); &#125; &#125;); /** * 向zookeeper发送内容 * 参数1：发送的文件 * 参数2：发送的内容 * 参数3：权限 * 参数4：内容的模式 */ String content = zooKeeper.create(&quot;/demo/rmi-adress&quot;,&quot;rmi:localhost:8080/demoService&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL); System.out.println(&quot;content=&quot;+content); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; 1.4 控制台输出 1.5 zookeeper输出 1.6 异常 解决方案—-防火墙未关闭 查看防火墙状态 1systemctl status firewalld.service active表示当前防火墙处于开启状态 inactive表示关闭状态systemctl stop firewalld.service （关闭防火墙）systemctl start firewalld.service （开启防火墙）systemctl disable firewalld.service （禁止防火墙自启动）systemctl enable firewalld.service （防火墙随系统开启启动） 关闭防火墙即可 1.7 异常2—6.8新增如果在关闭防火墙后仍出现以上问题 解决方案–用记事本打开C:\\Windows\\System32\\drivers\\etc\\hosts文件，添加ZooKeeper部署的服务器ip，然后保存。 2、zookeeper消息订阅2.1 编写代码12345678910111213141516171819202122232425262728try &#123; /** * 创建zookeeper对象 * 参数1：zookeeper IP+端口 * 参数2：访问超时设置 * 参数3：链接成功后，编写成功信息 */ String ip = &quot;192.168.253.132:2181&quot;; ZooKeeper zooKeeper = new ZooKeeper(ip, 10000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;获取链接&quot;); &#125; &#125;); //从zookeeper中获取内容 //2.1获取节点 List&lt;String&gt; list = zooKeeper.getChildren(&quot;/demo&quot;,false); System.out.println(list); //获取内容 for(String child:list)&#123; byte[] result = zooKeeper.getData(&quot;/demo/&quot;+child,false,null); System.out.println(new String(result)); &#125; &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; 2.2 控制台输出结果","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"zookeeper常用命令","date":"2022-06-07T12:53:54.000Z","path":"2022/06/07/study/zookeeper/","text":"zookeeper常用命令 1、lsls -s&#x2F;path -s 详细信息，替代老版本ls2 -R 当前目录和子目录中内容都罗列出来 例如：ls -R &#x2F; 显示根目录下所有内容 2、createcreate &#x2F;path [data] [data] 包含内容 创建指定路径信息 例如：create &#x2F;demo 创建&#x2F;demo 3、getget [-s] &#x2F;path [-s] 详细信息 查看指定路径下内容。 例如： get -s &#x2F;demo null:存放的数据 cZxid:创建时zxid(znode每次改变时递增的事务id) ctime:创建时间戳 mZxid:最近一次更新的zxid mtime:最近一次更新的时间戳 pZxid:子节点的zxid cversion:子节点更新次数 dataversion:节点数据更新次数 aclVersion:节点ACL(授权信息)的更新次数 ephemeralOwner:如果该节点为ephemeral节点(临时，生命周期与session一样), ephemeralOwner值表示与该节点绑定的session id. 如果该节点不是ephemeral节点, ephemeralOwner值为0. dataLength:节点数据字节数 numChildren:子节点数量 4、setset &#x2F;path data 设置节点内容 5、deletedelete &#x2F;path 删除节点","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"CentOS 8 安装zookeeper","date":"2022-06-06T13:43:24.000Z","path":"2022/06/06/software/zookeeper/","text":"CentOS8安装zookeeper 1、检验java环境1java -version 2、安装wget,供文件下载时使用:1yum install wget 3、下载zookeeper1wget https://downloads.apache.org/zookeeper/zookeeper-3.8.0/apache-zookeeper-3.8.0-bin.tar.gz 4、解压，安装12345cd /usrmkdir zookeepercd ./zookeepertar -zxvf apache-zookeeper-3.8.0-bin.tar.gzmv apache-zookeeper-3.8.0-bin/ /usr/local/soft/ 这块我出现点问题，直接在跟目录下下载的，最好新建一个文件夹 5、创建数据和日志目录1234mkdir -p /data/zookeepermkdir -p /data/zookeeper/datamkdir -p /data/zookeeper/datalogsmkdir -p /data/zookeeper/logs ​ 说明： data:数据目录 datalogs:事务日志 logs:zk应用的日志 6、生成配置文件12cd /usr/local/soft/apache-zookeeper-3.8.0-bin/conf/cp zoo_sample.cfg zoo.cfg 7、设置配置文件1vi zoo.cfg 添加内容 123dataDir=/data/zookeeper/datadataLogDir=/data/zookeeper/datalogsadmin.enableServer=false ​ 说明： admin.enableServer&#x3D;false 用来关闭zk内置的web管理器 dataDir 定义了zk的数据目录 dataLogDir 定义了zk的事务日志 8、配置环境变量1vi /etc/profile 在末尾增加以下内容: 12export ZK_HOME=/usr/local/soft/apache-zookeeper-3.8.0-binexport PATH=$ZK_HOME/bin:$PATH 使环境变量生效: 1source /etc/profile 9、测试启动停止zookeeper12zkServer.sh startzkServer.sh stop","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://lyblog2022.github.io/tags/zookeeper/"}]},{"title":"CentOS 8 配置JDK环境","date":"2022-06-06T13:41:00.000Z","path":"2022/06/06/software/jdk/","text":"CentOS 8 安装 JDK环境 1、使用Yum安装安装OpenJDK的可以选择此方法，方便快捷 1.1 查看是否有JDK环境1java -version 可以看到系统自带的 OpenJDK 版本信息，如果不满足，则卸载现有JDK 1.2 卸载现有JDK使用 rpm 命令查询 java 1rpm -qa | grep java .noarch文件可以不用管，卸载其余条目 执行一下命令卸载信息 1rpm -e --nodeps java-1.8.0-openjdk-1.8.0.201.b09-2.el8.x86_64 1rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.201.b09-2.el8.x86_64 卸载完后查询版本信息 1.3 使用Yum安装OpenJDK1yum install -y java-1.8.0-openjdk 1.3.1 报错 报错信息为： 12Failed to synchronize cache for repo &#x27;AppStream&#x27;, ignoring this repo.Failed to synchronize cache for repo &#x27;BaseOS&#x27;, ignoring this repo. 1.3.2 解决方案切换阿里源 1、备份 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2、下载新的 CentOS-Base.repo 到 &#x2F;etc&#x2F;yum.repos.d&#x2F; 1wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo 3、生成缓存 1yum makecache 1.4 校验 2、使用rpm包安装适用于有提供RPM Package的情况，例如Oracle JDK有提供。 Oracle JDK所有版本下载 OracleJDK8下载","tags":[{"name":"software","slug":"software","permalink":"https://lyblog2022.github.io/tags/software/"},{"name":"CentOS 8","slug":"CentOS-8","permalink":"https://lyblog2022.github.io/tags/CentOS-8/"},{"name":"jdk","slug":"jdk","permalink":"https://lyblog2022.github.io/tags/jdk/"}]},{"title":"RPC-远程服务调用","date":"2022-06-05T08:45:21.000Z","path":"2022/06/05/study/RPC/","text":"RPC–远程服务调用 1、RPC1.1 RFC​ RFC(Request For Comments) 是由互联网工程任务组(IETF)发布的文件集。文件集中每个文件都有自己唯一编号，例如：rfc1831。目前RFC文件由互联网协会(Internet Society，ISOC)赞助发型。 ​ RPC就收集到了rfc 1831中。可以通过下面网址查看： ​ https://datatracker.ietf.org/doc/rfc1831/ 1.2 RPC​ RPC在rfc 1831中收录 ，RPC（Remote Procedure Call） 远程过程调用协议 ​ RPC协议规定允许互联网中一台主机程序调用另一台主机程序，而程序员无需对这个交互过程进行编程。在RPC协议中强调当A程序调用B程序中功能或方法时，A是不知道B中方法具体实现的。 ​ RPC是上层协议，底层可以基于TCP协议，也可以基于HTTP协议。一般我们说RPC都是基于RPC的具体实现，如：Dubbo框架。从广义上讲只要是满足网络中进行通讯调用都统称为RPC，甚至HTTP协议都可以说是RPC的具体实现，但是具体分析看来RPC协议要比HTTP协议更加高效，基于RPC的框架功能更多。 ​ RPC协议是基于分布式架构而出现的，所以RPC在分布式项目中有着得天独厚的优势。 1.3 RPC和HTTP1.3.1 具体实现​ RPC：可以基于TCP协议，也可以基于HTTP协议。 ​ HTTP：基于HTTP协议 1.3.2 效率​ RPC：自定义具体实现可以减少很多无用的报文内容，使得报文体积更小。 ​ HTTP：如果是HTTP 1.1 报文中很多内容都是无用的。如果是HTTP2.0以后和RPC相差不大，比RPC少的可能就是一些服务治理等功能。 1.3.3 链接方式​ RPC：长连接支持。 ​ HTTP：每次连接都是3次握手。 1.3.4 性能​ RPC：可以基于很多序列化方式。如：thrift ​ HTTP：主要是通过JSON，序列化和反序列效率更低。 1.3.5 注册中心​ RPC ：一般RPC框架都带有注册中心。 ​ HTTP：都是直连。 1.3.6 负载均衡​ RPC：绝大多数RPC框架都带有负载均衡测量。 ​ HTTP：一般都需要借助第三方工具。如：nginx 1.3.7 综合结论​ RPC框架：一般都带有丰富的服务治理等功能，更适合企业内部接口调用。 ​ HTTP：更适合多平台之间相互调用。 2、HttpClient实现RPC2.1 HttpClient简介​ 在JDK中java.net包下提供了用户HTTP访问的基本功能，但是它缺少灵活性或许多应用所需要的功能。 ​ HttpClient起初是Apache Jakarta Common 的子项目。用来提供高效的、最新的、功能丰富的支持 HTTP 协议的客户端编程工具包，并且它支持 HTTP 协议最新的版本。2007年成为顶级项目。 ​ 通俗解释：HttpClient可以实现使用Java代码完成标准HTTP请求及响应。 2.2 代码实现2.2.1 服务端1、新建控制器 com.controller.DemoController 12345678@Controllerpublic class DemoController &#123; @RequestMapping(&quot;/demo&quot;) @ResponseBody public String demo(String param)&#123; return &quot;demo&quot;+param; &#125;&#125; 2、启动器 com.HttpClientServerApplication 123456@SpringBootApplicationpublic class HttpClientServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HttpClientServerApplication.class,args); &#125;&#125; 2.2.2 客户端1、添加依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.10&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、新建类 新建com.HttpClientDemo，编写主方法。 ​ 1、使用Get方法访问 123456789101112131415161718192021222324public static void main(String[] args) &#123; try &#123; //创建http工具（理解成:浏览器） 发起请求，解析响应 CloseableHttpClient httpClient = HttpClients.createDefault(); //请求路径 URIBuilder uriBuilder = new URIBuilder(&quot;http://localhost:8080/demo&quot;); uriBuilder.addParameter(&quot;param&quot;, &quot;get123&quot;); //创建HttpGet请求对象 HttpGet get = new HttpGet(uriBuilder.build()); //创建响应对象 CloseableHttpResponse response = httpClient.execute(get); //由于响应体是字符串，因此把HttpEntity类型转换为字符串类型，并设置字符编码 String result = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); //输出结果 System.out.println(result); //释放资源 response.close(); httpClient.close(); &#125; catch (URISyntaxException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; ​ 2、使用Post方式访问 12345678910111213141516171819202122232425262728public class HttpClientDemo &#123; public static void main(String[] args) &#123; try &#123; //创建http工具（理解成:浏览器） 发起请求，解析响应 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建HttpPOST请求对象 HttpPost post = new HttpPost(&quot;http://localhost:8080/demo&quot;); //所有请求参数 List&lt;NameValuePair&gt; params = new ArrayList&lt;&gt;(); params.add(new BasicNameValuePair(&quot;param&quot;,&quot;123&quot;)); //创建HttpEntity接口的文本实现类的对象，放入参数并设置编码 HttpEntity httpEntity = new UrlEncodedFormEntity(params,&quot;utf-8&quot;); //放入到HttpPost对象中 post.setEntity(httpEntity); //创建响应对象 CloseableHttpResponse response = httpClient.execute(post); //由于响应体是字符串，因此把HttpEntity类型转换为字符串类型 String result = EntityUtils.toString(response.getEntity()); //输出结果 System.out.println(result); //释放资源 response.close(); httpClient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3 Jackson用法2.3.1 对象 –&gt; json字符串123ObjectMapper objectMapper = new ObjectMapper();People peo = new People();objectMapper.writeValueAsString(peo); 2.3.2 json –&gt; 对象12ObjectMapper objectMapper = new ObjectMapper();People peo = objectMapper.readValue(content, People.class); 2.3.3 json –&gt; List集合123ObjectMapper objectMapper = new ObjectMapper();JavaType javaType = objectMapper.getTypeFactory().constructParametricType(List.class, People.class);List&lt;People&gt; list = objectMapper.readValue(content, javaType); 2.4 HttpClient请求包含JSON12345678910111213141516171819public class HttpClientDemo &#123; public static void main(String[] args) &#123; try &#123; CloseableHttpClient httpClient = HttpClients.createDefault(); HttpPost post = new HttpPost(&quot;http://localhost:8080/demo&quot;); HttpEntity httpEntity= null;String json = &quot;&#123;&#125;&quot;; StringEntity entity = new StringEntity(json, ContentType.APPLICATION_JSON); post.setEntity(entity); CloseableHttpResponse response = httpClient.execute(post); String result = EntityUtils.toString(response.getEntity()); System.out.println(result); response.close(); httpClient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.5 控制器接口参数@RequestBody把请求体中流数据转换为指定的对象。多用在请求参数是json数据且请求的Content-Type&#x3D;”application&#x2F;json” 123456@RequestMapping(&quot;/demo4&quot;)@ResponseBodypublic String demo4(@RequestBody List&lt;People&gt; list) &#123; System.out.println(list); return list.toString();&#125; 2.6 Ajax发送json参数写法1234567891011121314var json = &#x27;[&#123;&quot;id&quot;:123,&quot;name&quot;:&quot;ly&quot;&#125;,&#123;&quot;id&quot;:123,&quot;name&quot;:&quot;ly123&quot;&#125;]&#x27;; $.ajax(&#123; url:&#x27;/demo5&#x27;, type:&#x27;post&#x27;, success:function(data)&#123; alert(data); for(var i = 0 ;i&lt;data.length;i++)&#123; alert(data[i].id +&quot; &quot;+data[i].name); &#125; &#125;, contentType:&#x27;application/json&#x27;,//请求体中内容类型 dataType:&#x27;json&#x27;,//响应内容类型。 data:json &#125;); 2.7 跨域跨域：协议、IP、端口中只要有一个不同的就是跨域请求 同源策略：浏览器默认只允许ajax访问同源（协议、IP、端口）内容 解决同源策略：在控制器接口上添加@CrossOrigin。表示允许跨域。本质在响应头中添加Access-Control-Allow-Origin: * 123456789101112131415var json = &#x27;[&#123;&quot;id&quot;:123,&quot;name&quot;:&quot;ly&quot;&#125;,&#123;&quot;id&quot;:456,&quot;name&quot;:&quot;ly1234&quot;&#125;]&#x27;; $.ajax(&#123; url:&#x27;/demo5&#x27;, type:&#x27;post&#x27;, success:function(data)&#123; alert(data); for(var i = 0 ;i&lt;data.length;i++)&#123; alert(data[i].id +&quot; &quot;+data[i].name); &#125; &#125;, contentType:&#x27;application/json&#x27;,//请求体中内容类型 dataType:&#x27;json&#x27;,//响应内容类型。 data:json &#125;); 3、RMI实现RPC3.1 RMI简介 RMI(Remote Method Invocation) 远程方法调用。 RMI是从JDK1.2推出的功能，它可以实现在一个Java应用中可以像调用本地方法一样调用另一个服务器中Java应用（JVM）中的内容。 RMI 是Java语言的远程调用，无法实现跨语言。 3.2 执行流程 ​ Registry(注册表)是放置所有服务器对象的命名空间。 每次服务端创建一个对象时，它都会使用bind()或rebind()方法注册该对象。 这些是使用称为绑定名称的唯一名称注册的。 ​ 要调用远程对象，客户端需要该对象的引用。即通过服务端绑定的名称从注册表中获取对象(lookup()方法)。 3.3 API3.3.1 Remotejava.rmi.Remote 定义了此接口为远程调用接口。如果接口被外部调用，需要继承此接口。 3.3.2 RemoteException​ java.rmi.RemoteException ​ 继承了Remote接口的接口中，如果方法是允许被远程调用的，需要抛出此异常。 3.3.3 UnicastRemoteObject​ java.rmi.server.UnicastRemoteObject ​ 此类实现了Remote接口和Serializable接口。 ​ 自定义接口实现类除了实现自定义接口还需要继承此类。 3.3.4 LocateRegistry​ java.rmi.registry.LocateRegistry ​ 可以通过LocateRegistry在本机上创建Registry，通过特定的端口就可以访问这个Registry。 3.3.5 Naming​ java.rmi.Naming ​ Naming定义了发布内容可访问RMI名称。也是通过Naming获取到指定的远程方法。 3.4 代码实现3.4.1 服务端1、编写接口 com.service.DemoService 编写 123public interface DemoService extends Remote &#123; String demo(String demo) throws RemoteException;&#125; 2、编写实现类 com.service.impl.DemoServiceImpl 编写。 注意：构造方法是public的。默认生成protected 12345678public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123; public DemoServiceImpl() throws RemoteException &#123; &#125; @Override public String demo(String demo) throws RemoteException &#123; return demo+&quot;123&quot;; &#125;&#125; 3、主方法 编写com.DemoServer类，生成主方法 12345678public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123; public DemoServiceImpl() throws RemoteException &#123; &#125; @Override public String demo(String demo) throws RemoteException &#123; return demo+&quot;123&quot;; &#125;&#125; 4、运行项目 运行后项目，项目一直处于启动状态，表示可以远程访问此项目中的远程方法。 3.4.2 创建客户端代码1、复制服务端接口 把服务端com.service.DemoService粘贴到项目中 2、创建主方法 新建com.DemoClient 12345678public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123; public DemoServiceImpl() throws RemoteException &#123; &#125; @Override public String demo(String demo) throws RemoteException &#123; return demo+&quot;123&quot;; &#125;&#125;","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"RPC","slug":"RPC","permalink":"https://lyblog2022.github.io/tags/RPC/"}]},{"title":"SpringBoot","date":"2022-06-05T07:02:13.000Z","path":"2022/06/05/study/SpringBoot/","text":"SpringBoot学习1 1、SpringBoot 1.1 简介 Spring Boot是Spring公司的一个顶级项目，和Spring Framework是一个级别的。 Spring Boot实际上是利用Spring Framework 4 自动配置特性完成。编写项目时不需要编写xml文件。发展到现在，Spring Boot已经具有很很大的生态圈，各种主流技术已经都提供了Spring Boot的启动器。 1.2 启动器​ Spring框架在项目中作用是Spring整合各种其他技术，让其他技术使用更加方便。Spring Boot的启动器实际上就是一个依赖。这个依赖中包含了整个这个技术的相关jar包，还包含了这个技术的自动配置，以前绝大多数XML配置都不需要配置了。当然了，启动器中自动配置无法实现所有内容的自动配置，在使用Spring Boot时还需要进行少量的配置（这个配置不是在xml中了，而是在properties或yml中即可）。如果是Spring自己封装的启动器的artifact id名字满足：spring-boot-starter-xxxx，如果是第三方公司提供的启动满足：xxxx-spring-boot-starter。以后每次使用Spring Boot整合其他技术时首先需要考虑导入启动器。 1.3 优点 使用Spring Boot可以创建独立的Spring应用程序 在Spring Boot中直接嵌入了Tomcat、Jetty、Undertow等Web 容器，在使用SpringBoot做Web开发时不需要部署WAR文件 通过提供自己的启动器(Starter)依赖，简化项目构建配置 尽量的自动配置Spring和第三方库 绝对没有代码生成，也不需要XML配置文件 1.4 核心起步依赖- 起步依赖本质上是一个Maven项目对象模型（Project Object Model，POM），定义了对其他库的传递依赖，这些东西加在一起即支持某项功能。 简单的说，起步依赖就是将具备某种功能的坐标打包到一起，并提供一些默认的功能。 自动配置 -Spring Boot的自动配置是一个运行时（更准确地说，是应用程序启动时）的过程，考虑了众多因素，才决定 Spring配置应该用哪个，不该用哪个。该过程是Spring自动完成的。","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"springboot","slug":"springboot","permalink":"https://lyblog2022.github.io/tags/springboot/"}]},{"title":"SpringMVC","date":"2022-06-05T04:55:50.000Z","path":"2022/06/05/study/SpringMVC/","text":"Springmvc学习 1、SpringMVC1.1 概念 SpringMVC是spring为展现层提供的基于MVC设计理念的优秀WEB框架，是目前最主流的MVC框架之一 SpringMVC通过一套注解，可以让普通的JAVA类成为contrllor控制器，无需继承Servlet，实现了控制层和Servlet之间的解耦 SpringMVC支持Rest风格的URL写法 SpringMVC采用了松耦合，可热插的主键结构，比其他的框架更具扩展性和灵活性 1.2 执行流程 DispatcherServlet：前端控制器 用户请求到达前端控制器，它就相当于 mvc 模式中的 c，dispatcherServlet 是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet 的存在降低了组件之间的耦合性。 HandlerMapping：处理器映射器 HandlerMapping 负责根据用户请求找到 Handler 即处理器，SpringMVC 提供了不同的映射器实现不同的 映射方式，例如：配置文件方式，实现接口方式，注解方式等。 HandlerMapping的实现类的作用：实现类RequestMappingHandlerMapping，它会处理@RequestMapping 注解，并将其注册到请求映射表中。 Handler：处理器 (自己定义的Controller处理单元) 它就是我们开发中要编写的具体业务控制器。由 DispatcherServlet 把用户请求转发到 Handler。由 Handler 对具体的用户请求进行处理。 HandlAdapter：处理器适配器 通过 HandlerAdapter 对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行 HandlerAdapter的实现类的作用：实现类RequestMappingHandlerAdapter，则是处理请求的适配器，确定调用哪个类的哪个方法，并且构造方法参数，返回值。 View Resolver：视图解析器 View Resolver 负责将处理结果生成 View 视图，View Resolver 首先根据逻辑视图名解析成物理视图名 即具体的页面地址，再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户。 View：视图 SpringMVC 框架提供了很多的 View 视图类型的支持，包括：jstlView、freemarkerView、pdfView等。我们最常用的视图就是 jsp。 一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开 发具体的页面。 2、 获取请求参数2.1 紧耦合方式​ DispatcherServlet中的service方法直接将此次请求的request对象传递给调用的单元方法即可。同时在单元方法上声明形参HttpServletRequest来接收request实参即可。 2.2 解耦合方式​ DispatcherServlet在其service方法中将请求数据根据需求从request对象中获取出来后，将数据直接传递给对应的单元方法使用。同时在单元方法上直接声明对应的形参接收请求数据即可。在单元方法上声明形参来接收请求数据时，形参名必须和请求数据的键名一致，DispatcherServlet会将调用单元方法的形参名作为请求数据的键名获取请求数据，然后传递给单元方法。 2.3 常见注解2.3.1 @RequestMapping 作用：用于建立请求 URL 和处理请求方法之间的对应关系 出现位置： 类上：请求 URL 的第一级访问目录。此处不写的话，就相当于应用的根目录。写的话需要以&#x2F;开头 方法上：请求 URL 的第二级访问目录 属性： value：用于指定请求的 URL。它和 path 属性的作用是一样的。 method：用于指定请求的方式。 2.3.2 @RequestParam 作用：把请求中指定名称的参数给控制器中的形参赋值。 属性： value：请求参数中的名称。 required：请求参数中是否必须提供此参数。默认值：true。表示必须提供，如果不提供将报错。 12345@RequestMapping(&quot;/getRequestParam&quot;) public String getRequestParam(@RequestParam(&quot;name&quot;) String uname, @RequestParam(value=&quot;age&quot;, required=false) Integer age) &#123; System.out.println(username+&quot;,&quot;+age); return &quot;success&quot;; &#125; 2.3.3 @PathVariable 作用：用于绑定 url 中的占位符。例如：请求 url 中 &#x2F;delete&#x2F;**{id}，这个{id}**就是 url 占位符。 url 支持占位符是 spring3.0 之后加入的。是 springmvc 支持 rest 风格 URL 的一个重要标志。 属性： value：用于指定 url 中占位符名称。 required：是否必须提供占位符。 12345678910@Controllerpublic class PathController &#123; @RequestMapping(&quot;/testPathVariable/&#123;id&#125;/&#123;username&#125;&quot;) public String testPathVariable( @PathVariable(&quot;id&quot;) Integer id, @PathVariable(&quot;username&quot;) String username) &#123; System.out.println(&quot;id:&quot;+id); System.out.println(&quot;username:&quot;+username); System.out.println(&quot;testPathVariable1&quot;); return &quot;success&quot;; &#125;&#125; 3、作用域传参3.1 PageContext对象 作用域范围：当前jsp页面内有效 3.2 request对象 作用域范围：一次请求内。 作用: 解决了一次请求内的资源的数据共享问题 3.3 session对象 作用域范围：一次会话内有效。 说明：浏览器不关闭，并且后台的session不失效，在任意请求中都可以获取到同一个session对象。 作用：解决了一个用户不同请求的数据共享问题。 3.4 application(ServletContext)对象 作用域范围：整个项目内有效。 特点：一个项目只有一个，在服务器启动的时候即完成初始化创建无论如何获取都是同一个项目。 作用：解决了不同用户的数据共享问题。 4、拦截器Spring MVC中的拦截器（Interceptor）类似于Servlet中的过滤器（Filter），它主要用于拦截用户请求并作相应的处理。例如通过拦截器可以进行权限验证、记录请求信息的日志、判断用户是否登录等。 要使用Spring MVC中的拦截器，就需要对拦截器类进行定义和配置。通常拦截器类可以通过两种方式来定义。 通过实现HandlerInterceptor接口，或继承HandlerInterceptor接口的实现类（如HandlerInterceptorAdapter）来定义。 通过实现WebRequestInterceptor接口，或继承WebRequestInterceptor接口的实现类来定义。 4.1 拦截器过滤器区别 拦截器SpringMVC的，而过滤器是servlet的。 拦截器不依赖与servlet容器，由spring容器初始化，过滤器依赖与servlet容器，由servlet容器初始化。 拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。 拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。 在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。 拦截器可以获取IOC容器中的各个bean，而过滤器就不太方便，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。 4.2 preHandle方法 执行时机：再进入控制单元方法之前执行 调用：按拦截器定义顺序调用 具体作用：如果程序员决定该拦截器对请求进行拦截处理后还要调用其他的拦截器，或者是业务处理器去 进行处理，则返回 true。 如果程序员决定不需要再调用其他的组件去处理请求，则返回 false。 参数： HttpServletRequest arg0，拦截的请求的request对象 HttpServletResponse arg1，拦截的请求的response对象 Object arg2 封存了单元方法对象的HandleMethod对象 123456789101112131415161718192021222324/** * * @param request 请求对象 * @param response 响应对象 * @param handler 目标要调用的Handler * @return 返回true放行,返回false拦截 * @throws Exception*/public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; /*在请求到达我们定义的handler之前工作的*/ System.out.println(&quot;MyInterceptor preHandle&quot;); /*设置请求和响应的乱码 */ /* request.setCharacterEncoding(&quot;UTF-8&quot;); response.setCharacterEncoding(&quot;UTF-8&quot;);*/ // 判断是否登录 /*User user =(User) request.getSession().getAttribute(&quot;user&quot;); if(null == user) response.sendRedirect(&quot;index.jsp&quot;); return false;*/ // 用户权限控制 return true;&#125; 4.3 postHandle方法 执行时机：在进行数据处理和做出响应之间进行这个方法的调用 调用：在拦截器链内所有拦截器返成功调用 作用：在业务处理器处理完请求后，但是 DispatcherServlet 向客户端返回响应前被调用，在该方法中对用户请求 request域数据进行处理。 参数： HttpServletRequest arg0，拦截的请求的request对象 HttpServletResponse arg1，拦截的请求的response对象 Object arg2，封存了单元方法对象的HandleMethod对象 ModelAndView arg3，封存了单元方法的返回值资源路径和请求转到的Map数据 12345678910111213141516171819/** * * @param request * @param response * @param handler * @param modelAndView controller响应的结果,视图和数据 * @throws Exception */public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;MyInterceptor postHandle&quot;); /*控制数据*/ /*Map&lt;String, Object&gt; map = modelAndView.getModel(); String msg = (String)map.get(&quot;msg&quot;); String newMsg = msg.replaceAll(&quot;脏话&quot;, &quot;**&quot;); map.put(&quot;msg&quot;, newMsg);*/ /*控制视图*/ /*modelAndView.setViewName(&quot;/testDemo1.jsp&quot;);*/&#125; 4.4 afterCompletion方法 执行时机：在进行页面渲染的时候执行 调用：按拦截器定义逆序调用 作用：在DispatcherServlet 完全处理完请求后被调用,可以在该方法中进行一些资源清理的操作。 参数： HttpServletRequest arg0，拦截的请求的request对象 HttpServletResponse arg1，拦截的请求的response对象 Object arg2，封存了单元方法对象的HandleMethod对象 Exception arg3，存储了责任链的异常信息 1234567891011121314/** * 无论controller是否出现异常,都会执行的方法 * 一般来说都做一些资源释放工作 * @param request * @param response * @param handler * @param ex * @throws Exception */public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; /*页面渲染完毕,但是还没有给浏览器响应数据的时候*/ System.out.println(&quot;MyInterceptor afterCompletion&quot;); System.out.println(ex);&#125; 5、其他注解5.1 @PostMapping 作用：指定当前发送请求的方式只可以是post请求 属性：和@RequestMapping中属性一致 5.2 @GetMapping 作用：指定当前发送请求的方式只可以是get请求 属性：和@RequestMapping中属性一致 5.3 @JsonFormat 作用：处理响应json 数据的处理 属性： pattern ：指定响应时间日期的格式 Timezone：指定响应的时区，否则会有8个小时的时间差 5.4 @RequestBody 作用：用于获取请求体json格式的字符串内容。直接使用得到是 key=value&amp;key=value结构的数据，get 请求方式不适用。 属性：required：是否必须有请求体。默认值是:true。当取值为 true 时，get 请求方式会报错。如果取值 为 false，get 请求得到是null。 5.5 @CrossOrigin​ 跨域：出于浏览器的同源策略限制。同源策略（SameOriginPolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port） 作用：解决ajax请求之间的跨域问题 属性： origins：允许可访问的域列表IP maxAge：准备响应前的缓存持续的最大时间（以秒为单位）。 1234567@CrossOrigin(origins = &quot;http://domain2.com&quot;, maxAge = 3600)@RestController@RequestMapping(&quot;/account&quot;)public class AccountController &#123; @GetMapping(&quot;/&#123;id&#125;&quot;) public Account receive(@PathVariable Long id) &#123; &#125;&#125;","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"Springmvc","slug":"Springmvc","permalink":"https://lyblog2022.github.io/tags/Springmvc/"}]},{"title":"Spring","date":"2022-06-04T08:59:55.000Z","path":"2022/06/04/study/Spring/","text":"Spring学习 1、Spring框架1.1 Spring框架​ Spring框架是由于软件开发的复杂性而创建的。Spring使用的是基本的JavaBean来完成以前只可能由EJB完成的事情。然而，Spring的用途不仅仅限于服务器端的开发。从简单性、可测试性和松耦合性角度而言，绝大部分Java应用都可以从Spring中受益。 ​ —-百度百科 目的：解决企业应用开发的复杂性 功能：使用基本的JavaBean代替EJB，并提供更对的企业应用功能 范围：任何Java应用 ​ Spring是分层的全栈式的轻量级开发框架，以IOC和AOP为核心 1.2 优点 方便解耦，简化开发 Spring通过容器，将对象的创建从代码中剥离出来，交给Spring控制，避免直接编码造成模块之间的耦合度高，用户也不必自己编码处理对象的单例和多例控制，主要关注接口功能即可，不用关注具体使用哪个实现类和实现细节问题 AOP切面编程 AOP切面编程是程序设计的一种概念，Spring对该概念实现的比较好，通过切面编程我们可以在不修改原有代码的情况下实现功能的增加，通常用于事务控制、日志记录、性能检测、权限控制等等 声明式事务 事务的控制可以托管给Spring，我们通过注解或者配置文件声明事务的处理方式即可，不用我们自己去编码处理 整合JUNIT，方便测试 spring整合JUNIT单元测试，对于项目的功能都可以进行轻松快速的测试，便于我们调试程序 方便整合各种优秀的框架 丰富的功能封装 spring对JAVAEE(JDBC ，JAVAMail)都进行了一系列的封装，简化我们对于API的使用，提高程序的开发效率 规范的源码学习样本 spring的源码设计巧妙，结构清晰，大量使用了设计模式，是java代码规范编写的典范 2、Spring模块 2.1 Data Access/Integration（数据访问／集成）数据访问&#x2F;集成层包括 JDBC、ORM、OXM、JMS 和 Transactions 模块 JDBC 模块：提供了一个 JDBC 的抽象层，大幅度减少了在开发过程中对数据库操作的编码。 ORM 模块：对流行的对象关系映射 API，包括 JPA、JDO、Hibernate和 iBatis 提供了的集成层。 OXM 模块：提供了一个支持对象XML 映射的抽象层实现，如 JAXB、Castor、XMLBeans、JiBX 和 XStream。 JMS 模块：指JAVA消息服务，包含的功能为生产和消费的信息。 Transactions 事务模块：支持编程和声明式事务管理实现特殊接口类，并为所有的 POJO。 2.2 Web 模块Spring 的 Web 层包括 Web、Servlet、Struts 和 Portlet 组件 Web 模块：提供了基本的 Web 开发集成特性，例如多文件上传功能、使用的 Servlet 监听器的 IoC 容器初始化以及 Web 应用上下文。 Servlet模块：包括 Spring 模型—视图—控制器（MVC）实现 Web应用程序。 Struts 模块：包含支持类内的 Spring 应用程序，集成了经典的 Struts Web 层。 Portlet 模块：提供了在 Portlet 环境中使用 MVC实现，类似 Web-Servlet 模块的功能。 2.3 Core Container（核心容器）Spring 的核心容器是其他模块建立的基础，由 Beans 模块、Core 核心模块、Context 上下文模块和 Expression Language 表达式语言模块组成 Beans 模块：提供了 BeanFactory，是工厂模式的经典实现，Spring 将管理对象称为 Bean。 Core 核心模块：提供了 Spring 框架的基本组成部分，包括 IoC 和 DI 功能。 Context 上下文模块：建立在核心和 Beans 模块的基础之上，它是访问定义和配置任何对象的媒介。ApplicationContext 接口是上下文模块的焦点。 Expression Language 模块：是运行时查询和操作对象图的强大的表达式语言。 2.4 其他模块Spring的其他模块还有 AOP、Aspects、Instrumentation 以及 Test 模块 AOP 模块：提供了面向切面编程实现，允许定义方法拦截器和切入点，将代码按照功能进行分离，以降低耦合性。 Aspects 模块：提供与 AspectJ 的集成，是一个功能强大且成熟的面向切面编程（AOP）框架。 Instrumentation 模块：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用。 Test 模块：支持 Spring 组件，使用 JUnit 或 TestNG 框架的测试。 3、Spring_IOC3.1 控制反转​ 控制反转（Inversion of Control，缩写为IoC），是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫依赖查找（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。–【百度】 ​ 简单来说，创建对象的权利，或者是控制的位置，由Java代码转移到Spring容器，由Spring的容器控制对象的创建，就是控制反转，Spring创建对象时，会读取配置文件中的信息，然后使用反射创建好的对象之后在容器中存储起来，当需要某个对象时，通过id获取对象即可，不需要自己去new 3.2 原理分析3.2.1 XML解析1&lt;bean id=&quot;stuDao&quot; class=&quot;com.dao.impl.StuDaoImpl&quot;&gt;&lt;/bean&gt; ​ 将上面的信息读取进入程序 对象的ID ,一个是对象的类的全路径名 3.2.2 反射123456//获得类的字节码Class clazz =Class.forName(&quot;com.dao.impl.StuDaoImpl&quot;);//通过字节码实例化对象Object obj = clazz.newInstance(); //将对象放到一个map集合中map.put(&quot;empDao&quot;,obj) 3.2.3 工厂模式1234public Object getBean(String name)&#123; Object obj =map.get(name); return obj; &#125; IOC接口 BeanFactory 接口：IOC容器基本功能接口，是spring内部使用的接口，我们在处理业务时一般不直接使用该接口 ApplicationContext 接口：BeanFactory的子接口，提供更多更强大的功能，研发人员一般使用的接口 4、Spring_XML方式实现DIspring中的Bean的管理: Bean(汉译咖啡豆)，又称JAVABean，其实就是JAVA程序程序中的一个个对象，所以Bean的管理其实就是spring对于JAVA程序中的对象的管理 管理的内容 对象的创建（IOC）：控制反转，就是Spring给我们创建对象，然后我们直接用，不用自己NEW 属性的赋值（DI）：依赖注入，即创建属性时给对象属性赋值，对象功能的实现往往要依赖属性的值，由于对象属性不仅仅是基本数据类型，还可能是其他类或者引用类型，那么依赖注入将会把更多的对象之间的关系整理到一起，可以形成一个庞大的依赖关系，DI处理的是对象的属性赋值和互相依赖的关系 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!--通过无参构造方法构造对象--&gt;&lt;bean id=&quot;user1&quot; class=&quot;com.bean.User&quot; name=&quot;user1&quot; scope=&quot;prototype&quot; lazy-init=&quot;true&quot;&gt;&lt;/bean&gt;&lt;!--id:对象的idclass:类的全路径名name:和id类似,一般不用scope：控制对象单例多例和使用范围 singleton：作用域(scope 默认值), Spring IOC容器中只会存在一个共享的bean实例 prototype：作用域部署的bean，每一次获取都会产生一个新的bean实例，相当与一个new的操作 request：表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效 session：作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效 global session：作用域类似于标准的HTTP Session作用域，不过它仅仅在基于portlet的web应用中才有意义lazy-init：懒加载 调用getBean的时候再去实例化对象--&gt;&lt;!--通过set方法给对象属性赋值--&gt;&lt;bean id=&quot;user1&quot; class=&quot;com.bean.User&quot;&gt; &lt;property name=&quot;userid&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;username&quot; value=&quot;张三&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;abcdefg&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--通过有参构造给对象属性赋值--&gt;&lt;bean id=&quot;user2&quot; class=&quot;com.bean.User&quot;&gt; &lt;constructor-arg name=&quot;userid&quot; value=&quot;2&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;username&quot; value=&quot;小明&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;password&quot; value=&quot;123456789&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;!--特殊符号--&gt;&lt;bean id=&quot;user1&quot; class=&quot;com.bean.User&quot;&gt; &lt;!--null值--&gt; &lt;property name=&quot;userid&quot;&gt; &lt;null&gt;&lt;/null&gt; &lt;/property&gt; &lt;!--特殊符号 转译字符 &lt; &amp;lt; &gt;&amp;gt; &amp; &amp;amp; --&gt; &lt;property name=&quot;username&quot; value=&quot;&amp;amp;xiaoming&amp;lt;&amp;gt;&quot;&gt;&lt;/property&gt; &lt;!-- 特殊符号 &lt;![CDATA[内容]]&gt; --&gt; &lt;property name=&quot;password&quot;&gt; &lt;value&gt;&lt;![CDATA[&amp;&lt;123456&gt;]]&gt;&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 5、Spring_Bean生命周期 通过构造器创建bean实例&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 执行构造器 为bean属性赋值&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 执行set方法 初始化bean&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 调用bean的初始化方法,需要配置指定调用的方法 bean的获取&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 容器对象 getBean方法 容器关闭销毁bean&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 调用销毁方法,需要配置指定调用的方法 6、Spring注解方式管理Bean6.1 注解方式创建对象IOC @Component：放在类上,用于标记，告诉spring当前类需要由容器实例化bean并放入容器中 @Controller：@Component子注解，用于实例化controller层bean @Service：@Component子注解，用于实例化service层bean @Repository：@Component子注解，用于实例化持久层bean 6.2 注解方式依赖注入DI @Autowired：根据属性数据类型自动装配 @Qualifier：根据属性名称注入依赖 @Resources：可以根据类型,也可以根据名称注入 @Value：注入普通数据类型(8+String) 7、Spring代理7.1 代理模式通过代理对象访问目标对象，可以在目标对象基础上增强额外的功能，如添加权限、访问控制等 7.2 静态代理​ 静态代理中代理类与被代理类都需要实现同一个接口，即一个静态代理类只能代理一个类，并且需要知道要代理哪个类才能编写代理类代码，如果有其他类想要使用代理类，就必须再写一个 ​ 在实际开发中是可能有非常多的类需要被代理，并且可能并不知道要代理哪个类，所以继续使用静态代理反而会增加更多的工作量，且效率低下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.test;/*** @Author: Ly* @Description: */public class Test1 &#123; public static void main(String[] args) &#123; Person person =new Person(&quot;张三&quot;); Court court=new Lawyer(person); court.doCourt(); &#125;&#125;// 接口interface Court&#123; void doCourt();&#125;// 代理类class Lawyer implements Court&#123; private Person person; public Lawyer(Person person) &#123; this.person = person; &#125; @Override public void doCourt() &#123; System.out.println(&quot;律师取证:视频证明张三当时正在旅游,不在案发现场&quot;); System.out.println(&quot;律师总结:张三不可能去杀人&quot;); person.doCourt(); &#125;&#125;// 被代理的类class Person implements Court&#123; private String name; public Person(String name) &#123; this.name = name; &#125; @Override public void doCourt() &#123; System.out.println(name+&quot;说:我没有杀人&quot;); &#125;&#125; 7.3 动态代理​ 动态代理可以针对于一些不特定的类或者一些不特定的方法进行代理，可以在程序运行时动态的改变代理的规则，代理类在程序运行时才创建的代理模式，在这种情况下，代理类并不是在Java代码中定义好，而是在程序运行时根据在Java代码中的指示动态生成的 Proxy动态代理：JDK动态代理，面向接口 cglib动态代理：第三方动态代理，面向父类 7.3.1 Proxy动态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.testProxy; import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.Arrays;/** * @Author: Ly * @Description: */public class Test1 &#123; public static void main(String[] args) &#123; Dinner dinner=new Person(&quot;张三&quot;); // 通过Porxy动态代理获得一个代理对象,在代理对象中,对某个方法进行增强 // ClassLoader loader,被代理的对象的类加载器 ClassLoader classLoader = dinner.getClass().getClassLoader(); // Class&lt;?&gt;[] interfaces,被代理对象所实现的所有接口 Class[] interaces= dinner.getClass().getInterfaces(); //InvocationHandler h,执行处理器对象,专门用于定义增强的规则 InvocationHandler handler = new InvocationHandler() &#123; // invoke 当我们让代理对象调用任何方法时,都会触发invoke方法的执行 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //Object proxy, 代理对象 //Method method,被代理的方法 //Object[] args,被代理方法运行时的实参 Object res = null; if (method.getName().equals(&quot;eat&quot;)) &#123; System.out.println(&quot;饭前洗手&quot;); // 让原有的eat的方法去运行 res = method.invoke(dinner, args); System.out.println(&quot;饭后刷碗&quot;); &#125; else &#123; // 如果是其他方法,那么正常执行就可以了 res = method.invoke(dinner, args); &#125; return res; &#125; &#125;; Dinner dinnerProxy =(Dinner) Proxy.newProxyInstance(classLoader,interaces,handler); //dinnerProxy.eat(&quot;包子&quot;); dinnerProxy.drink(); &#125;&#125;interface Dinner&#123; void eat(String foodName); void drink();&#125; class Person implements Dinner&#123; private String name; public Person(String name) &#123; this.name = name; &#125; @Override public void eat(String foodName) &#123; System.out.println(name+&quot;正在吃&quot;+foodName); &#125; @Override public void drink() &#123; System.out.println(name+&quot;正在喝茶&quot;); &#125;&#125; class Student implements Dinner&#123; private String name; public Student(String name) &#123; this.name = name; &#125; @Override public void eat(String foodName) &#123; System.out.println(name+&quot;正在食堂吃&quot;+foodName); &#125; @Override public void drink() &#123; System.out.println(name+&quot;正在喝可乐&quot;); &#125;&#125; ​ 总结： 在不修改原有代码的或者没有办法修改原有代码的情况下，增强对象功能使用代理对象代替原来的对象去完成功能，进而达到拓展功能的目的 JDK Proxy动态代理是面向接口的动态代理，一定要有接口和实现类，代理对象增强的是实现类，在实现接口的方法重写方法，生成的代理对象只能转换成接口，不能转换成代理类 生成的代理对象只能转换成接口，不能转换成被代理类 代理对象只能增强接口中定义的方法，实现类中其他和接口无关的方法是无法增强的 代理对象只能读取到接口中方法上的注解，不能读取到实现类方法上的注解 7.3.2 cglib动态代理模式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.testCglib; import org.junit.Test;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy; import java.lang.reflect.Method;/** * @Author: Ly * @Description: */public class Test1 &#123; @Test public void testCglib()&#123; Person person = new Person(); // 获取一个Person的代理对象 // 1 获得一个Enhancer对象 Enhancer enhancer = new Enhancer(); // 2 设置父类字节码 enhancer.setSuperclass(person.getClass()); // 3 获取MethodIntercepter对象 用于定义增强规则 MethodInterceptor methodInterceptor = new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; /* Object o, 生成之后的代理对象 personProxy Method method, 父类中原本要执行的方法 Person&gt;&gt;&gt; eat() Object[] objects, 方法在调用时传入的实参数组 MethodProxy methodProxy 子类中重写父类的方法 personProxy &gt;&gt;&gt; eat() */ Object res = null; if (method.getName().equals(&quot;eat&quot;)) &#123; // 如果是eat方法 则增强并运行 System.out.println(&quot;饭前洗手&quot;); res = methodProxy.invokeSuper(o,objects); System.out.println(&quot;饭后刷碗&quot;); &#125; else &#123; // 如果是其他方法 不增强运行 res = methodProxy.invokeSuper(o,objects); // 子类对象方法在执行,默认会调用父类对应被重写的方法 &#125; return res; &#125; &#125;; // 4 设置methodInterceptor enhancer.setCallback(methodInterceptor); // 5 获得代理对象 Person personProxy = (Person)enhancer.create(); // 6 使用代理对象完成功能 personProxy.eat(&quot;包子&quot;); &#125;&#125;class Person &#123; public Person() &#123; &#125; public void eat(String foodName) &#123; System.out.println(&quot;张三正在吃&quot;+foodName); &#125;&#125; 8、Spring AOP8.1 AOP 概念及原理​ 在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。—-【百度百科】 ​ AOP 面向切面编程一般可以在不修改现有代码的情况下，对程序功能进行拓展，往往用于实现日志处理、权限控制、性能检测、事务控制等 ​ AOP实现的原理就是动态代理，在有接口的情况下，使用**JDK动态代理，在没有接口的情况下使用cglib动态代理** 8.2 术语 连接点（Joint point）：类里面可以被增强的方法，这些方法称之为连接点，表示在程序中明确定义的点，典型的包括方法调用，对类成员的访问以及异常处理程序块的执行等待，它自身还可以嵌套其他Join point 切入点（Pointcut）：实际被增强的方法，称之为切入点，表示一组joint point，这些joint point或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的Advince将要发生的地方 通知（Advince）：实际增强的逻辑部分称为通知（增加的功能），Advince定义了在Pointcut里面定义的程序点具体要做的操作，它通过before、after、around来区别是在每个joint point之前、之后还是代替执行的代码，通知类型：前置通知、后置通知、环绕通知、异常通知、最终通知 目标对象（Target）：被增强功能的对象（被代理的对象） 切面（Aspect）：表现为功能相关的一些advice放在一起声明成为一个java类，aspect声明类似与java的类声明，在aspect中会包含一些pointcut以及相应的advince 织入（Weaving）：创建代理对象并实现功能增强的声明并运行的过程，将Aspect和其他对象链接起来，并创建Advince Object的过程 8.3 注解方式实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.aspect; import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;import java.util.Arrays;/** * @Author: Ly * @Description: */ @Component@Aspectpublic class DaoAspect &#123; //定义公共切点 @Pointcut(&quot;execution(* com.dao.*.add*(..))&quot;) public void addPointCut() &#123;&#125;. /* * 前置通知: 切点方法执行之前先执行的功能 * 参数列表可以用JoinPoint接收切点对象 * 可以获取方法执行的参数 * */ @Before(&quot;addPointCut()&quot;) public void methodBefore(JoinPoint joinPoint) &#123; System.out.println(&quot;Before invoked&quot;); &#125; /* * 后置通知:方法执行之后要增强的功能 * 无论切点方法是否出现异常都会执行的方法 * 参数列表可以用JoinPoint接收切点对象 * */ @After(&quot;addPointCut()&quot;) public void methodAfter(JoinPoint joinPoint) &#123; System.out.println(&quot;After invoked&quot;); &#125; /* * 返回通知:切点方法正常运行结束后增强的功能 * 如果方法运行过程中出现异常,则该功能不运行 * 参数列表可以用 JoinPoint joinPoint接收切点对象 * 可以用Object res接收方法返回值,需要用returning指定返回值名称 * */ @AfterReturning( value = &quot;addPointCut()&quot;,returning = &quot;res&quot;) public void methodAfterReturning(JoinPoint joinPoint, Object res) &#123; System.out.println(&quot;AfterReturning invoked&quot;); &#125; /* * 异常通知:切点方法出现异常时运行的增强功能 * 如果方法运行没有出现异常,则该功能不运行 * 参数列表可以用Exception ex接收异常对象 需要通过throwing指定异常名称 * */ @AfterThrowing( value = &quot;addPointCut()&quot;,throwing = &quot;ex&quot;) public void methodAfterThrowing(Exception ex) &#123; System.out.println(&quot;AfterThrowing invoked&quot;); &#125; /*环绕通知:在切点方法之前和之后都进行功能的增强 * 需要在通知中定义方法执行的位置,并在执行位置之前和之后自定义增强的功能 * 方法列表可以通过ProceedingJoinPoint获取执行的切点 * 通过proceedingJoinPoint.proceed()方法控制切点方法的执行位置 * proceedingJoinPoint.proceed()方法会将切点方法的返回值获取到,并交给我们,可以做后续处理 * 我们在环绕通知的最后需要将切点方法的返回值继续向上返回,否则切点方法在执行时接收不到返回值 * */ @Around(&quot;addPointCut()&quot;) public Object methodAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; System.out.println(&quot;aroundA invoked&quot;); Object proceed = proceedingJoinPoint.proceed(); System.out.println(&quot;aroundB invoked&quot;); return proceed; &#125;&#125; ​ 有多个增强类对同一个方法进行增强，通过@Order注解设置增强类优先级，数字越小，优先级越高，数字越小，其代理位置越靠近注入位置 9、Spring 事务9.1 事务​ 事务（Transaction）：指的是一个操作序列，该操作序列中的多个操作，只能都做，或者都不做，是一个不可分割的工作单位，是数据库环境中的逻辑工作单位，由DBMS中的事务管理子系统负责事务的处理 ​ 但并不是所有的操作序列都可以称为为事务，因为一个操作序列成为事务，必须满足事务的四个特性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;ACID特性 9.1.1 原子性​ 原子是自然界最小的颗粒，具有不可再分的特性。事务中的所有操作可以看做一个原子，事务是应用中不可再分的最小的逻辑执行体。 ​ 使用事务对数据进行修改的操作序列，要么全部执行，要么全不执行。通常，某个事务中的操作都具有共同的目标，并且是相互依赖的。如果数据库系统只执行这些操作中的一部分，则可能会破坏事务的总体目标，而原子性消除了系统只处理部分操作的可能性。 9.1.2 一致性​ 一致性是指事务执行的结果必须使数据库从一个一致性状态，变到另一个一致性状态。当数据库中只包含事务成功提交的结果时，数据库处于一致性状态。一致性是通过原子性来保证的。 ​ 例如：在转账时，只有保证转出和转入的金额一致才能构成事务。也就是说事务发生前和发生后，数据的总额依然匹配。 9.1.3 隔离性​ 隔离性是指各个事务的执行互不干扰，任意一个事务的内部操作对其他并发的事务，都是隔离的。也就是说：并发执行的事务之间既不能看到对方的中间状态，也不能相互影响。 ​ 例如：在转账时，只有当A账户中的转出和B账户中转入操作都执行成功后才能看到A账户中的金额减少以及B账户中的金额增多。并且其他的事务对于转账操作的事务是不能产生任何影响的。 9.1.4 持久性​ 持久性指事务一旦提交，对数据所做的任何改变，都要记录到永久存储器中，通常是保存进物理数据库，即使数据库出现故障，提交的数据也应该能够恢复。但如果是由于外部原因导致的数据库故障，如硬盘被损坏，那么之前提交的数据则有可能会丢失。 9.2 事务的并发问题9.2.1 脏读（Dirty read）​ 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 9.2.2 不可重复读（Unrepeatableread）​ 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 9.2.3 幻读（Phantom read）​ 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 9.2.4 总结​ 不可重复读的重点是修改，幻读的重点在于新增或者删除 ​ 解决不可重复读的问题只需要锁住满足条件的行，解决幻读需要锁表 9.2.5 事务的隔离级别​ 事务的隔离级别用于决定如何控制并发用户读写数据的操作。数据库是允许多用户并发访问的，如果多个用户同时开启事务并对同一数据进行读写操作的话，有可能会出现脏读、不可重复读和幻读问题，所以MySQL中提供了四种隔离级别来解决上述问题。 ​ 事务的隔离级别从低到高依次为READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ以及SERIALIZABLE，隔离级别越低，越能支持高并发的数据库操作。 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITTED（读未提交） true true true READ COMMITTED（读已提交） false true true REPEATABLE READ（可重复读） false false true SERIALIZABLE（串行化） false false false ​","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"Spring","slug":"Spring","permalink":"https://lyblog2022.github.io/tags/Spring/"}]},{"title":"Servlet","date":"2022-06-04T08:59:30.000Z","path":"2022/06/04/study/Servlet/","text":"Servlet学习 1、Servlet的继承结构 2、Servlet接口 init()：创建servlet对象后立即调用该方法完成其他初始化工作 service()：处理客户端请求，执行业务操作，利用响应对象响应客户端请求 destory()：再销毁servlet对象之前调用该方法，释放资源 getServletConfig()：ServletConfig 是容器向Servlet传递参数的载体 getServletInfo()：获取servlet相关信息 3、ServletConfig 接口​ Servlet运行期间，需要一些辅助信息，这些信息可以在web.xml文件中，使用一个或多个元素进行配置。当tomacat初始化一个servlet时，会将该servlet的配置信息，封装到ServletConfig对象中，通过调用init(ServletConfig servletConfig)方法，将ServletConfig对象传递给Servlet 4、GenericServlet 抽象类​ GenericServlet是实现了Servlet接口的抽象类。在GenericServlet中进一步的定义了Servlet接口的具体实现，其设计的目的是为了和应用层协议解耦，再GenericServlet中包含了一个Service抽象方法，可以通过继承GenericServlet并实现Service方法实现请求的处理，但是需要将ServletRequest和ServletResponse 转化为HttpServletRequest和HttpServletResponse 5、HttpServlet​ 继承自GenericServlet，针对于处理Http协议的请求定制，在HttpServlet的service()方法中已经把ServletRequest和ServletResponse 转化为HttpServletRequest和HttpServletResponse 6、Servlet的生命周期​ servlet的生命周期是由容器管理的，分别经历4个阶段 阶段 字数 时机 创建 1次 第一次请求之后 初始化 1次 实例化之后 执行服务 多次 每次请求 销毁 1次 停止服务、 7、注意事项 在Servlet中一般不要轻易使用成员变量，可能会造成线程安全问题 如果要使用，应尽量避免对成员变量产生修改 如果要产生修改，应注意线程安全问题 8、ServletContext对象和ServletConfig对象​ ServletContext叫做Servlet上下文，服务器会为每一个web应用创建一个ServletContext对象，这个对象全局唯一，而且web应用中的所有Servlet都共享这个对象 8.1、ServletContext对象的作用 相对路径转为绝对路径 获取容器的附加信息 读取配置 全局容器 8.2、ServletContext的生命周期​ 当容器启动时会创建ServletContext对象并一直缓存该对象，直到容器关闭后该对象生命周期结束，ServletContext的生命周期非常长，所以在使用全局容器时不建议存放业务数据 8.3、ServletConfig对象​ ServletConfig对象对应web.xml文件中的节点，当Tomcat初始化一个Servlet时，会将该Servlet的配置信息，封装到一个ServletConfig对象中，可以通过该对象读取节点中的配置信息 9、请求转发9.1 forward转发9.1.1 forward转发处理流程 清空response存放的正在响应正文数据缓冲区 如果目标资源为Servlet或jsp，就调用他们的service方法，把该方法产生的响应结果发送到客户端；如果目标资源是静态文件中的HTML，就读取文件中的数据把它发送到客户端 9.1.2 forward处理特点 由于forward()方法先清空用于存放相应正文的缓冲区，因此源Servlet生成的响应结果不会被发送到客户端，只有目标资源生成的响应结果才会被发送到客户端 如果源Servlet在进行请求转发之前，已经提交了响应结(flushBuffer()，close()方法)，那么forward()方法会抛出异常，为避免异常，不应该在源servlet中提交响应结果 9.2 include转发9.2.1 include处理流程 如果目标资源为Servlet或者jsp，就调用他们的service方法，把该方法产生的响应正文添加到源Servlet的响应结果中；如果目标组建为HTML文档，就直接把文档的内容添加到源Servlet的响应结果中 返回到源Servlet的服务方法中，继续执行后续代码 9.2.2 include处理特点 源Servlet与被包含的目标资源的输出数据都会被添加到响应结果中 在目标资源对响应状态码或者响应开头所做的修改都会被忽略 10、Cookie对象和HttpSession对象​ Cookie对象和HttpSession对象的作用是维护客户端浏览器与服务端的会话状态的两个对象，二者的不同是Cookie是通过客户端浏览器实现会话的维持，而HttpSession是通过服务端来实现会话的维持 10.1 区别 cookie数据存放在客户的浏览器或系统文件中，httpsession中的数据存放在服务器中 cookie不安全，httpSession是安全的 单个cookie保存的数据不能超过4K，httpSession无限制","tags":[{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"servlet","slug":"servlet","permalink":"https://lyblog2022.github.io/tags/servlet/"}]},{"title":"MyBatis","date":"2022-06-04T08:59:00.000Z","path":"2022/06/04/study/MyBatis/","text":"MyBatis学习 1、简介Mybatis 是一款优秀的持久层框架，支持定制化SQL、存储过程及高级映射，可以使用简单的XML或注解来配置和映射原生信息 是一款半自动的持久层的半自动ORM映射框架 1.1 框架 框架是一个基本概念上的结构，用于解决或处理复杂的问题。 使用框架的优点：减少开发时间，降低开发难度，保证设计质量，降低程序员之间的沟通以及日后维护的成本 框架是一个半成品，已经对基础的代码进行了封装并提供响应的API，开发者再使用框架是直接调用封装好的API，可以省去很多代码编写，从而提升效率和开发速度 1.2 ORM Object-Relation Mapping，对象关系映射 它的作用是在关系型数据库和对象之间做一个映射，这样在操作具体数据的时候就像操作对象一样 1.2.1 持久化 持久：把数据保存到可永久保存的存储设备中 主要应用：将内存中的数据存储在关系型数据库中 1.2.2 持久层 专注于实现数据持久化应用领域的某一个特定系统的一个逻辑层面，将数据使用者和数据实体想关联（mapper层、DAO层） 2、Mybatis配置2.1 事务​ 在MyBatis 核心配置文件中envirment 中通过transactionManager配置事务的处理策略 JDBC：该配置使用了JDBC的提交及回滚，依赖于从数据源得到的链接来管理事务范围 MANAGED：该配置几乎无任何操作，不提交或回滚一个链接，它会让容器来管理整个生命周期（Spring应用服务器的上下文），默认情况下会关闭链接，但一些容器不希望如此，因此如果需要从链接中停止它，将closeConnection的属性值设置为false，Mybatis本身并不会处理事务，而是交给其他框架去处理 2.2 映射文件的加载方式 mapper的映射文件的文件路径导入，使用的是mapper标签的resource属性 网络资源路径使用的是mapper的url属性 接口的全限定名导入使用的是mapper标签的class属性—–基于接口的代理模式 包扫描形式加载所有的mapper映射文件，使用的package标签 3、Mybatis 开发3.1 传递参数 ${} 代表mybatis底层使用Statment语句对象,参数是以字符串拼接的形式设置 #{} 代表mybatis底层使用的preparedStatment语句对象,参数使用?作为占位符处理，更常用 4、MyBatis代理模式开发在MyBatis中提供了一种称为Mapper代理（接口绑定）的操作方式，在实际开发中也使用该方式 4.1 原理浅析​ 底层使用了动态代理模式，动态创建一个Mapper的一个代理对象并赋给接口使用 5、动态SQL​ MyBatis在简化操作方法上提出了动态SQL功能，将使用Java代码拼接SQL语句，改变为在XML映射文件中截止标签拼接SQL语句。相比而言，大大减少代码量，更灵活、有利于后期维护 ​ MyBatis中动态SQL是编写在mapper.xml中的，其语法和JSTL类似，但是却是基于强大的OGNL表达式实现的 ​ MyBatis也可以在注解中配置SQL，但是由于注解功能受限，尤其是对于复杂的SQL语句，可读性很差，所以较少使用 5.1 If标签条件查询，符合if的条件，则补充SQL语句 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.mapper.StudentMapper&quot;&gt; &lt;select id=&quot;findByCondition&quot; resultType=&quot;Student&quot;&gt; select * from student where 1=1 &lt;if test=&quot;stuno != null&quot;&gt; and stuno =#&#123;stuno&#125; &lt;/if&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; and classname like concat(&#x27;%&#x27;,#&#123;classname&#125;,&#x27;%&#x27;) &lt;/if&gt; &lt;/select&gt;&lt;/mapper&gt; 5.2 Where标签用于处理where关键字和and 1234567891011&lt;select id=&quot;findStuByCondition&quot; resultType=&quot;Student&quot;&gt; select * from student &lt;where&gt; &lt;if test=&quot;stuno != null&quot;&gt; and stuno= #&#123;stuno&#125; &lt;/if&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; and classname= #&#123;classname&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 5.3 Choose标签前面的when条件成立 后面的 when就不再判断了 12345678910111213&lt;select id=&quot;findStuByCondition&quot; resultType=&quot;Student&quot;&gt; select * from student &lt;where&gt; &lt;choose&gt; &lt;when test=&quot;stuno != null&quot;&gt; and stuno= #&#123;stuno&#125; &lt;/when&gt; &lt;when test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; and classname= #&#123;classname&#125; &lt;/when&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; 5.4 Set标签12345678910111213&lt;update id=&quot;updateStuByCondtion&quot; &gt; update student &lt;set&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27; &quot;&gt; , classname =#&#123;classname&#125; &lt;/if&gt; &lt;if test=&quot;stuno != null &quot;&gt; , stuname =#&#123;stuname&#125; &lt;/if&gt; &lt;/set&gt; where stuno =#&#123;stuno&#125;&lt;/update&gt; 5.5 Trim标签123456789101112131415161718&lt;update id=&quot;updateStuByCondition&quot; &gt; update student &lt;!--prefix 要增加什么前缀 prefixOverrides 要去除什么前缀 suffix 要增加什么后缀 suffixOverrides 要去除什么后缀 set 是trim的一种特殊情况 --&gt; &lt;trim prefix=&quot;set&quot; suffixOverrides=&quot;,&quot; &gt; &lt;if test=&quot;stuname != null and stuname != &#x27;&#x27;&quot;&gt; stuname= #&#123;stuname&#125;, &lt;/if&gt; &lt;if test=&quot;classname != null and classname != &#x27;&#x27;&quot;&gt; classname= #&#123;classname&#125;, &lt;/if&gt; &lt;/trim&gt; where stuno = #&#123;stuno&#125;&lt;/update&gt; 5.6 Bind标签一般用于处理模糊查询的模板 1234&lt;select id=&quot;findStuByClassName&quot; resultType=&quot;Student&quot;&gt; &lt;bind name=&quot;likePattern&quot; value=&quot;&#x27;%&#x27;+param1+&#x27;%&#x27;&quot;&gt;&lt;/bind&gt; select * from student where classname like #&#123;classname&#125;&lt;/select&gt; 6、缓存6.1 一级缓存​ 一级存储是SqlSession上的缓存，默认开启，是一种内存型缓存,不要求实体类对象实现Serializable接口 ​ 缓存中的数据使用键值对形式存储数据 ​ namespace+sqlid+args+offset&gt;&gt;&gt; hash值作为键,查询出的结果作为值 6.2 二级缓存​ 二级缓存是以namespace为标记的缓存，可以是由一个SqlSessionFactory创建的SqlSession之间共享缓存数据。默认并不开启，要求实体类必须实现序列化接口 注意： ​ 1、 MyBatis的二级缓存的缓存介质有多种多样，而并不一定是在内存中，所以需要对JavaBean对象实现序列化接口。 ​ 2、二级缓存是以 namespace 为单位的，不同 namespace 下的操作互不影响 ​ 3、加入Cache元素后，会对相应命名空间所有的select元素查询结果进行缓存，而其中的insert、update、delete在操作是会清空整个namespace的缓存 ​ 4、cache 有一些可选的属性 type, eviction, flushInterval, size, readOnly, blocking。 1&lt;cache type=&quot;&quot; readOnly=&quot;&quot; eviction=&quot;&quot;flushInterval=&quot;&quot;size=&quot;&quot;blocking=&quot;&quot;/&gt; 属性 含义 默认值 type 自定义缓存类，要求实现org.apache.ibatis.cache.Cache接口 null readOnly 是否只读 true:给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。false:会返回缓存对象的拷贝(通过序列化) 。这会慢一些,但是安全 false eviction 缓存策略LRU（默认） – 最近最少使用：移除最长时间不被使用的对象。FIFO – 先进先出：按对象进入缓存的顺序来移除它们。SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。 LRU flushInterval 刷新间隔，毫秒为单位。默认为null，也就是没有刷新间隔，只有执行update、insert、delete语句才会刷新 null size 缓存对象个数 1024 blocking 是否使用阻塞性缓存BlockingCachetrue：在查询缓存时锁住对应的Key，如果缓存命中了则会释放对应的锁，否则会在查询数据库以后再释放锁，保证只有一个线程到数据库中查找指定key对应的数据false：不使用阻塞性缓存，性能更好 false ​ 5、如果在加入Cache元素的前提下让个别select 元素不使用缓存，可以使用useCache属性，设置为false。**useCache**控制当前sql语句是否启用缓存 flushCache控制当前sql执行一次后是否刷新缓存 1&lt;select id=&quot;findStuByCondition&quot; resultType=&quot;Student&quot; useCache=&quot;true&quot; flushCache=&quot;false&quot;&gt; 6.3 三方缓存 分布式缓存框架：我们系统为了提高系统并发和性能，一般对系统进行分布式部署（集群部署方式）不适用分布缓存， 缓存的数据在各个服务单独存储，不方便系统开发。所以要使用分布式缓存对缓存数据进行集中管理.ehcache,redis ,memcache缓存框架。 Ehcache：是一种广泛使用的开源java分布式缓存。主要面向通用缓存，javaEE 和 轻量级容器。它具有内存和磁盘存储功能。被用于大型复杂分布式web application的","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://lyblog2022.github.io/tags/MyBatis/"},{"name":"学习","slug":"学习","permalink":"https://lyblog2022.github.io/tags/%E5%AD%A6%E4%B9%A0/"}]},{"title":"518总结--post请求调用接口","date":"2022-05-18T13:06:35.000Z","path":"2022/05/18/dailysummary/20220518/dailysummary/","text":"使用post方式调用接口并传递参数 方式一1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.summary;import java.nio.charset.Charset;import java.util.ArrayList;import java.util.Iterator;import java.util.List;import java.util.Map;import org.apache.http.HttpEntity;import org.apache.http.NameValuePair;import org.apache.http.client.config.RequestConfig;import org.apache.http.client.entity.UrlEncodedFormEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpPost;import org.apache.http.entity.StringEntity;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.message.BasicNameValuePair;import org.apache.http.util.EntityUtils;import com.alibaba.fastjson.JSONObject;public class Summary &#123; /** * 发送post请求 * @param url：请求URL * @param headerParamsJson：请求header参数 * @param paramJson：请求参数 * @return */ public JSONObject sendData(String url, JSONObject headerParamsJson, JSONObject paramJson) &#123; JSONObject resultJson = new JSONObject(); // 发送post请求 try &#123; HttpPost httppost = new HttpPost(url); RequestConfig defaultRequestConfig = RequestConfig.custom().setConnectTimeout(5000) .setConnectionRequestTimeout(5000).setSocketTimeout(15000).build(); httppost.setConfig(defaultRequestConfig); StringEntity entity = new StringEntity(paramJson.toJSONString(), &quot;utf-8&quot;);// 解决中文乱码问题 entity.setContentEncoding(&quot;UTF-8&quot;); entity.setContentType(&quot;text/json&quot;); httppost.setEntity(entity); httppost.setHeader(&quot;Content-type&quot;, &quot;application/json&quot;); // 添加header参数 Iterator headerParamsIterator = headerParamsJson.entrySet().iterator(); while (headerParamsIterator.hasNext()) &#123; Map.Entry entry = (Map.Entry) headerParamsIterator.next(); httppost.setHeader(entry.getKey().toString(), entry.getValue().toString()); &#125; // 装填参数 List&lt;NameValuePair&gt; nvps = new ArrayList&lt;NameValuePair&gt;(); if (paramJson != null) &#123; Iterator iterator = paramJson.entrySet().iterator(); while (iterator.hasNext()) &#123; Map.Entry entry = (Map.Entry) iterator.next(); nvps.add(new BasicNameValuePair((String) entry.getKey(), (String) entry.getValue())); &#125; &#125; UrlEncodedFormEntity reqEntity = new UrlEncodedFormEntity(nvps, &quot;utf-8&quot;); httppost.setEntity(reqEntity); // 执行post请求. CloseableHttpClient httpclient = HttpClients.createDefault(); CloseableHttpResponse response1 = httpclient.execute(httppost); String resultText = &quot;&quot;; try &#123; int statusCode = response1.getStatusLine().getStatusCode(); if (statusCode != 200) &#123; throw new RuntimeException(&quot;请求失败&quot;); &#125; else &#123; // 响应实体 HttpEntity entity2 = response1.getEntity(); if (entity2 != null) &#123; // 响应内容 resultText = EntityUtils.toString(entity2, Charset.forName(&quot;UTF-8&quot;)); resultJson = JSONObject.parseObject(resultText); &#125; &#125; resultJson.put(&quot;code&quot;, statusCode); &#125; finally &#123; response1.close(); &#125; &#125; catch (Exception e) &#123; resultJson.put(&quot;code&quot;, &quot;410&quot;); resultJson.put(&quot;err&quot;, e.toString()); &#125; return resultJson; &#125;&#125;","tags":[{"name":"httpClient","slug":"httpClient","permalink":"https://lyblog2022.github.io/tags/httpClient/"},{"name":"那些代码那些总结","slug":"那些代码那些总结","permalink":"https://lyblog2022.github.io/tags/%E9%82%A3%E4%BA%9B%E4%BB%A3%E7%A0%81%E9%82%A3%E4%BA%9B%E6%80%BB%E7%BB%93/"},{"name":"接口调用","slug":"接口调用","permalink":"https://lyblog2022.github.io/tags/%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"}]}]